{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "mU7Kb8-6Qs9m"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'build_g' from 'network' (/Users/lilyhua/OneDrive - Imperial College London/INHALE Code/Lily/AAE/network.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a660d5660202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mAAE_Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - Imperial College London/INHALE Code/Lily/AAE/AAE_Model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'build_g' from 'network' (/Users/lilyhua/OneDrive - Imperial College London/INHALE Code/Lily/AAE/network.py)"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "import dataset, network\n",
    "import AAE_Model\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37tykamPQs9o"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "scenario = \"moons\"\n",
    "n_instance = 1000 # number of generated points\n",
    "n_features = 2\n",
    "\n",
    "scenario = X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "export_excel(X_train, 'Dataset/X_train')\n",
    "export_excel(y_train, 'Dataset/y_train')\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "vars = np.zeros((6,864)) #變數\n",
    "j=0\n",
    "n_features = 2\n",
    "n_var =int(vars[0,j])  #變數\n",
    "latent_spaces = [3,10,50,100]\n",
    "latent_space = 3 #int(latent_spaces[int(vars[1,j])])\n",
    "batchs = [10,100,1000]\n",
    "BATCH_SIZE = 100#int(batchs[int(vars[2,j])])\n",
    "scales = ['-1-1']\n",
    "scaled = '-1-1'#scales[int(vars[3,j])]\n",
    "epochs = 5001   #[1000,10000,10000]\n",
    "# epoch = int(epochs[int(vars[4,j])])\n",
    "bias = [True,False]\n",
    "use_bias = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AAE_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0b7e7fa3162d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build and compile the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAAE_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AAE_Model' is not defined"
     ]
    }
   ],
   "source": [
    "# Build and compile the discriminator\n",
    "discriminator = AAE_Model.AAE.build_discriminator(latent_space)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the encoder / decoder\n",
    "encoder = AAE_Model.AAE.build_encoder(latent_space, )\n",
    "decoder = AAE_Model.AAE.build_decoder(latent_space, fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE_Model.AAE(n_features,latent_space,BATCH_SIZE,n_var,use_bias)\n",
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "hist = aae.train(train_dataset, epochs, scaler, scaled, X_train, y_train)\n",
    "wgan.generator.save('GANS/Models/GAN_'+str(j))\n",
    "# plot loss\n",
    "print('Loss: ')\n",
    "fig, ax = plt.subplots(1,1, figsize=[10,5])\n",
    "ax.plot(hist)\n",
    "ax.legend(['loss_gen', 'loss_disc'])\n",
    "#ax.set_yscale('log')\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('GANS/Losses/GANS_loss'+str(j)+'.png')\n",
    "generator = keras.models.load_model('GANS/Models/GAN_'+str(j))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_values = tf.random.normal([1000, latent_space], mean=0.0, stddev=0.1)\n",
    "predicted_values = wgan.generator.predict(latent_values)\n",
    "if scaled == '-1-1':\n",
    "    predicted_values[:,:]=(predicted_values[:,:])\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "plt.plot(X_train,y_train,'o')\n",
    "plt.plot(predicted_values[:,0],predicted_values[:,1],'o')\n",
    "plt.show()\n",
    "\n",
    "np.shape(latent_values)\n",
    "\n",
    "np.shape(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = [-1, 0, 0.5, 1.5]\n",
    "n_points = 80\n",
    "y_min = -0.75\n",
    "y_max = 1\n",
    "\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//4, 2), x_input[0])\n",
    "predict2 = np.full((n_points//4, 2), x_input[1])\n",
    "predict3 = np.full((n_points//4, 2), x_input[2])\n",
    "predict4 = np.full((n_points//4, 2), x_input[3])\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4))\n",
    "\n",
    "for n in range(n_points):\n",
    "    predictthis[n,1] = random.uniform(y_min, y_max)\n",
    "    \n",
    "predictthis_scaled = scaler.transform(predictthis)\n",
    "input_test = predictthis_scaled.reshape(-1, n_features).astype('float32')\n",
    "\n",
    "print(input_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-2)\n",
    "\n",
    "def mse_loss(inp, outp):\n",
    "    \"\"\"\n",
    "    Calculates the MSE loss between the x-coordinates\n",
    "    \"\"\"\n",
    "    inp = tf.reshape(inp, [-1, n_features])\n",
    "    outp = tf.reshape(outp, [-1, n_features])\n",
    "    return mse(inp[:,0], outp[:,0])\n",
    "\n",
    "\n",
    "def opt_step(latent_values, real_coding):\n",
    "    \"\"\"\n",
    "    Minimizes the loss between generated point and inputted point\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(latent_values)\n",
    "        gen_output = wgan.generator(latent_values, training=False)\n",
    "        loss = mse_loss(real_coding, gen_output)\n",
    "\n",
    "    gradient = tape.gradient(loss, latent_values)\n",
    "    optimizer.apply_gradients(zip([gradient], [latent_values]))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def optimize_coding(real_coding):\n",
    "    \"\"\"\n",
    "    Optimizes the latent space values\n",
    "    \"\"\"\n",
    "    latent_values = tf.random.normal([1, latent_space], mean=0.0, stddev=0.1)\n",
    "    latent_values = tf.Variable(latent_values)\n",
    "\n",
    "    loss = np.array()\n",
    "    while \n",
    "#     for epoch in range(500):\n",
    "        loss.append(opt_step(latent_values, real_coding).numpy())\n",
    "\n",
    "    return latent_values\n",
    "\n",
    "def predict(input_data, scaler, scaled):\n",
    "    \"\"\"\n",
    "    Optimizes the latent space of the input then produces a prediction from\n",
    "    the generator.\n",
    "    \"\"\"\n",
    "    predicted_vals = np.zeros((1, n_features))\n",
    "\n",
    "    for n in range(len(input_data)):\n",
    "        print(\"Optimizing latent space for point \", n, \" / \", len(input_data))\n",
    "        real_coding = input_data[n].reshape(1, n_features)\n",
    "        real_coding = tf.constant(real_coding)\n",
    "        real_coding = tf.cast(real_coding, dtype=tf.float32)\n",
    "        \n",
    "        print(real_coding)\n",
    "\n",
    "        latent_values = optimize_coding(real_coding)\n",
    "\n",
    "        print(latent_values)\n",
    "        #predicted_vals.append(scaler.inverse_transform(wgan.generator.predict(tf.convert_to_tensor(latent_values)).reshape(1,n_features)))\n",
    "        predicted_vals_1 = scaler.inverse_transform((wgan.generator.predict(tf.convert_to_tensor(latent_values)).reshape(1, n_features)))\n",
    "#         predicted_vals_1 = predicted_vals_1.reshape(1, self.n_features)\n",
    "        predicted_vals = np.concatenate((predicted_vals, predicted_vals_1), axis=0)\n",
    "    \n",
    "    predicted_vals = predicted_vals[1:,:]\n",
    "\n",
    "    \n",
    "    return predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated = predict(input_test, scaler, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_generated)\n",
    "plt.title(\"Prediction at x = -1, 0, 1.5\")\n",
    "plt.scatter(X_train, y_train, label=\"Training data\")\n",
    "#plt.scatter(predictthis[:,0], predictthis[:,1], label=\"Sample data\", c=\"pink\")\n",
    "plt.scatter(X_generated[:,0], X_generated[:,1], label=\"Fixed Input Prediction\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wgan-gp_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
