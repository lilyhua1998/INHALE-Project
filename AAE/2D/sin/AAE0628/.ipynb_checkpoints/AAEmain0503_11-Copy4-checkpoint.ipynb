{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"sinus\" #sinus, helix\n",
    "n_instance = 1000\n",
    "n_features = 2\n",
    "Z=40\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'\n",
    "nodes=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "export_excel(X_train, 'Dataset/X_train')\n",
    "export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder:\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40)           1320        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 40)           1320        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 40)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,296\n",
      "Trainable params: 5,104\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "Decoder:\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,578\n",
      "Trainable params: 5,386\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Discriminator:\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,081\n",
      "Trainable params: 961\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=network11.build_encoder(Z, nodes, n_features)\n",
    "print(\"Encoder:\\n\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "decoder=network11.build_decoder(Z,nodes, n_features)\n",
    "print(\"Decoder:\\n\")\n",
    "decoder.summary()\n",
    "\n",
    "discriminator=network11.build_discriminator(Z)\n",
    "print(\"Discriminator:\\n\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model11\n",
    "\n",
    "GANorWGAN='WGAN'\n",
    "epochs = 101\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE_Model11.AAE(Z, n_features, BATCH_SIZE,GANorWGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (100, 2)\n",
      "data shape_2 (100, 2)\n",
      "data shape_3 (100, 2)\n",
      "data shape_4 (100, 2)\n",
      "data shape_5 (100, 2)\n",
      "data shape_6 (100, 2)\n",
      "data shape_7 (100, 2)\n",
      "data shape_8 (100, 2)\n",
      "data shape_9 (100, 2)\n",
      "data shape_10 (100, 2)\n",
      "Cycles:  10\n",
      "X_train (1000, 1)\n",
      "y_train (1000, 1)\n",
      "X_train_scaled (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/101\n",
      "[C1 valid: -0.501723, C2 fake: 0.505074], [G loss: 0.406537, mse: 0.407464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyhua/OneDrive - Imperial College London/INHALE Code/Lily/AAE/AAE0504/AAE_Model11.py:190: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AAE/Models/11encoder_40_0/assets\n",
      "INFO:tensorflow:Assets written to: AAE/Models/11decoder_40_0/assets\n",
      "INFO:tensorflow:Assets written to: AAE_PCAE/11discriminator_40_0/assets\n",
      "Epoch 2/101\n",
      "[C1 valid: -0.504292, C2 fake: 0.504594], [G loss: 0.265236, mse: 0.266016]\n",
      "Epoch 3/101\n",
      "[C1 valid: -0.504395, C2 fake: 0.503259], [G loss: 0.145055, mse: 0.145702]\n",
      "Epoch 4/101\n",
      "[C1 valid: -0.503877, C2 fake: 0.502939], [G loss: 0.144066, mse: 0.144719]\n",
      "Epoch 5/101\n",
      "[C1 valid: -0.503808, C2 fake: 0.502453], [G loss: 0.115644, mse: 0.116248]\n",
      "Epoch 6/101\n",
      "[C1 valid: -0.502591, C2 fake: 0.502551], [G loss: 0.079618, mse: 0.080142]\n",
      "Epoch 7/101\n",
      "[C1 valid: -0.502758, C2 fake: 0.503274], [G loss: 0.068446, mse: 0.069062]\n",
      "Epoch 8/101\n",
      "[C1 valid: -0.502979, C2 fake: 0.503467], [G loss: 0.075571, mse: 0.076164]\n",
      "Epoch 9/101\n",
      "[C1 valid: -0.503530, C2 fake: 0.503457], [G loss: 0.058248, mse: 0.058796]\n",
      "Epoch 10/101\n",
      "[C1 valid: -0.503476, C2 fake: 0.503149], [G loss: 0.050718, mse: 0.051137]\n",
      "Epoch 11/101\n",
      "[C1 valid: -0.504849, C2 fake: 0.506412], [G loss: 0.044186, mse: 0.044663]\n",
      "Epoch 12/101\n",
      "[C1 valid: -0.505060, C2 fake: 0.507689], [G loss: 0.039404, mse: 0.039828]\n",
      "Epoch 13/101\n",
      "[C1 valid: -0.503807, C2 fake: 0.507205], [G loss: 0.039643, mse: 0.040024]\n",
      "Epoch 14/101\n",
      "[C1 valid: -0.504009, C2 fake: 0.506573], [G loss: 0.039103, mse: 0.039498]\n",
      "Epoch 15/101\n",
      "[C1 valid: -0.504390, C2 fake: 0.505906], [G loss: 0.036544, mse: 0.036945]\n",
      "Epoch 16/101\n",
      "[C1 valid: -0.504124, C2 fake: 0.505250], [G loss: 0.027571, mse: 0.027934]\n",
      "Epoch 17/101\n",
      "[C1 valid: -0.503832, C2 fake: 0.504833], [G loss: 0.025864, mse: 0.026258]\n",
      "Epoch 18/101\n",
      "[C1 valid: -0.503889, C2 fake: 0.505255], [G loss: 0.021914, mse: 0.022270]\n",
      "Epoch 19/101\n",
      "[C1 valid: -0.504232, C2 fake: 0.505340], [G loss: 0.030797, mse: 0.031164]\n",
      "Epoch 20/101\n",
      "[C1 valid: -0.504158, C2 fake: 0.505168], [G loss: 0.040097, mse: 0.040421]\n",
      "Epoch 21/101\n",
      "[C1 valid: -0.499307, C2 fake: 0.503080], [G loss: 0.033229, mse: 0.033493]\n",
      "Epoch 22/101\n",
      "[C1 valid: -0.502120, C2 fake: 0.504107], [G loss: 0.023632, mse: 0.023980]\n",
      "Epoch 23/101\n",
      "[C1 valid: -0.501880, C2 fake: 0.504293], [G loss: 0.024300, mse: 0.024576]\n",
      "Epoch 24/101\n",
      "[C1 valid: -0.502739, C2 fake: 0.505116], [G loss: 0.019094, mse: 0.019351]\n",
      "Epoch 25/101\n",
      "[C1 valid: -0.502088, C2 fake: 0.505225], [G loss: 0.019656, mse: 0.019842]\n",
      "Epoch 26/101\n",
      "[C1 valid: -0.502727, C2 fake: 0.504773], [G loss: 0.016345, mse: 0.016647]\n",
      "Epoch 27/101\n",
      "[C1 valid: -0.502758, C2 fake: 0.504679], [G loss: 0.021402, mse: 0.021651]\n",
      "Epoch 28/101\n",
      "[C1 valid: -0.503122, C2 fake: 0.504522], [G loss: 0.029077, mse: 0.029343]\n",
      "Epoch 29/101\n",
      "[C1 valid: -0.503452, C2 fake: 0.504620], [G loss: 0.014178, mse: 0.014395]\n",
      "Epoch 30/101\n",
      "[C1 valid: -0.503461, C2 fake: 0.504306], [G loss: 0.015336, mse: 0.015561]\n",
      "Epoch 31/101\n",
      "[C1 valid: -0.500891, C2 fake: 0.508932], [G loss: 0.011513, mse: 0.011719]\n",
      "Epoch 32/101\n",
      "[C1 valid: -0.501668, C2 fake: 0.505133], [G loss: 0.013678, mse: 0.013888]\n",
      "Epoch 33/101\n",
      "[C1 valid: -0.503003, C2 fake: 0.506065], [G loss: 0.013540, mse: 0.013724]\n",
      "Epoch 34/101\n",
      "[C1 valid: -0.502815, C2 fake: 0.505507], [G loss: 0.011157, mse: 0.011412]\n",
      "Epoch 35/101\n",
      "[C1 valid: -0.503947, C2 fake: 0.504630], [G loss: 0.018134, mse: 0.018332]\n",
      "Epoch 36/101\n",
      "[C1 valid: -0.503448, C2 fake: 0.504467], [G loss: 0.012405, mse: 0.012622]\n",
      "Epoch 37/101\n",
      "[C1 valid: -0.503775, C2 fake: 0.503837], [G loss: 0.013313, mse: 0.013509]\n",
      "Epoch 38/101\n",
      "[C1 valid: -0.503702, C2 fake: 0.504184], [G loss: 0.011557, mse: 0.011686]\n",
      "Epoch 39/101\n",
      "[C1 valid: -0.503690, C2 fake: 0.504099], [G loss: 0.021625, mse: 0.021789]\n",
      "Epoch 40/101\n",
      "[C1 valid: -0.503534, C2 fake: 0.504366], [G loss: 0.013728, mse: 0.013898]\n",
      "Epoch 41/101\n",
      "[C1 valid: -0.502439, C2 fake: 0.503928], [G loss: 0.012356, mse: 0.012513]\n",
      "Epoch 42/101\n",
      "[C1 valid: -0.503728, C2 fake: 0.504111], [G loss: 0.011165, mse: 0.011383]\n",
      "Epoch 43/101\n",
      "[C1 valid: -0.504335, C2 fake: 0.503506], [G loss: 0.013562, mse: 0.013712]\n",
      "Epoch 44/101\n",
      "[C1 valid: -0.503594, C2 fake: 0.504854], [G loss: 0.013355, mse: 0.013491]\n",
      "Epoch 45/101\n",
      "[C1 valid: -0.504456, C2 fake: 0.503518], [G loss: 0.009182, mse: 0.009332]\n",
      "Epoch 46/101\n",
      "[C1 valid: -0.503500, C2 fake: 0.503581], [G loss: 0.010422, mse: 0.010543]\n",
      "Epoch 47/101\n",
      "[C1 valid: -0.503522, C2 fake: 0.503797], [G loss: 0.009981, mse: 0.010190]\n",
      "Epoch 48/101\n",
      "[C1 valid: -0.503419, C2 fake: 0.503450], [G loss: 0.011008, mse: 0.011121]\n",
      "Epoch 49/101\n",
      "[C1 valid: -0.503096, C2 fake: 0.503511], [G loss: 0.010918, mse: 0.011003]\n",
      "Epoch 50/101\n",
      "[C1 valid: -0.503641, C2 fake: 0.503254], [G loss: 0.011170, mse: 0.011257]\n",
      "Epoch 51/101\n",
      "[C1 valid: -0.500524, C2 fake: 0.500407], [G loss: 0.007719, mse: 0.007874]\n",
      "Epoch 52/101\n",
      "[C1 valid: -0.498909, C2 fake: 0.500446], [G loss: 0.011755, mse: 0.011868]\n",
      "Epoch 53/101\n",
      "[C1 valid: -0.500840, C2 fake: 0.500334], [G loss: 0.019132, mse: 0.019251]\n",
      "Epoch 54/101\n",
      "[C1 valid: -0.501043, C2 fake: 0.500647], [G loss: 0.010654, mse: 0.010776]\n",
      "Epoch 55/101\n",
      "[C1 valid: -0.501243, C2 fake: 0.501327], [G loss: 0.009507, mse: 0.009665]\n",
      "Epoch 56/101\n",
      "[C1 valid: -0.501166, C2 fake: 0.502348], [G loss: 0.009987, mse: 0.010129]\n",
      "Epoch 57/101\n",
      "[C1 valid: -0.501761, C2 fake: 0.502065], [G loss: 0.014983, mse: 0.015151]\n",
      "Epoch 58/101\n",
      "[C1 valid: -0.501684, C2 fake: 0.502345], [G loss: 0.008883, mse: 0.009072]\n",
      "Epoch 59/101\n",
      "[C1 valid: -0.502197, C2 fake: 0.502998], [G loss: 0.008206, mse: 0.008454]\n",
      "Epoch 60/101\n",
      "[C1 valid: -0.502304, C2 fake: 0.503242], [G loss: 0.012423, mse: 0.012544]\n",
      "Epoch 61/101\n",
      "[C1 valid: -0.503118, C2 fake: 0.500124], [G loss: 0.006007, mse: 0.006261]\n",
      "Epoch 62/101\n",
      "[C1 valid: -0.503088, C2 fake: 0.500945], [G loss: 0.012451, mse: 0.012696]\n",
      "Epoch 63/101\n",
      "[C1 valid: -0.503342, C2 fake: 0.501055], [G loss: 0.006812, mse: 0.006928]\n",
      "Epoch 64/101\n",
      "[C1 valid: -0.504077, C2 fake: 0.501207], [G loss: 0.011414, mse: 0.011586]\n",
      "Epoch 65/101\n",
      "[C1 valid: -0.504115, C2 fake: 0.501048], [G loss: 0.008120, mse: 0.008300]\n",
      "Epoch 66/101\n",
      "[C1 valid: -0.503510, C2 fake: 0.501149], [G loss: 0.005804, mse: 0.006056]\n",
      "Epoch 67/101\n",
      "[C1 valid: -0.503850, C2 fake: 0.501329], [G loss: 0.007008, mse: 0.007219]\n",
      "Epoch 68/101\n",
      "[C1 valid: -0.503624, C2 fake: 0.501800], [G loss: 0.007716, mse: 0.007919]\n",
      "Epoch 69/101\n",
      "[C1 valid: -0.502819, C2 fake: 0.501964], [G loss: 0.009853, mse: 0.010078]\n",
      "Epoch 70/101\n",
      "[C1 valid: -0.503566, C2 fake: 0.502416], [G loss: 0.008649, mse: 0.008812]\n",
      "Epoch 71/101\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(Z,BATCH_SIZE,train_dataset, epochs, scaler, scaled,X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict from the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the labels of the data values on the basis of the trained model.\n",
    "#predicted_values = aae.decoder.predict(aae.encoder(X_train_scaled))\n",
    "#sampling from the latent space without prediction\n",
    "latent_values = tf.random.normal([1000, Z])\n",
    "\n",
    "#predict the labels of the data values on the basis of the trained model.\n",
    "predicted_values = aae.decoder.predict(latent_values)\n",
    "\n",
    "\n",
    "if scaled == '-1-1':\n",
    "    predicted_values[:,:]=(predicted_values[:,:])\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    \n",
    "\n",
    "if n_features==3:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    print(\"latent_space:\",Z)\n",
    "    print(\"BATCH_SIZE:\",BATCH_SIZE)\n",
    "    print(\"epochs:\",epochs)\n",
    "    \n",
    "\n",
    "    ab = plt.subplot(projection='3d')\n",
    "    ab.scatter(predicted_values[:,0],predicted_values[:,1],predicted_values[:,2])\n",
    "    ab.set_ylabel('Y')\n",
    "    ab.set_zlabel('Z')\n",
    "    ab.set_xlabel('X')\n",
    "    \n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(predicted_values[:,1],predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,0]>=-0.8-0.05,predicted_values[:,0]<=-0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,0]>=0.0-0.05,predicted_values[:,0]<=0.0+0.05),predicted_values[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,0]>=0.8-0.05,predicted_values[:,0]<=0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,1]>=0.2-0.05,predicted_values[:,1]<=0.2+0.05),predicted_values[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,1]>=0.5-0.05,predicted_values[:,1]<=0.5+0.05),predicted_values[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,1]>=0.8-0.05,predicted_values[:,1]<=0.8+0.05),predicted_values[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input = [-3,-1,1,3]\n",
    "n_points = 400\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//4, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//4, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//4, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//4, n_features), x_input[3])\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4))\n",
    "\n",
    "input_test = predictthis.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated = aae.generator.predict(input_test)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    print(\"latent_space=\",latent_space)\n",
    "    print(\"Epochs=\",epochs)\n",
    "    print(\"BATCH_SIZE=\",BATCH_SIZE)\n",
    "    print(\"use_bias=\",use_bias)\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,label=\"Sample Data\")\n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
