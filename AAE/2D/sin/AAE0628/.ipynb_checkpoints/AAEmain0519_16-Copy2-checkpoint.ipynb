{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"sinus\" #sinus, helix\n",
    "n_instance = 1000\n",
    "n_features = 2\n",
    "Z=40\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'\n",
    "nodes=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "#export_excel(X_train, 'Dataset/X_train')\n",
    "#export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder:\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           48          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 16)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            136         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8)            32          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 8)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40)           360         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 40)           360         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 40)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,000\n",
      "Trainable params: 952\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "Decoder:\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 2,242\n",
      "Trainable params: 2,194\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Discriminator:\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                1680      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                1620      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 5,801\n",
      "Trainable params: 5,401\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=network16.build_encoder(Z, nodes, n_features)\n",
    "print(\"Encoder:\\n\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "decoder=network16.build_decoder(Z,nodes, n_features)\n",
    "print(\"Decoder:\\n\")\n",
    "decoder.summary()\n",
    "\n",
    "discriminator=network16.build_discriminator(Z)\n",
    "print(\"Discriminator:\\n\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model16\n",
    "\n",
    "GANorWGAN='WGAN'\n",
    "epochs = 10001\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE_Model16.AAE(Z, n_features, BATCH_SIZE,GANorWGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (1000, 2)\n",
      "Cycles:  1\n",
      "X_train (1000, 1)\n",
      "y_train (1000, 1)\n",
      "X_train_scaled (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10001\n",
      "[C1 valid: 0.490551, C2 fake: 0.000000], [G loss: 1.490423, mse: 0.981204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyhua/OneDrive - Imperial College London/INHALE Code/Lily/AAE/AAE05019/AAE_Model16.py:197: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AAE/Models/encoder_40_10001/assets\n",
      "INFO:tensorflow:Assets written to: AAE/Models/decoder_40_10001/assets\n",
      "INFO:tensorflow:Assets written to: AAE/Models/discriminator_40_10001/assets\n",
      "Epoch 2/10001\n",
      "[C1 valid: 0.486835, C2 fake: 0.000000], [G loss: 1.480888, mse: 0.980613]\n",
      "Epoch 3/10001\n",
      "[C1 valid: 0.483770, C2 fake: 0.000000], [G loss: 1.402903, mse: 0.910281]\n",
      "Epoch 4/10001\n",
      "[C1 valid: 0.479838, C2 fake: 0.000000], [G loss: 1.417697, mse: 0.933690]\n",
      "Epoch 5/10001\n",
      "[C1 valid: 0.476832, C2 fake: 0.000000], [G loss: 1.434341, mse: 0.957526]\n",
      "Epoch 6/10001\n",
      "[C1 valid: 0.471843, C2 fake: 0.000000], [G loss: 1.364863, mse: 0.898606]\n",
      "Epoch 7/10001\n",
      "[C1 valid: 0.467419, C2 fake: 0.000000], [G loss: 1.355400, mse: 0.899077]\n",
      "Epoch 8/10001\n",
      "[C1 valid: 0.462527, C2 fake: 0.000000], [G loss: 1.352457, mse: 0.905753]\n",
      "Epoch 9/10001\n",
      "[C1 valid: 0.457735, C2 fake: 0.000000], [G loss: 1.320381, mse: 0.882677]\n",
      "Epoch 10/10001\n",
      "[C1 valid: 0.452467, C2 fake: 0.000000], [G loss: 1.303630, mse: 0.870730]\n",
      "Epoch 11/10001\n",
      "[C1 valid: 0.448856, C2 fake: 0.000000], [G loss: 1.290973, mse: 0.869315]\n",
      "Epoch 12/10001\n",
      "[C1 valid: 0.441993, C2 fake: 0.000000], [G loss: 1.233912, mse: 0.826170]\n",
      "Epoch 13/10001\n",
      "[C1 valid: 0.436910, C2 fake: 0.000000], [G loss: 1.212597, mse: 0.814847]\n",
      "Epoch 14/10001\n",
      "[C1 valid: 0.432793, C2 fake: 0.000000], [G loss: 1.179402, mse: 0.791462]\n",
      "Epoch 15/10001\n",
      "[C1 valid: 0.428105, C2 fake: 0.000000], [G loss: 1.153365, mse: 0.776756]\n",
      "Epoch 16/10001\n",
      "[C1 valid: 0.421976, C2 fake: 0.000000], [G loss: 1.103885, mse: 0.730877]\n",
      "Epoch 17/10001\n",
      "[C1 valid: 0.415092, C2 fake: 0.000000], [G loss: 1.090097, mse: 0.724272]\n",
      "Epoch 18/10001\n",
      "[C1 valid: 0.410623, C2 fake: 0.000000], [G loss: 1.079350, mse: 0.730449]\n",
      "Epoch 19/10001\n",
      "[C1 valid: 0.407711, C2 fake: 0.000000], [G loss: 1.051451, mse: 0.715117]\n",
      "Epoch 20/10001\n",
      "[C1 valid: 0.400057, C2 fake: 0.000000], [G loss: 0.984886, mse: 0.658156]\n",
      "Epoch 21/10001\n",
      "[C1 valid: 0.395617, C2 fake: 0.000000], [G loss: 0.978060, mse: 0.650447]\n",
      "Epoch 22/10001\n",
      "[C1 valid: 0.390420, C2 fake: 0.000000], [G loss: 0.966217, mse: 0.653536]\n",
      "Epoch 23/10001\n",
      "[C1 valid: 0.388237, C2 fake: 0.000000], [G loss: 0.929260, mse: 0.629368]\n",
      "Epoch 24/10001\n",
      "[C1 valid: 0.380175, C2 fake: 0.000000], [G loss: 0.890722, mse: 0.596206]\n",
      "Epoch 25/10001\n",
      "[C1 valid: 0.376503, C2 fake: 0.000000], [G loss: 0.911027, mse: 0.605559]\n",
      "Epoch 26/10001\n",
      "[C1 valid: 0.372278, C2 fake: 0.000000], [G loss: 0.865767, mse: 0.588211]\n",
      "Epoch 27/10001\n",
      "[C1 valid: 0.367761, C2 fake: 0.000000], [G loss: 0.878614, mse: 0.595589]\n",
      "Epoch 28/10001\n",
      "[C1 valid: 0.362094, C2 fake: 0.000000], [G loss: 0.793802, mse: 0.523122]\n",
      "Epoch 29/10001\n",
      "[C1 valid: 0.357775, C2 fake: 0.000000], [G loss: 0.808298, mse: 0.540031]\n",
      "Epoch 30/10001\n",
      "[C1 valid: 0.354418, C2 fake: 0.000000], [G loss: 0.776766, mse: 0.519886]\n",
      "Epoch 31/10001\n",
      "[C1 valid: 0.350024, C2 fake: 0.000000], [G loss: 0.790116, mse: 0.532925]\n",
      "Epoch 32/10001\n",
      "[C1 valid: 0.344130, C2 fake: 0.000000], [G loss: 0.719342, mse: 0.473348]\n",
      "Epoch 33/10001\n",
      "[C1 valid: 0.340947, C2 fake: 0.000000], [G loss: 0.715004, mse: 0.473270]\n",
      "Epoch 34/10001\n",
      "[C1 valid: 0.336657, C2 fake: 0.000000], [G loss: 0.725995, mse: 0.476666]\n",
      "Epoch 35/10001\n",
      "[C1 valid: 0.331311, C2 fake: 0.000000], [G loss: 0.690375, mse: 0.448536]\n",
      "Epoch 36/10001\n",
      "[C1 valid: 0.328339, C2 fake: 0.000000], [G loss: 0.667094, mse: 0.437676]\n",
      "Epoch 37/10001\n",
      "[C1 valid: 0.320913, C2 fake: 0.000000], [G loss: 0.654999, mse: 0.429734]\n",
      "Epoch 38/10001\n",
      "[C1 valid: 0.319926, C2 fake: 0.000000], [G loss: 0.618799, mse: 0.400749]\n",
      "Epoch 39/10001\n",
      "[C1 valid: 0.317464, C2 fake: 0.000000], [G loss: 0.602972, mse: 0.398190]\n",
      "Epoch 40/10001\n",
      "[C1 valid: 0.313996, C2 fake: 0.000000], [G loss: 0.590796, mse: 0.384582]\n",
      "Epoch 41/10001\n",
      "[C1 valid: 0.311400, C2 fake: 0.000000], [G loss: 0.587100, mse: 0.382232]\n",
      "Epoch 42/10001\n",
      "[C1 valid: 0.306303, C2 fake: 0.000000], [G loss: 0.593075, mse: 0.387379]\n",
      "Epoch 43/10001\n",
      "[C1 valid: 0.306355, C2 fake: 0.000000], [G loss: 0.565581, mse: 0.365128]\n",
      "Epoch 44/10001\n",
      "[C1 valid: 0.302256, C2 fake: 0.000000], [G loss: 0.524199, mse: 0.345151]\n",
      "Epoch 45/10001\n",
      "[C1 valid: 0.298409, C2 fake: 0.000000], [G loss: 0.516573, mse: 0.337439]\n",
      "Epoch 46/10001\n",
      "[C1 valid: 0.293132, C2 fake: 0.000000], [G loss: 0.538876, mse: 0.356330]\n",
      "Epoch 47/10001\n",
      "[C1 valid: 0.290767, C2 fake: 0.000000], [G loss: 0.530576, mse: 0.342658]\n",
      "Epoch 48/10001\n",
      "[C1 valid: 0.288802, C2 fake: 0.000000], [G loss: 0.497397, mse: 0.327126]\n",
      "Epoch 49/10001\n",
      "[C1 valid: 0.286685, C2 fake: 0.000000], [G loss: 0.490716, mse: 0.320515]\n",
      "Epoch 50/10001\n",
      "[C1 valid: 0.281210, C2 fake: 0.000000], [G loss: 0.488600, mse: 0.313358]\n",
      "Epoch 51/10001\n",
      "[C1 valid: 0.277578, C2 fake: 0.000000], [G loss: 0.484917, mse: 0.312482]\n",
      "Epoch 52/10001\n",
      "[C1 valid: 0.277911, C2 fake: 0.000000], [G loss: 0.479609, mse: 0.309080]\n",
      "Epoch 53/10001\n",
      "[C1 valid: 0.273910, C2 fake: 0.000000], [G loss: 0.477889, mse: 0.319191]\n",
      "Epoch 54/10001\n",
      "[C1 valid: 0.270268, C2 fake: 0.000000], [G loss: 0.453648, mse: 0.300330]\n",
      "Epoch 55/10001\n",
      "[C1 valid: 0.268641, C2 fake: 0.000000], [G loss: 0.433636, mse: 0.279685]\n",
      "Epoch 56/10001\n",
      "[C1 valid: 0.265979, C2 fake: 0.000000], [G loss: 0.430954, mse: 0.293769]\n",
      "Epoch 57/10001\n",
      "[C1 valid: 0.264883, C2 fake: 0.000000], [G loss: 0.406862, mse: 0.265322]\n",
      "Epoch 58/10001\n",
      "[C1 valid: 0.259685, C2 fake: 0.000000], [G loss: 0.414850, mse: 0.284346]\n",
      "Epoch 59/10001\n",
      "[C1 valid: 0.257350, C2 fake: 0.000000], [G loss: 0.433365, mse: 0.274454]\n",
      "Epoch 60/10001\n",
      "[C1 valid: 0.256509, C2 fake: 0.000000], [G loss: 0.390236, mse: 0.254665]\n",
      "Epoch 61/10001\n",
      "[C1 valid: 0.252428, C2 fake: 0.000000], [G loss: 0.398522, mse: 0.262042]\n",
      "Epoch 62/10001\n",
      "[C1 valid: 0.251116, C2 fake: 0.000000], [G loss: 0.395698, mse: 0.241644]\n",
      "Epoch 63/10001\n",
      "[C1 valid: 0.249191, C2 fake: 0.000000], [G loss: 0.382443, mse: 0.248158]\n",
      "Epoch 64/10001\n",
      "[C1 valid: 0.244875, C2 fake: 0.000000], [G loss: 0.384581, mse: 0.258517]\n",
      "Epoch 65/10001\n",
      "[C1 valid: 0.240925, C2 fake: 0.000000], [G loss: 0.377017, mse: 0.240472]\n",
      "Epoch 66/10001\n",
      "[C1 valid: 0.240496, C2 fake: 0.000000], [G loss: 0.361106, mse: 0.234183]\n",
      "Epoch 67/10001\n",
      "[C1 valid: 0.242674, C2 fake: 0.000000], [G loss: 0.368856, mse: 0.244940]\n",
      "Epoch 68/10001\n",
      "[C1 valid: 0.237361, C2 fake: 0.000000], [G loss: 0.366112, mse: 0.228527]\n",
      "Epoch 69/10001\n",
      "[C1 valid: 0.233986, C2 fake: 0.000000], [G loss: 0.342468, mse: 0.225420]\n",
      "Epoch 70/10001\n",
      "[C1 valid: 0.234939, C2 fake: 0.000000], [G loss: 0.328289, mse: 0.213631]\n",
      "Epoch 71/10001\n",
      "[C1 valid: 0.235260, C2 fake: 0.000000], [G loss: 0.335873, mse: 0.215709]\n",
      "Epoch 72/10001\n",
      "[C1 valid: 0.233767, C2 fake: 0.000000], [G loss: 0.335510, mse: 0.212314]\n",
      "Epoch 73/10001\n",
      "[C1 valid: 0.228077, C2 fake: 0.000000], [G loss: 0.333644, mse: 0.218147]\n",
      "Epoch 74/10001\n",
      "[C1 valid: 0.226922, C2 fake: 0.000000], [G loss: 0.323338, mse: 0.216723]\n",
      "Epoch 75/10001\n",
      "[C1 valid: 0.220016, C2 fake: 0.000000], [G loss: 0.309997, mse: 0.204433]\n",
      "Epoch 76/10001\n",
      "[C1 valid: 0.220447, C2 fake: 0.000000], [G loss: 0.301011, mse: 0.199836]\n",
      "Epoch 77/10001\n",
      "[C1 valid: 0.217794, C2 fake: 0.000000], [G loss: 0.314320, mse: 0.203831]\n",
      "Epoch 78/10001\n",
      "[C1 valid: 0.218029, C2 fake: 0.000000], [G loss: 0.307534, mse: 0.205347]\n",
      "Epoch 79/10001\n",
      "[C1 valid: 0.218180, C2 fake: 0.000000], [G loss: 0.304579, mse: 0.194383]\n",
      "Epoch 80/10001\n",
      "[C1 valid: 0.214907, C2 fake: 0.000000], [G loss: 0.296837, mse: 0.187802]\n",
      "Epoch 81/10001\n",
      "[C1 valid: 0.210168, C2 fake: 0.000000], [G loss: 0.304360, mse: 0.190344]\n",
      "Epoch 82/10001\n",
      "[C1 valid: 0.209416, C2 fake: 0.000000], [G loss: 0.299420, mse: 0.200469]\n",
      "Epoch 83/10001\n",
      "[C1 valid: 0.211619, C2 fake: 0.000000], [G loss: 0.293156, mse: 0.190706]\n",
      "Epoch 84/10001\n",
      "[C1 valid: 0.205516, C2 fake: 0.000000], [G loss: 0.280393, mse: 0.181712]\n",
      "Epoch 85/10001\n",
      "[C1 valid: 0.207270, C2 fake: 0.000000], [G loss: 0.283375, mse: 0.186687]\n",
      "Epoch 86/10001\n",
      "[C1 valid: 0.201817, C2 fake: 0.000000], [G loss: 0.274801, mse: 0.182393]\n",
      "Epoch 87/10001\n",
      "[C1 valid: 0.206421, C2 fake: 0.000000], [G loss: 0.272401, mse: 0.182964]\n",
      "Epoch 88/10001\n",
      "[C1 valid: 0.199315, C2 fake: 0.000000], [G loss: 0.277121, mse: 0.177688]\n",
      "Epoch 89/10001\n",
      "[C1 valid: 0.200423, C2 fake: 0.000000], [G loss: 0.255608, mse: 0.176593]\n",
      "Epoch 90/10001\n",
      "[C1 valid: 0.197420, C2 fake: 0.000000], [G loss: 0.253762, mse: 0.172665]\n",
      "Epoch 91/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.196865, C2 fake: 0.000000], [G loss: 0.244914, mse: 0.163549]\n",
      "Epoch 92/10001\n",
      "[C1 valid: 0.192849, C2 fake: 0.000000], [G loss: 0.250863, mse: 0.166797]\n",
      "Epoch 93/10001\n",
      "[C1 valid: 0.194387, C2 fake: 0.000000], [G loss: 0.266387, mse: 0.165452]\n",
      "Epoch 94/10001\n",
      "[C1 valid: 0.189387, C2 fake: 0.000000], [G loss: 0.243498, mse: 0.165213]\n",
      "Epoch 95/10001\n",
      "[C1 valid: 0.189106, C2 fake: 0.000000], [G loss: 0.255875, mse: 0.169427]\n",
      "Epoch 96/10001\n",
      "[C1 valid: 0.186727, C2 fake: 0.000000], [G loss: 0.248621, mse: 0.166311]\n",
      "Epoch 97/10001\n",
      "[C1 valid: 0.188354, C2 fake: 0.000000], [G loss: 0.253071, mse: 0.158851]\n",
      "Epoch 98/10001\n",
      "[C1 valid: 0.185930, C2 fake: 0.000000], [G loss: 0.245009, mse: 0.164048]\n",
      "Epoch 99/10001\n",
      "[C1 valid: 0.184185, C2 fake: 0.000000], [G loss: 0.234854, mse: 0.151473]\n",
      "Epoch 100/10001\n",
      "[C1 valid: 0.186947, C2 fake: 0.000000], [G loss: 0.232790, mse: 0.162317]\n",
      "Epoch 101/10001\n",
      "[C1 valid: 0.184635, C2 fake: 0.000000], [G loss: 0.237188, mse: 0.154430]\n",
      "Epoch 102/10001\n",
      "[C1 valid: 0.183921, C2 fake: 0.000000], [G loss: 0.251180, mse: 0.167379]\n",
      "Epoch 103/10001\n",
      "[C1 valid: 0.179670, C2 fake: 0.000000], [G loss: 0.224112, mse: 0.152487]\n",
      "Epoch 104/10001\n",
      "[C1 valid: 0.176236, C2 fake: 0.000000], [G loss: 0.234684, mse: 0.155445]\n",
      "Epoch 105/10001\n",
      "[C1 valid: 0.176364, C2 fake: 0.000000], [G loss: 0.246113, mse: 0.158101]\n",
      "Epoch 106/10001\n",
      "[C1 valid: 0.176424, C2 fake: 0.000000], [G loss: 0.217361, mse: 0.151527]\n",
      "Epoch 107/10001\n",
      "[C1 valid: 0.175569, C2 fake: 0.000000], [G loss: 0.208113, mse: 0.142654]\n",
      "Epoch 108/10001\n",
      "[C1 valid: 0.173895, C2 fake: 0.000000], [G loss: 0.210005, mse: 0.144900]\n",
      "Epoch 109/10001\n",
      "[C1 valid: 0.167268, C2 fake: 0.000000], [G loss: 0.216930, mse: 0.150230]\n",
      "Epoch 110/10001\n",
      "[C1 valid: 0.167957, C2 fake: 0.000000], [G loss: 0.204013, mse: 0.137649]\n",
      "Epoch 111/10001\n",
      "[C1 valid: 0.169731, C2 fake: 0.000000], [G loss: 0.231798, mse: 0.147698]\n",
      "Epoch 112/10001\n",
      "[C1 valid: 0.169967, C2 fake: 0.000000], [G loss: 0.205111, mse: 0.144955]\n",
      "Epoch 113/10001\n",
      "[C1 valid: 0.167384, C2 fake: 0.000000], [G loss: 0.205523, mse: 0.138751]\n",
      "Epoch 114/10001\n",
      "[C1 valid: 0.166328, C2 fake: 0.000000], [G loss: 0.195923, mse: 0.132190]\n",
      "Epoch 115/10001\n",
      "[C1 valid: 0.161801, C2 fake: 0.000000], [G loss: 0.206487, mse: 0.134776]\n",
      "Epoch 116/10001\n",
      "[C1 valid: 0.163493, C2 fake: 0.000000], [G loss: 0.213512, mse: 0.148659]\n",
      "Epoch 117/10001\n",
      "[C1 valid: 0.160565, C2 fake: 0.000000], [G loss: 0.207012, mse: 0.136615]\n",
      "Epoch 118/10001\n",
      "[C1 valid: 0.159911, C2 fake: 0.000000], [G loss: 0.210315, mse: 0.143784]\n",
      "Epoch 119/10001\n",
      "[C1 valid: 0.164295, C2 fake: 0.000000], [G loss: 0.210790, mse: 0.141857]\n",
      "Epoch 120/10001\n",
      "[C1 valid: 0.156637, C2 fake: 0.000000], [G loss: 0.199342, mse: 0.133973]\n",
      "Epoch 121/10001\n",
      "[C1 valid: 0.154911, C2 fake: 0.000000], [G loss: 0.193199, mse: 0.136760]\n",
      "Epoch 122/10001\n",
      "[C1 valid: 0.157136, C2 fake: 0.000000], [G loss: 0.193279, mse: 0.133551]\n",
      "Epoch 123/10001\n",
      "[C1 valid: 0.153268, C2 fake: 0.000000], [G loss: 0.190980, mse: 0.132776]\n",
      "Epoch 124/10001\n",
      "[C1 valid: 0.151618, C2 fake: 0.000000], [G loss: 0.185233, mse: 0.128695]\n",
      "Epoch 125/10001\n",
      "[C1 valid: 0.153081, C2 fake: 0.000000], [G loss: 0.193533, mse: 0.134838]\n",
      "Epoch 126/10001\n",
      "[C1 valid: 0.150787, C2 fake: 0.000000], [G loss: 0.183269, mse: 0.131635]\n",
      "Epoch 127/10001\n",
      "[C1 valid: 0.151825, C2 fake: 0.000000], [G loss: 0.181839, mse: 0.122949]\n",
      "Epoch 128/10001\n",
      "[C1 valid: 0.149066, C2 fake: 0.000000], [G loss: 0.185541, mse: 0.127185]\n",
      "Epoch 129/10001\n",
      "[C1 valid: 0.148017, C2 fake: 0.000000], [G loss: 0.189716, mse: 0.126161]\n",
      "Epoch 130/10001\n",
      "[C1 valid: 0.150085, C2 fake: 0.000000], [G loss: 0.170505, mse: 0.119907]\n",
      "Epoch 131/10001\n",
      "[C1 valid: 0.143740, C2 fake: 0.000000], [G loss: 0.185255, mse: 0.126359]\n",
      "Epoch 132/10001\n",
      "[C1 valid: 0.146829, C2 fake: 0.000000], [G loss: 0.174281, mse: 0.118665]\n",
      "Epoch 133/10001\n",
      "[C1 valid: 0.145393, C2 fake: 0.000000], [G loss: 0.178241, mse: 0.123195]\n",
      "Epoch 134/10001\n",
      "[C1 valid: 0.143960, C2 fake: 0.000000], [G loss: 0.175160, mse: 0.120386]\n",
      "Epoch 135/10001\n",
      "[C1 valid: 0.142073, C2 fake: 0.000000], [G loss: 0.177298, mse: 0.115774]\n",
      "Epoch 136/10001\n",
      "[C1 valid: 0.141414, C2 fake: 0.000000], [G loss: 0.174705, mse: 0.119738]\n",
      "Epoch 137/10001\n",
      "[C1 valid: 0.141177, C2 fake: 0.000000], [G loss: 0.171291, mse: 0.119572]\n",
      "Epoch 138/10001\n",
      "[C1 valid: 0.136680, C2 fake: 0.000000], [G loss: 0.164703, mse: 0.112884]\n",
      "Epoch 139/10001\n",
      "[C1 valid: 0.136286, C2 fake: 0.000000], [G loss: 0.181345, mse: 0.124430]\n",
      "Epoch 140/10001\n",
      "[C1 valid: 0.136430, C2 fake: 0.000000], [G loss: 0.168560, mse: 0.112930]\n",
      "Epoch 141/10001\n",
      "[C1 valid: 0.135032, C2 fake: 0.000000], [G loss: 0.160889, mse: 0.112625]\n",
      "Epoch 142/10001\n",
      "[C1 valid: 0.132360, C2 fake: 0.000000], [G loss: 0.170229, mse: 0.120856]\n",
      "Epoch 143/10001\n",
      "[C1 valid: 0.133527, C2 fake: 0.000000], [G loss: 0.163073, mse: 0.115573]\n",
      "Epoch 144/10001\n",
      "[C1 valid: 0.133688, C2 fake: 0.000000], [G loss: 0.156606, mse: 0.104055]\n",
      "Epoch 145/10001\n",
      "[C1 valid: 0.132391, C2 fake: 0.000000], [G loss: 0.155189, mse: 0.105604]\n",
      "Epoch 146/10001\n",
      "[C1 valid: 0.131599, C2 fake: 0.000000], [G loss: 0.164202, mse: 0.110191]\n",
      "Epoch 147/10001\n",
      "[C1 valid: 0.127625, C2 fake: 0.000000], [G loss: 0.148627, mse: 0.104521]\n",
      "Epoch 148/10001\n",
      "[C1 valid: 0.131301, C2 fake: 0.000000], [G loss: 0.160690, mse: 0.111637]\n",
      "Epoch 149/10001\n",
      "[C1 valid: 0.129458, C2 fake: 0.000000], [G loss: 0.159406, mse: 0.108457]\n",
      "Epoch 150/10001\n",
      "[C1 valid: 0.128683, C2 fake: 0.000000], [G loss: 0.153164, mse: 0.104701]\n",
      "Epoch 151/10001\n",
      "[C1 valid: 0.128167, C2 fake: 0.000000], [G loss: 0.153732, mse: 0.107498]\n",
      "Epoch 152/10001\n",
      "[C1 valid: 0.127324, C2 fake: 0.000000], [G loss: 0.146172, mse: 0.101737]\n",
      "Epoch 153/10001\n",
      "[C1 valid: 0.123301, C2 fake: 0.000000], [G loss: 0.157017, mse: 0.106111]\n",
      "Epoch 154/10001\n",
      "[C1 valid: 0.125899, C2 fake: 0.000000], [G loss: 0.154766, mse: 0.108669]\n",
      "Epoch 155/10001\n",
      "[C1 valid: 0.121462, C2 fake: 0.000000], [G loss: 0.154954, mse: 0.104381]\n",
      "Epoch 156/10001\n",
      "[C1 valid: 0.121253, C2 fake: 0.000000], [G loss: 0.145226, mse: 0.102458]\n",
      "Epoch 157/10001\n",
      "[C1 valid: 0.119027, C2 fake: 0.000000], [G loss: 0.151447, mse: 0.106032]\n",
      "Epoch 158/10001\n",
      "[C1 valid: 0.121792, C2 fake: 0.000000], [G loss: 0.150888, mse: 0.105207]\n",
      "Epoch 159/10001\n",
      "[C1 valid: 0.121254, C2 fake: 0.000000], [G loss: 0.142175, mse: 0.097927]\n",
      "Epoch 160/10001\n",
      "[C1 valid: 0.118159, C2 fake: 0.000000], [G loss: 0.134830, mse: 0.094276]\n",
      "Epoch 161/10001\n",
      "[C1 valid: 0.119496, C2 fake: 0.000000], [G loss: 0.153629, mse: 0.110829]\n",
      "Epoch 162/10001\n",
      "[C1 valid: 0.117438, C2 fake: 0.000000], [G loss: 0.145273, mse: 0.099267]\n",
      "Epoch 163/10001\n",
      "[C1 valid: 0.114696, C2 fake: 0.000000], [G loss: 0.137767, mse: 0.096456]\n",
      "Epoch 164/10001\n",
      "[C1 valid: 0.115722, C2 fake: 0.000000], [G loss: 0.145533, mse: 0.098764]\n",
      "Epoch 165/10001\n",
      "[C1 valid: 0.113560, C2 fake: 0.000000], [G loss: 0.148815, mse: 0.104536]\n",
      "Epoch 166/10001\n",
      "[C1 valid: 0.113681, C2 fake: 0.000000], [G loss: 0.141710, mse: 0.099112]\n",
      "Epoch 167/10001\n",
      "[C1 valid: 0.114971, C2 fake: 0.000000], [G loss: 0.138660, mse: 0.099256]\n",
      "Epoch 168/10001\n",
      "[C1 valid: 0.111121, C2 fake: 0.000000], [G loss: 0.144809, mse: 0.103528]\n",
      "Epoch 169/10001\n",
      "[C1 valid: 0.112888, C2 fake: 0.000000], [G loss: 0.134002, mse: 0.093200]\n",
      "Epoch 170/10001\n",
      "[C1 valid: 0.110553, C2 fake: 0.000000], [G loss: 0.127145, mse: 0.084580]\n",
      "Epoch 171/10001\n",
      "[C1 valid: 0.108649, C2 fake: 0.000000], [G loss: 0.140087, mse: 0.098529]\n",
      "Epoch 172/10001\n",
      "[C1 valid: 0.109288, C2 fake: 0.000000], [G loss: 0.137951, mse: 0.097768]\n",
      "Epoch 173/10001\n",
      "[C1 valid: 0.104682, C2 fake: 0.000000], [G loss: 0.127320, mse: 0.091745]\n",
      "Epoch 174/10001\n",
      "[C1 valid: 0.108557, C2 fake: 0.000000], [G loss: 0.132864, mse: 0.095256]\n",
      "Epoch 175/10001\n",
      "[C1 valid: 0.106278, C2 fake: 0.000000], [G loss: 0.138951, mse: 0.095993]\n",
      "Epoch 176/10001\n",
      "[C1 valid: 0.104252, C2 fake: 0.000000], [G loss: 0.130424, mse: 0.090407]\n",
      "Epoch 177/10001\n",
      "[C1 valid: 0.107672, C2 fake: 0.000000], [G loss: 0.134157, mse: 0.094692]\n",
      "Epoch 178/10001\n",
      "[C1 valid: 0.103831, C2 fake: 0.000000], [G loss: 0.128154, mse: 0.090623]\n",
      "Epoch 179/10001\n",
      "[C1 valid: 0.101557, C2 fake: 0.000000], [G loss: 0.131209, mse: 0.094946]\n",
      "Epoch 180/10001\n",
      "[C1 valid: 0.104225, C2 fake: 0.000000], [G loss: 0.129701, mse: 0.093874]\n",
      "Epoch 181/10001\n",
      "[C1 valid: 0.102040, C2 fake: 0.000000], [G loss: 0.127951, mse: 0.088084]\n",
      "Epoch 182/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.101140, C2 fake: 0.000000], [G loss: 0.121042, mse: 0.087777]\n",
      "Epoch 183/10001\n",
      "[C1 valid: 0.098237, C2 fake: 0.000000], [G loss: 0.126128, mse: 0.090588]\n",
      "Epoch 184/10001\n",
      "[C1 valid: 0.100199, C2 fake: 0.000000], [G loss: 0.125984, mse: 0.086035]\n",
      "Epoch 185/10001\n",
      "[C1 valid: 0.100200, C2 fake: 0.000000], [G loss: 0.130825, mse: 0.089055]\n",
      "Epoch 186/10001\n",
      "[C1 valid: 0.100554, C2 fake: 0.000000], [G loss: 0.123109, mse: 0.087800]\n",
      "Epoch 187/10001\n",
      "[C1 valid: 0.098838, C2 fake: 0.000000], [G loss: 0.123919, mse: 0.085609]\n",
      "Epoch 188/10001\n",
      "[C1 valid: 0.096522, C2 fake: 0.000000], [G loss: 0.124971, mse: 0.084434]\n",
      "Epoch 189/10001\n",
      "[C1 valid: 0.095228, C2 fake: 0.000000], [G loss: 0.115945, mse: 0.082732]\n",
      "Epoch 190/10001\n",
      "[C1 valid: 0.095849, C2 fake: 0.000000], [G loss: 0.118888, mse: 0.081885]\n",
      "Epoch 191/10001\n",
      "[C1 valid: 0.095232, C2 fake: 0.000000], [G loss: 0.116342, mse: 0.082466]\n",
      "Epoch 192/10001\n",
      "[C1 valid: 0.094612, C2 fake: 0.000000], [G loss: 0.115308, mse: 0.080501]\n",
      "Epoch 193/10001\n",
      "[C1 valid: 0.094250, C2 fake: 0.000000], [G loss: 0.114291, mse: 0.077889]\n",
      "Epoch 194/10001\n",
      "[C1 valid: 0.091240, C2 fake: 0.000000], [G loss: 0.119562, mse: 0.082998]\n",
      "Epoch 195/10001\n",
      "[C1 valid: 0.093949, C2 fake: 0.000000], [G loss: 0.116830, mse: 0.082336]\n",
      "Epoch 196/10001\n",
      "[C1 valid: 0.091668, C2 fake: 0.000000], [G loss: 0.111711, mse: 0.077908]\n",
      "Epoch 197/10001\n",
      "[C1 valid: 0.091847, C2 fake: 0.000000], [G loss: 0.118720, mse: 0.083509]\n",
      "Epoch 198/10001\n",
      "[C1 valid: 0.089235, C2 fake: 0.000000], [G loss: 0.116291, mse: 0.084451]\n",
      "Epoch 199/10001\n",
      "[C1 valid: 0.090553, C2 fake: 0.000000], [G loss: 0.115362, mse: 0.082549]\n",
      "Epoch 200/10001\n",
      "[C1 valid: 0.088598, C2 fake: 0.000000], [G loss: 0.115795, mse: 0.081507]\n",
      "Epoch 201/10001\n",
      "[C1 valid: 0.089395, C2 fake: 0.000000], [G loss: 0.113566, mse: 0.077966]\n",
      "Epoch 202/10001\n",
      "[C1 valid: 0.090833, C2 fake: 0.000000], [G loss: 0.110623, mse: 0.078337]\n",
      "Epoch 203/10001\n",
      "[C1 valid: 0.087477, C2 fake: 0.000000], [G loss: 0.117567, mse: 0.081643]\n",
      "Epoch 204/10001\n",
      "[C1 valid: 0.088418, C2 fake: 0.000000], [G loss: 0.113181, mse: 0.082526]\n",
      "Epoch 205/10001\n",
      "[C1 valid: 0.085388, C2 fake: 0.000000], [G loss: 0.115533, mse: 0.080654]\n",
      "Epoch 206/10001\n",
      "[C1 valid: 0.084510, C2 fake: 0.000000], [G loss: 0.113651, mse: 0.078574]\n",
      "Epoch 207/10001\n",
      "[C1 valid: 0.086962, C2 fake: 0.000000], [G loss: 0.111884, mse: 0.078883]\n",
      "Epoch 208/10001\n",
      "[C1 valid: 0.083365, C2 fake: 0.000000], [G loss: 0.114906, mse: 0.079425]\n",
      "Epoch 209/10001\n",
      "[C1 valid: 0.082783, C2 fake: 0.000000], [G loss: 0.106083, mse: 0.075560]\n",
      "Epoch 210/10001\n",
      "[C1 valid: 0.082558, C2 fake: 0.000000], [G loss: 0.106685, mse: 0.074854]\n",
      "Epoch 211/10001\n",
      "[C1 valid: 0.078810, C2 fake: 0.000000], [G loss: 0.103051, mse: 0.071799]\n",
      "Epoch 212/10001\n",
      "[C1 valid: 0.081106, C2 fake: 0.000000], [G loss: 0.104915, mse: 0.074641]\n",
      "Epoch 213/10001\n",
      "[C1 valid: 0.080531, C2 fake: 0.000000], [G loss: 0.105693, mse: 0.072622]\n",
      "Epoch 214/10001\n",
      "[C1 valid: 0.080195, C2 fake: 0.000000], [G loss: 0.102210, mse: 0.072292]\n",
      "Epoch 215/10001\n",
      "[C1 valid: 0.080228, C2 fake: 0.000000], [G loss: 0.109152, mse: 0.076963]\n",
      "Epoch 216/10001\n",
      "[C1 valid: 0.077339, C2 fake: 0.000000], [G loss: 0.103829, mse: 0.073178]\n",
      "Epoch 217/10001\n",
      "[C1 valid: 0.077814, C2 fake: 0.000000], [G loss: 0.104713, mse: 0.072850]\n",
      "Epoch 218/10001\n",
      "[C1 valid: 0.078006, C2 fake: 0.000000], [G loss: 0.104559, mse: 0.074166]\n",
      "Epoch 219/10001\n",
      "[C1 valid: 0.077309, C2 fake: 0.000000], [G loss: 0.107582, mse: 0.075347]\n",
      "Epoch 220/10001\n",
      "[C1 valid: 0.078713, C2 fake: 0.000000], [G loss: 0.102414, mse: 0.072807]\n",
      "Epoch 221/10001\n",
      "[C1 valid: 0.076193, C2 fake: 0.000000], [G loss: 0.106186, mse: 0.077750]\n",
      "Epoch 222/10001\n",
      "[C1 valid: 0.074673, C2 fake: 0.000000], [G loss: 0.098895, mse: 0.068829]\n",
      "Epoch 223/10001\n",
      "[C1 valid: 0.077334, C2 fake: 0.000000], [G loss: 0.103337, mse: 0.073370]\n",
      "Epoch 224/10001\n",
      "[C1 valid: 0.073402, C2 fake: 0.000000], [G loss: 0.094986, mse: 0.068328]\n",
      "Epoch 225/10001\n",
      "[C1 valid: 0.074001, C2 fake: 0.000000], [G loss: 0.100780, mse: 0.071729]\n",
      "Epoch 226/10001\n",
      "[C1 valid: 0.073296, C2 fake: 0.000000], [G loss: 0.102350, mse: 0.074004]\n",
      "Epoch 227/10001\n",
      "[C1 valid: 0.071793, C2 fake: 0.000000], [G loss: 0.096338, mse: 0.068372]\n",
      "Epoch 228/10001\n",
      "[C1 valid: 0.073092, C2 fake: 0.000000], [G loss: 0.097192, mse: 0.069458]\n",
      "Epoch 229/10001\n",
      "[C1 valid: 0.071344, C2 fake: 0.000000], [G loss: 0.095755, mse: 0.067775]\n",
      "Epoch 230/10001\n",
      "[C1 valid: 0.072912, C2 fake: 0.000000], [G loss: 0.096284, mse: 0.069765]\n",
      "Epoch 231/10001\n",
      "[C1 valid: 0.072908, C2 fake: 0.000000], [G loss: 0.097399, mse: 0.071351]\n",
      "Epoch 232/10001\n",
      "[C1 valid: 0.071049, C2 fake: 0.000000], [G loss: 0.092959, mse: 0.066180]\n",
      "Epoch 233/10001\n",
      "[C1 valid: 0.069314, C2 fake: 0.000000], [G loss: 0.096590, mse: 0.068404]\n",
      "Epoch 234/10001\n",
      "[C1 valid: 0.071645, C2 fake: 0.000000], [G loss: 0.095039, mse: 0.070679]\n",
      "Epoch 235/10001\n",
      "[C1 valid: 0.070433, C2 fake: 0.000000], [G loss: 0.096307, mse: 0.070189]\n",
      "Epoch 236/10001\n",
      "[C1 valid: 0.069774, C2 fake: 0.000000], [G loss: 0.090951, mse: 0.066636]\n",
      "Epoch 237/10001\n",
      "[C1 valid: 0.068956, C2 fake: 0.000000], [G loss: 0.097492, mse: 0.069675]\n",
      "Epoch 238/10001\n",
      "[C1 valid: 0.068338, C2 fake: 0.000000], [G loss: 0.093185, mse: 0.067928]\n",
      "Epoch 239/10001\n",
      "[C1 valid: 0.067369, C2 fake: 0.000000], [G loss: 0.094134, mse: 0.067944]\n",
      "Epoch 240/10001\n",
      "[C1 valid: 0.067090, C2 fake: 0.000000], [G loss: 0.088896, mse: 0.065537]\n",
      "Epoch 241/10001\n",
      "[C1 valid: 0.066609, C2 fake: 0.000000], [G loss: 0.090980, mse: 0.066454]\n",
      "Epoch 242/10001\n",
      "[C1 valid: 0.063816, C2 fake: 0.000000], [G loss: 0.084361, mse: 0.061386]\n",
      "Epoch 243/10001\n",
      "[C1 valid: 0.065327, C2 fake: 0.000000], [G loss: 0.105227, mse: 0.075996]\n",
      "Epoch 244/10001\n",
      "[C1 valid: 0.065881, C2 fake: 0.000000], [G loss: 0.097630, mse: 0.072349]\n",
      "Epoch 245/10001\n",
      "[C1 valid: 0.064451, C2 fake: 0.000000], [G loss: 0.087649, mse: 0.065887]\n",
      "Epoch 246/10001\n",
      "[C1 valid: 0.063399, C2 fake: 0.000000], [G loss: 0.088406, mse: 0.063736]\n",
      "Epoch 247/10001\n",
      "[C1 valid: 0.063992, C2 fake: 0.000000], [G loss: 0.087679, mse: 0.063940]\n",
      "Epoch 248/10001\n",
      "[C1 valid: 0.064561, C2 fake: 0.000000], [G loss: 0.090362, mse: 0.065385]\n",
      "Epoch 249/10001\n",
      "[C1 valid: 0.065035, C2 fake: 0.000000], [G loss: 0.086936, mse: 0.061303]\n",
      "Epoch 250/10001\n",
      "[C1 valid: 0.062930, C2 fake: 0.000000], [G loss: 0.088764, mse: 0.064606]\n",
      "Epoch 251/10001\n",
      "[C1 valid: 0.062773, C2 fake: 0.000000], [G loss: 0.090602, mse: 0.066713]\n",
      "Epoch 252/10001\n",
      "[C1 valid: 0.063615, C2 fake: 0.000000], [G loss: 0.089797, mse: 0.065846]\n",
      "Epoch 253/10001\n",
      "[C1 valid: 0.062792, C2 fake: 0.000000], [G loss: 0.090300, mse: 0.062557]\n",
      "Epoch 254/10001\n",
      "[C1 valid: 0.059930, C2 fake: 0.000000], [G loss: 0.085669, mse: 0.061549]\n",
      "Epoch 255/10001\n",
      "[C1 valid: 0.061485, C2 fake: 0.000000], [G loss: 0.080665, mse: 0.057724]\n",
      "Epoch 256/10001\n",
      "[C1 valid: 0.059036, C2 fake: 0.000000], [G loss: 0.088834, mse: 0.065049]\n",
      "Epoch 257/10001\n",
      "[C1 valid: 0.058583, C2 fake: 0.000000], [G loss: 0.083648, mse: 0.060839]\n",
      "Epoch 258/10001\n",
      "[C1 valid: 0.058004, C2 fake: 0.000000], [G loss: 0.083348, mse: 0.061304]\n",
      "Epoch 259/10001\n",
      "[C1 valid: 0.060270, C2 fake: 0.000000], [G loss: 0.082047, mse: 0.060496]\n",
      "Epoch 260/10001\n",
      "[C1 valid: 0.061257, C2 fake: 0.000000], [G loss: 0.086196, mse: 0.064336]\n",
      "Epoch 261/10001\n",
      "[C1 valid: 0.057457, C2 fake: 0.000000], [G loss: 0.086622, mse: 0.063479]\n",
      "Epoch 262/10001\n",
      "[C1 valid: 0.058688, C2 fake: 0.000000], [G loss: 0.086545, mse: 0.063027]\n",
      "Epoch 263/10001\n",
      "[C1 valid: 0.057092, C2 fake: 0.000000], [G loss: 0.080802, mse: 0.059812]\n",
      "Epoch 264/10001\n",
      "[C1 valid: 0.056076, C2 fake: 0.000000], [G loss: 0.082089, mse: 0.060564]\n",
      "Epoch 265/10001\n",
      "[C1 valid: 0.053499, C2 fake: 0.000000], [G loss: 0.080793, mse: 0.060585]\n",
      "Epoch 266/10001\n",
      "[C1 valid: 0.055116, C2 fake: 0.000000], [G loss: 0.079339, mse: 0.058111]\n",
      "Epoch 267/10001\n",
      "[C1 valid: 0.054290, C2 fake: 0.000000], [G loss: 0.079541, mse: 0.057728]\n",
      "Epoch 268/10001\n",
      "[C1 valid: 0.052566, C2 fake: 0.000000], [G loss: 0.080849, mse: 0.060646]\n",
      "Epoch 269/10001\n",
      "[C1 valid: 0.054313, C2 fake: 0.000000], [G loss: 0.083508, mse: 0.061050]\n",
      "Epoch 270/10001\n",
      "[C1 valid: 0.053423, C2 fake: 0.000000], [G loss: 0.084551, mse: 0.061410]\n",
      "Epoch 271/10001\n",
      "[C1 valid: 0.054484, C2 fake: 0.000000], [G loss: 0.077800, mse: 0.056694]\n",
      "Epoch 272/10001\n",
      "[C1 valid: 0.056382, C2 fake: 0.000000], [G loss: 0.079531, mse: 0.058924]\n",
      "Epoch 273/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.052588, C2 fake: 0.000000], [G loss: 0.076885, mse: 0.057335]\n",
      "Epoch 274/10001\n",
      "[C1 valid: 0.052953, C2 fake: 0.000000], [G loss: 0.082948, mse: 0.061052]\n",
      "Epoch 275/10001\n",
      "[C1 valid: 0.054131, C2 fake: 0.000000], [G loss: 0.081063, mse: 0.062705]\n",
      "Epoch 276/10001\n",
      "[C1 valid: 0.050094, C2 fake: 0.000000], [G loss: 0.076661, mse: 0.057265]\n",
      "Epoch 277/10001\n",
      "[C1 valid: 0.053876, C2 fake: 0.000000], [G loss: 0.076996, mse: 0.056727]\n",
      "Epoch 278/10001\n",
      "[C1 valid: 0.051261, C2 fake: 0.000000], [G loss: 0.083891, mse: 0.065084]\n",
      "Epoch 279/10001\n",
      "[C1 valid: 0.051630, C2 fake: 0.000000], [G loss: 0.075768, mse: 0.057442]\n",
      "Epoch 280/10001\n",
      "[C1 valid: 0.052460, C2 fake: 0.000000], [G loss: 0.076640, mse: 0.058267]\n",
      "Epoch 281/10001\n",
      "[C1 valid: 0.051301, C2 fake: 0.000000], [G loss: 0.077134, mse: 0.057602]\n",
      "Epoch 282/10001\n",
      "[C1 valid: 0.050325, C2 fake: 0.000000], [G loss: 0.077491, mse: 0.057459]\n",
      "Epoch 283/10001\n",
      "[C1 valid: 0.052457, C2 fake: 0.000000], [G loss: 0.072988, mse: 0.054469]\n",
      "Epoch 284/10001\n",
      "[C1 valid: 0.049146, C2 fake: 0.000000], [G loss: 0.076385, mse: 0.056217]\n",
      "Epoch 285/10001\n",
      "[C1 valid: 0.049970, C2 fake: 0.000000], [G loss: 0.075111, mse: 0.057077]\n",
      "Epoch 286/10001\n",
      "[C1 valid: 0.049095, C2 fake: 0.000000], [G loss: 0.076130, mse: 0.057929]\n",
      "Epoch 287/10001\n",
      "[C1 valid: 0.048368, C2 fake: 0.000000], [G loss: 0.074623, mse: 0.054415]\n",
      "Epoch 288/10001\n",
      "[C1 valid: 0.049877, C2 fake: 0.000000], [G loss: 0.073206, mse: 0.053275]\n",
      "Epoch 289/10001\n",
      "[C1 valid: 0.048047, C2 fake: 0.000000], [G loss: 0.073699, mse: 0.054377]\n",
      "Epoch 290/10001\n",
      "[C1 valid: 0.049365, C2 fake: 0.000000], [G loss: 0.075088, mse: 0.055796]\n",
      "Epoch 291/10001\n",
      "[C1 valid: 0.047780, C2 fake: 0.000000], [G loss: 0.069865, mse: 0.051107]\n",
      "Epoch 292/10001\n",
      "[C1 valid: 0.047028, C2 fake: 0.000000], [G loss: 0.073345, mse: 0.055904]\n",
      "Epoch 293/10001\n",
      "[C1 valid: 0.046260, C2 fake: 0.000000], [G loss: 0.073714, mse: 0.055318]\n",
      "Epoch 294/10001\n",
      "[C1 valid: 0.044003, C2 fake: 0.000000], [G loss: 0.075331, mse: 0.057798]\n",
      "Epoch 295/10001\n",
      "[C1 valid: 0.047217, C2 fake: 0.000000], [G loss: 0.074444, mse: 0.055802]\n",
      "Epoch 296/10001\n",
      "[C1 valid: 0.046922, C2 fake: 0.000000], [G loss: 0.072652, mse: 0.052647]\n",
      "Epoch 297/10001\n",
      "[C1 valid: 0.044553, C2 fake: 0.000000], [G loss: 0.069177, mse: 0.051340]\n",
      "Epoch 298/10001\n",
      "[C1 valid: 0.045949, C2 fake: 0.000000], [G loss: 0.069842, mse: 0.052208]\n",
      "Epoch 299/10001\n",
      "[C1 valid: 0.042605, C2 fake: 0.000000], [G loss: 0.071596, mse: 0.052546]\n",
      "Epoch 300/10001\n",
      "[C1 valid: 0.046369, C2 fake: 0.000000], [G loss: 0.070657, mse: 0.052972]\n",
      "Epoch 301/10001\n",
      "[C1 valid: 0.041959, C2 fake: 0.000000], [G loss: 0.073790, mse: 0.055276]\n",
      "Epoch 302/10001\n",
      "[C1 valid: 0.043786, C2 fake: 0.000000], [G loss: 0.072926, mse: 0.054518]\n",
      "Epoch 303/10001\n",
      "[C1 valid: 0.044152, C2 fake: 0.000000], [G loss: 0.068833, mse: 0.051785]\n",
      "Epoch 304/10001\n",
      "[C1 valid: 0.043729, C2 fake: 0.000000], [G loss: 0.071482, mse: 0.052109]\n",
      "Epoch 305/10001\n",
      "[C1 valid: 0.043028, C2 fake: 0.000000], [G loss: 0.072779, mse: 0.053834]\n",
      "Epoch 306/10001\n",
      "[C1 valid: 0.041284, C2 fake: 0.000000], [G loss: 0.069841, mse: 0.051794]\n",
      "Epoch 307/10001\n",
      "[C1 valid: 0.042220, C2 fake: 0.000000], [G loss: 0.071538, mse: 0.054473]\n",
      "Epoch 308/10001\n",
      "[C1 valid: 0.041346, C2 fake: 0.000000], [G loss: 0.067611, mse: 0.050023]\n",
      "Epoch 309/10001\n",
      "[C1 valid: 0.042919, C2 fake: 0.000000], [G loss: 0.070015, mse: 0.053368]\n",
      "Epoch 310/10001\n",
      "[C1 valid: 0.040102, C2 fake: 0.000000], [G loss: 0.068402, mse: 0.051641]\n",
      "Epoch 311/10001\n",
      "[C1 valid: 0.040843, C2 fake: 0.000000], [G loss: 0.067118, mse: 0.051334]\n",
      "Epoch 312/10001\n",
      "[C1 valid: 0.041902, C2 fake: 0.000000], [G loss: 0.070334, mse: 0.053288]\n",
      "Epoch 313/10001\n",
      "[C1 valid: 0.041927, C2 fake: 0.000000], [G loss: 0.070214, mse: 0.053727]\n",
      "Epoch 314/10001\n",
      "[C1 valid: 0.041361, C2 fake: 0.000000], [G loss: 0.066246, mse: 0.048953]\n",
      "Epoch 315/10001\n",
      "[C1 valid: 0.039295, C2 fake: 0.000000], [G loss: 0.067227, mse: 0.050333]\n",
      "Epoch 316/10001\n",
      "[C1 valid: 0.041020, C2 fake: 0.000000], [G loss: 0.066600, mse: 0.050103]\n",
      "Epoch 317/10001\n",
      "[C1 valid: 0.041348, C2 fake: 0.000000], [G loss: 0.063699, mse: 0.047299]\n",
      "Epoch 318/10001\n",
      "[C1 valid: 0.040256, C2 fake: 0.000000], [G loss: 0.066949, mse: 0.051537]\n",
      "Epoch 319/10001\n",
      "[C1 valid: 0.039973, C2 fake: 0.000000], [G loss: 0.066120, mse: 0.050713]\n",
      "Epoch 320/10001\n",
      "[C1 valid: 0.039877, C2 fake: 0.000000], [G loss: 0.066454, mse: 0.050756]\n",
      "Epoch 321/10001\n",
      "[C1 valid: 0.038522, C2 fake: 0.000000], [G loss: 0.065079, mse: 0.049239]\n",
      "Epoch 322/10001\n",
      "[C1 valid: 0.037067, C2 fake: 0.000000], [G loss: 0.067045, mse: 0.051743]\n",
      "Epoch 323/10001\n",
      "[C1 valid: 0.036843, C2 fake: 0.000000], [G loss: 0.065496, mse: 0.050039]\n",
      "Epoch 324/10001\n",
      "[C1 valid: 0.038047, C2 fake: 0.000000], [G loss: 0.062341, mse: 0.045153]\n",
      "Epoch 325/10001\n",
      "[C1 valid: 0.037935, C2 fake: 0.000000], [G loss: 0.061029, mse: 0.045145]\n",
      "Epoch 326/10001\n",
      "[C1 valid: 0.037274, C2 fake: 0.000000], [G loss: 0.064897, mse: 0.049964]\n",
      "Epoch 327/10001\n",
      "[C1 valid: 0.037615, C2 fake: 0.000000], [G loss: 0.067169, mse: 0.052555]\n",
      "Epoch 328/10001\n",
      "[C1 valid: 0.035794, C2 fake: 0.000000], [G loss: 0.063546, mse: 0.048947]\n",
      "Epoch 329/10001\n",
      "[C1 valid: 0.037760, C2 fake: 0.000000], [G loss: 0.064212, mse: 0.048486]\n",
      "Epoch 330/10001\n",
      "[C1 valid: 0.035260, C2 fake: 0.000000], [G loss: 0.062964, mse: 0.047456]\n",
      "Epoch 331/10001\n",
      "[C1 valid: 0.034865, C2 fake: 0.000000], [G loss: 0.063266, mse: 0.048499]\n",
      "Epoch 332/10001\n",
      "[C1 valid: 0.035011, C2 fake: 0.000000], [G loss: 0.059558, mse: 0.045295]\n",
      "Epoch 333/10001\n",
      "[C1 valid: 0.035566, C2 fake: 0.000000], [G loss: 0.062601, mse: 0.047881]\n",
      "Epoch 334/10001\n",
      "[C1 valid: 0.035830, C2 fake: 0.000000], [G loss: 0.058517, mse: 0.043209]\n",
      "Epoch 335/10001\n",
      "[C1 valid: 0.034177, C2 fake: 0.000000], [G loss: 0.061971, mse: 0.047863]\n",
      "Epoch 336/10001\n",
      "[C1 valid: 0.035370, C2 fake: 0.000000], [G loss: 0.058727, mse: 0.045165]\n",
      "Epoch 337/10001\n",
      "[C1 valid: 0.035593, C2 fake: 0.000000], [G loss: 0.061570, mse: 0.046755]\n",
      "Epoch 338/10001\n",
      "[C1 valid: 0.033051, C2 fake: 0.000000], [G loss: 0.063752, mse: 0.049099]\n",
      "Epoch 339/10001\n",
      "[C1 valid: 0.034422, C2 fake: 0.000000], [G loss: 0.059569, mse: 0.044832]\n",
      "Epoch 340/10001\n",
      "[C1 valid: 0.034136, C2 fake: 0.000000], [G loss: 0.060202, mse: 0.046464]\n",
      "Epoch 341/10001\n",
      "[C1 valid: 0.034353, C2 fake: 0.000000], [G loss: 0.058905, mse: 0.045172]\n",
      "Epoch 342/10001\n",
      "[C1 valid: 0.034278, C2 fake: 0.000000], [G loss: 0.061160, mse: 0.047301]\n",
      "Epoch 343/10001\n",
      "[C1 valid: 0.033533, C2 fake: 0.000000], [G loss: 0.060658, mse: 0.047301]\n",
      "Epoch 344/10001\n",
      "[C1 valid: 0.035633, C2 fake: 0.000000], [G loss: 0.058948, mse: 0.045250]\n",
      "Epoch 345/10001\n",
      "[C1 valid: 0.031634, C2 fake: 0.000000], [G loss: 0.058651, mse: 0.045288]\n",
      "Epoch 346/10001\n",
      "[C1 valid: 0.032908, C2 fake: 0.000000], [G loss: 0.059553, mse: 0.046289]\n",
      "Epoch 347/10001\n",
      "[C1 valid: 0.033161, C2 fake: 0.000000], [G loss: 0.057953, mse: 0.044479]\n",
      "Epoch 348/10001\n",
      "[C1 valid: 0.033767, C2 fake: 0.000000], [G loss: 0.058995, mse: 0.046097]\n",
      "Epoch 349/10001\n",
      "[C1 valid: 0.032299, C2 fake: 0.000000], [G loss: 0.056133, mse: 0.043180]\n",
      "Epoch 350/10001\n",
      "[C1 valid: 0.031470, C2 fake: 0.000000], [G loss: 0.060771, mse: 0.047786]\n",
      "Epoch 351/10001\n",
      "[C1 valid: 0.032810, C2 fake: 0.000000], [G loss: 0.059133, mse: 0.045819]\n",
      "Epoch 352/10001\n",
      "[C1 valid: 0.030643, C2 fake: 0.000000], [G loss: 0.054516, mse: 0.041576]\n",
      "Epoch 353/10001\n",
      "[C1 valid: 0.033613, C2 fake: 0.000000], [G loss: 0.056616, mse: 0.042707]\n",
      "Epoch 354/10001\n",
      "[C1 valid: 0.032432, C2 fake: 0.000000], [G loss: 0.060060, mse: 0.046912]\n",
      "Epoch 355/10001\n",
      "[C1 valid: 0.031726, C2 fake: 0.000000], [G loss: 0.059314, mse: 0.046541]\n",
      "Epoch 356/10001\n",
      "[C1 valid: 0.030131, C2 fake: 0.000000], [G loss: 0.054509, mse: 0.041807]\n",
      "Epoch 357/10001\n",
      "[C1 valid: 0.031244, C2 fake: 0.000000], [G loss: 0.055199, mse: 0.042599]\n",
      "Epoch 358/10001\n",
      "[C1 valid: 0.030616, C2 fake: 0.000000], [G loss: 0.057611, mse: 0.044169]\n",
      "Epoch 359/10001\n",
      "[C1 valid: 0.032125, C2 fake: 0.000000], [G loss: 0.056405, mse: 0.044634]\n",
      "Epoch 360/10001\n",
      "[C1 valid: 0.030552, C2 fake: 0.000000], [G loss: 0.057303, mse: 0.044671]\n",
      "Epoch 361/10001\n",
      "[C1 valid: 0.030441, C2 fake: 0.000000], [G loss: 0.056510, mse: 0.043510]\n",
      "Epoch 362/10001\n",
      "[C1 valid: 0.028528, C2 fake: 0.000000], [G loss: 0.057037, mse: 0.044983]\n",
      "Epoch 363/10001\n",
      "[C1 valid: 0.027929, C2 fake: 0.000000], [G loss: 0.056062, mse: 0.044373]\n",
      "Epoch 364/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.030831, C2 fake: 0.000000], [G loss: 0.055249, mse: 0.043681]\n",
      "Epoch 365/10001\n",
      "[C1 valid: 0.030156, C2 fake: 0.000000], [G loss: 0.053753, mse: 0.042214]\n",
      "Epoch 366/10001\n",
      "[C1 valid: 0.027976, C2 fake: 0.000000], [G loss: 0.053684, mse: 0.041858]\n",
      "Epoch 367/10001\n",
      "[C1 valid: 0.029044, C2 fake: 0.000000], [G loss: 0.052438, mse: 0.041145]\n",
      "Epoch 368/10001\n",
      "[C1 valid: 0.028952, C2 fake: 0.000000], [G loss: 0.057635, mse: 0.043887]\n",
      "Epoch 369/10001\n",
      "[C1 valid: 0.027899, C2 fake: 0.000000], [G loss: 0.054188, mse: 0.041977]\n",
      "Epoch 370/10001\n",
      "[C1 valid: 0.028446, C2 fake: 0.000000], [G loss: 0.055273, mse: 0.043788]\n",
      "Epoch 371/10001\n",
      "[C1 valid: 0.026583, C2 fake: 0.000000], [G loss: 0.054805, mse: 0.043133]\n",
      "Epoch 372/10001\n",
      "[C1 valid: 0.028039, C2 fake: 0.000000], [G loss: 0.053397, mse: 0.042200]\n",
      "Epoch 373/10001\n",
      "[C1 valid: 0.027338, C2 fake: 0.000000], [G loss: 0.051519, mse: 0.040531]\n",
      "Epoch 374/10001\n",
      "[C1 valid: 0.028009, C2 fake: 0.000000], [G loss: 0.053891, mse: 0.041898]\n",
      "Epoch 375/10001\n",
      "[C1 valid: 0.027262, C2 fake: 0.000000], [G loss: 0.052208, mse: 0.041187]\n",
      "Epoch 376/10001\n",
      "[C1 valid: 0.025674, C2 fake: 0.000000], [G loss: 0.057060, mse: 0.044269]\n",
      "Epoch 377/10001\n",
      "[C1 valid: 0.027441, C2 fake: 0.000000], [G loss: 0.050729, mse: 0.040097]\n",
      "Epoch 378/10001\n",
      "[C1 valid: 0.027348, C2 fake: 0.000000], [G loss: 0.055384, mse: 0.044288]\n",
      "Epoch 379/10001\n",
      "[C1 valid: 0.026384, C2 fake: 0.000000], [G loss: 0.053263, mse: 0.042330]\n",
      "Epoch 380/10001\n",
      "[C1 valid: 0.027096, C2 fake: 0.000000], [G loss: 0.053042, mse: 0.042199]\n",
      "Epoch 381/10001\n",
      "[C1 valid: 0.026524, C2 fake: 0.000000], [G loss: 0.053748, mse: 0.042358]\n",
      "Epoch 382/10001\n",
      "[C1 valid: 0.025690, C2 fake: 0.000000], [G loss: 0.053652, mse: 0.043004]\n",
      "Epoch 383/10001\n",
      "[C1 valid: 0.026346, C2 fake: 0.000000], [G loss: 0.052352, mse: 0.041780]\n",
      "Epoch 384/10001\n",
      "[C1 valid: 0.026304, C2 fake: 0.000000], [G loss: 0.052960, mse: 0.041351]\n",
      "Epoch 385/10001\n",
      "[C1 valid: 0.026453, C2 fake: 0.000000], [G loss: 0.052259, mse: 0.041673]\n",
      "Epoch 386/10001\n",
      "[C1 valid: 0.025538, C2 fake: 0.000000], [G loss: 0.050220, mse: 0.039968]\n",
      "Epoch 387/10001\n",
      "[C1 valid: 0.025578, C2 fake: 0.000000], [G loss: 0.052107, mse: 0.040665]\n",
      "Epoch 388/10001\n",
      "[C1 valid: 0.025057, C2 fake: 0.000000], [G loss: 0.052859, mse: 0.042177]\n",
      "Epoch 389/10001\n",
      "[C1 valid: 0.025582, C2 fake: 0.000000], [G loss: 0.050558, mse: 0.040406]\n",
      "Epoch 390/10001\n",
      "[C1 valid: 0.024827, C2 fake: 0.000000], [G loss: 0.055501, mse: 0.045492]\n",
      "Epoch 391/10001\n",
      "[C1 valid: 0.025587, C2 fake: 0.000000], [G loss: 0.049433, mse: 0.039710]\n",
      "Epoch 392/10001\n",
      "[C1 valid: 0.024381, C2 fake: 0.000000], [G loss: 0.047842, mse: 0.038076]\n",
      "Epoch 393/10001\n",
      "[C1 valid: 0.025898, C2 fake: 0.000000], [G loss: 0.051013, mse: 0.040334]\n",
      "Epoch 394/10001\n",
      "[C1 valid: 0.024566, C2 fake: 0.000000], [G loss: 0.050075, mse: 0.040302]\n",
      "Epoch 395/10001\n",
      "[C1 valid: 0.023321, C2 fake: 0.000000], [G loss: 0.050454, mse: 0.040536]\n",
      "Epoch 396/10001\n",
      "[C1 valid: 0.024693, C2 fake: 0.000000], [G loss: 0.049166, mse: 0.039862]\n",
      "Epoch 397/10001\n",
      "[C1 valid: 0.022690, C2 fake: 0.000000], [G loss: 0.051507, mse: 0.041015]\n",
      "Epoch 398/10001\n",
      "[C1 valid: 0.025043, C2 fake: 0.000000], [G loss: 0.050180, mse: 0.040601]\n",
      "Epoch 399/10001\n",
      "[C1 valid: 0.024418, C2 fake: 0.000000], [G loss: 0.050498, mse: 0.040953]\n",
      "Epoch 400/10001\n",
      "[C1 valid: 0.023874, C2 fake: 0.000000], [G loss: 0.047263, mse: 0.038199]\n",
      "Epoch 401/10001\n",
      "[C1 valid: 0.024051, C2 fake: 0.000000], [G loss: 0.045425, mse: 0.036374]\n",
      "Epoch 402/10001\n",
      "[C1 valid: 0.024173, C2 fake: 0.000000], [G loss: 0.048122, mse: 0.038805]\n",
      "Epoch 403/10001\n",
      "[C1 valid: 0.023044, C2 fake: 0.000000], [G loss: 0.048620, mse: 0.039355]\n",
      "Epoch 404/10001\n",
      "[C1 valid: 0.023867, C2 fake: 0.000000], [G loss: 0.046882, mse: 0.037842]\n",
      "Epoch 405/10001\n",
      "[C1 valid: 0.023368, C2 fake: 0.000000], [G loss: 0.048518, mse: 0.039148]\n",
      "Epoch 406/10001\n",
      "[C1 valid: 0.024126, C2 fake: 0.000000], [G loss: 0.048711, mse: 0.039931]\n",
      "Epoch 407/10001\n",
      "[C1 valid: 0.023634, C2 fake: 0.000000], [G loss: 0.049951, mse: 0.040267]\n",
      "Epoch 408/10001\n",
      "[C1 valid: 0.021271, C2 fake: 0.000000], [G loss: 0.046929, mse: 0.038046]\n",
      "Epoch 409/10001\n",
      "[C1 valid: 0.021348, C2 fake: 0.000000], [G loss: 0.048061, mse: 0.039023]\n",
      "Epoch 410/10001\n",
      "[C1 valid: 0.022015, C2 fake: 0.000000], [G loss: 0.048413, mse: 0.039410]\n",
      "Epoch 411/10001\n",
      "[C1 valid: 0.021919, C2 fake: 0.000000], [G loss: 0.046657, mse: 0.037384]\n",
      "Epoch 412/10001\n",
      "[C1 valid: 0.022044, C2 fake: 0.000000], [G loss: 0.047600, mse: 0.038531]\n",
      "Epoch 413/10001\n",
      "[C1 valid: 0.021634, C2 fake: 0.000000], [G loss: 0.046769, mse: 0.037798]\n",
      "Epoch 414/10001\n",
      "[C1 valid: 0.020782, C2 fake: 0.000000], [G loss: 0.047958, mse: 0.039163]\n",
      "Epoch 415/10001\n",
      "[C1 valid: 0.021306, C2 fake: 0.000000], [G loss: 0.044307, mse: 0.035637]\n",
      "Epoch 416/10001\n",
      "[C1 valid: 0.020606, C2 fake: 0.000000], [G loss: 0.048946, mse: 0.039771]\n",
      "Epoch 417/10001\n",
      "[C1 valid: 0.020591, C2 fake: 0.000000], [G loss: 0.046497, mse: 0.037521]\n",
      "Epoch 418/10001\n",
      "[C1 valid: 0.020584, C2 fake: 0.000000], [G loss: 0.048175, mse: 0.039210]\n",
      "Epoch 419/10001\n",
      "[C1 valid: 0.019389, C2 fake: 0.000000], [G loss: 0.043166, mse: 0.034500]\n",
      "Epoch 420/10001\n",
      "[C1 valid: 0.021073, C2 fake: 0.000000], [G loss: 0.048435, mse: 0.038846]\n",
      "Epoch 421/10001\n",
      "[C1 valid: 0.021453, C2 fake: 0.000000], [G loss: 0.046758, mse: 0.036682]\n",
      "Epoch 422/10001\n",
      "[C1 valid: 0.020634, C2 fake: 0.000000], [G loss: 0.047700, mse: 0.038715]\n",
      "Epoch 423/10001\n",
      "[C1 valid: 0.020930, C2 fake: 0.000000], [G loss: 0.044437, mse: 0.035850]\n",
      "Epoch 424/10001\n",
      "[C1 valid: 0.019485, C2 fake: 0.000000], [G loss: 0.044000, mse: 0.035635]\n",
      "Epoch 425/10001\n",
      "[C1 valid: 0.020552, C2 fake: 0.000000], [G loss: 0.043548, mse: 0.035296]\n",
      "Epoch 426/10001\n",
      "[C1 valid: 0.020299, C2 fake: 0.000000], [G loss: 0.045601, mse: 0.037340]\n",
      "Epoch 427/10001\n",
      "[C1 valid: 0.021187, C2 fake: 0.000000], [G loss: 0.046815, mse: 0.038840]\n",
      "Epoch 428/10001\n",
      "[C1 valid: 0.019222, C2 fake: 0.000000], [G loss: 0.045120, mse: 0.036076]\n",
      "Epoch 429/10001\n",
      "[C1 valid: 0.019547, C2 fake: 0.000000], [G loss: 0.046574, mse: 0.037551]\n",
      "Epoch 430/10001\n",
      "[C1 valid: 0.019052, C2 fake: 0.000000], [G loss: 0.049095, mse: 0.041095]\n",
      "Epoch 431/10001\n",
      "[C1 valid: 0.019062, C2 fake: 0.000000], [G loss: 0.044823, mse: 0.036857]\n",
      "Epoch 432/10001\n",
      "[C1 valid: 0.019719, C2 fake: 0.000000], [G loss: 0.047260, mse: 0.039174]\n",
      "Epoch 433/10001\n",
      "[C1 valid: 0.019878, C2 fake: 0.000000], [G loss: 0.044098, mse: 0.035955]\n",
      "Epoch 434/10001\n",
      "[C1 valid: 0.021023, C2 fake: 0.000000], [G loss: 0.045367, mse: 0.036662]\n",
      "Epoch 435/10001\n",
      "[C1 valid: 0.019065, C2 fake: 0.000000], [G loss: 0.043253, mse: 0.034972]\n",
      "Epoch 436/10001\n",
      "[C1 valid: 0.019000, C2 fake: 0.000000], [G loss: 0.044970, mse: 0.037788]\n",
      "Epoch 437/10001\n",
      "[C1 valid: 0.018986, C2 fake: 0.000000], [G loss: 0.042570, mse: 0.035427]\n",
      "Epoch 438/10001\n",
      "[C1 valid: 0.018687, C2 fake: 0.000000], [G loss: 0.044696, mse: 0.037042]\n",
      "Epoch 439/10001\n",
      "[C1 valid: 0.018984, C2 fake: 0.000000], [G loss: 0.046080, mse: 0.037923]\n",
      "Epoch 440/10001\n",
      "[C1 valid: 0.017594, C2 fake: 0.000000], [G loss: 0.043334, mse: 0.035573]\n",
      "Epoch 441/10001\n",
      "[C1 valid: 0.018570, C2 fake: 0.000000], [G loss: 0.043709, mse: 0.035074]\n",
      "Epoch 442/10001\n",
      "[C1 valid: 0.018761, C2 fake: 0.000000], [G loss: 0.043132, mse: 0.035787]\n",
      "Epoch 443/10001\n",
      "[C1 valid: 0.018008, C2 fake: 0.000000], [G loss: 0.044262, mse: 0.036223]\n",
      "Epoch 444/10001\n",
      "[C1 valid: 0.019029, C2 fake: 0.000000], [G loss: 0.045741, mse: 0.036720]\n",
      "Epoch 445/10001\n",
      "[C1 valid: 0.017433, C2 fake: 0.000000], [G loss: 0.041083, mse: 0.034009]\n",
      "Epoch 446/10001\n",
      "[C1 valid: 0.016782, C2 fake: 0.000000], [G loss: 0.042435, mse: 0.034985]\n",
      "Epoch 447/10001\n",
      "[C1 valid: 0.017458, C2 fake: 0.000000], [G loss: 0.041740, mse: 0.034084]\n",
      "Epoch 448/10001\n",
      "[C1 valid: 0.017486, C2 fake: 0.000000], [G loss: 0.044927, mse: 0.037021]\n",
      "Epoch 449/10001\n",
      "[C1 valid: 0.016862, C2 fake: 0.000000], [G loss: 0.042803, mse: 0.035581]\n",
      "Epoch 450/10001\n",
      "[C1 valid: 0.017740, C2 fake: 0.000000], [G loss: 0.041616, mse: 0.034331]\n",
      "Epoch 451/10001\n",
      "[C1 valid: 0.016727, C2 fake: 0.000000], [G loss: 0.042421, mse: 0.034970]\n",
      "Epoch 452/10001\n",
      "[C1 valid: 0.017314, C2 fake: 0.000000], [G loss: 0.042373, mse: 0.035460]\n",
      "Epoch 453/10001\n",
      "[C1 valid: 0.016176, C2 fake: 0.000000], [G loss: 0.040539, mse: 0.033595]\n",
      "Epoch 454/10001\n",
      "[C1 valid: 0.017216, C2 fake: 0.000000], [G loss: 0.045805, mse: 0.039057]\n",
      "Epoch 455/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.016922, C2 fake: 0.000000], [G loss: 0.041741, mse: 0.034156]\n",
      "Epoch 456/10001\n",
      "[C1 valid: 0.016393, C2 fake: 0.000000], [G loss: 0.042971, mse: 0.035293]\n",
      "Epoch 457/10001\n",
      "[C1 valid: 0.017832, C2 fake: 0.000000], [G loss: 0.043616, mse: 0.036991]\n",
      "Epoch 458/10001\n",
      "[C1 valid: 0.015562, C2 fake: 0.000000], [G loss: 0.041502, mse: 0.034694]\n",
      "Epoch 459/10001\n",
      "[C1 valid: 0.017625, C2 fake: 0.000000], [G loss: 0.041420, mse: 0.034755]\n",
      "Epoch 460/10001\n",
      "[C1 valid: 0.016341, C2 fake: 0.000000], [G loss: 0.041164, mse: 0.034663]\n",
      "Epoch 461/10001\n",
      "[C1 valid: 0.016170, C2 fake: 0.000000], [G loss: 0.039796, mse: 0.033431]\n",
      "Epoch 462/10001\n",
      "[C1 valid: 0.015829, C2 fake: 0.000000], [G loss: 0.041426, mse: 0.035089]\n",
      "Epoch 463/10001\n",
      "[C1 valid: 0.016696, C2 fake: 0.000000], [G loss: 0.038638, mse: 0.032381]\n",
      "Epoch 464/10001\n",
      "[C1 valid: 0.016307, C2 fake: 0.000000], [G loss: 0.040282, mse: 0.034012]\n",
      "Epoch 465/10001\n",
      "[C1 valid: 0.015990, C2 fake: 0.000000], [G loss: 0.042181, mse: 0.035998]\n",
      "Epoch 466/10001\n",
      "[C1 valid: 0.015634, C2 fake: 0.000000], [G loss: 0.038794, mse: 0.032642]\n",
      "Epoch 467/10001\n",
      "[C1 valid: 0.016895, C2 fake: 0.000000], [G loss: 0.041130, mse: 0.034808]\n",
      "Epoch 468/10001\n",
      "[C1 valid: 0.015501, C2 fake: 0.000000], [G loss: 0.040116, mse: 0.033897]\n",
      "Epoch 469/10001\n",
      "[C1 valid: 0.016734, C2 fake: 0.000000], [G loss: 0.039358, mse: 0.033615]\n",
      "Epoch 470/10001\n",
      "[C1 valid: 0.014163, C2 fake: 0.000000], [G loss: 0.040987, mse: 0.034116]\n",
      "Epoch 471/10001\n",
      "[C1 valid: 0.014689, C2 fake: 0.000000], [G loss: 0.037484, mse: 0.030674]\n",
      "Epoch 472/10001\n",
      "[C1 valid: 0.015569, C2 fake: 0.000000], [G loss: 0.039938, mse: 0.033759]\n",
      "Epoch 473/10001\n",
      "[C1 valid: 0.014890, C2 fake: 0.000000], [G loss: 0.037894, mse: 0.031790]\n",
      "Epoch 474/10001\n",
      "[C1 valid: 0.014311, C2 fake: 0.000000], [G loss: 0.039482, mse: 0.033683]\n",
      "Epoch 475/10001\n",
      "[C1 valid: 0.014729, C2 fake: 0.000000], [G loss: 0.039168, mse: 0.033692]\n",
      "Epoch 476/10001\n",
      "[C1 valid: 0.015906, C2 fake: 0.000000], [G loss: 0.036679, mse: 0.031239]\n",
      "Epoch 477/10001\n",
      "[C1 valid: 0.013396, C2 fake: 0.000000], [G loss: 0.039587, mse: 0.034098]\n",
      "Epoch 478/10001\n",
      "[C1 valid: 0.015144, C2 fake: 0.000000], [G loss: 0.039226, mse: 0.033698]\n",
      "Epoch 479/10001\n",
      "[C1 valid: 0.014860, C2 fake: 0.000000], [G loss: 0.042238, mse: 0.036656]\n",
      "Epoch 480/10001\n",
      "[C1 valid: 0.016445, C2 fake: 0.000000], [G loss: 0.036035, mse: 0.030610]\n",
      "Epoch 481/10001\n",
      "[C1 valid: 0.015789, C2 fake: 0.000000], [G loss: 0.038914, mse: 0.033696]\n",
      "Epoch 482/10001\n",
      "[C1 valid: 0.014482, C2 fake: 0.000000], [G loss: 0.036565, mse: 0.031293]\n",
      "Epoch 483/10001\n",
      "[C1 valid: 0.014200, C2 fake: 0.000000], [G loss: 0.041781, mse: 0.034180]\n",
      "Epoch 484/10001\n",
      "[C1 valid: 0.013451, C2 fake: 0.000000], [G loss: 0.037197, mse: 0.031479]\n",
      "Epoch 485/10001\n",
      "[C1 valid: 0.014197, C2 fake: 0.000000], [G loss: 0.039663, mse: 0.033982]\n",
      "Epoch 486/10001\n",
      "[C1 valid: 0.012546, C2 fake: 0.000000], [G loss: 0.037473, mse: 0.031886]\n",
      "Epoch 487/10001\n",
      "[C1 valid: 0.015290, C2 fake: 0.000000], [G loss: 0.035648, mse: 0.030464]\n",
      "Epoch 488/10001\n",
      "[C1 valid: 0.013562, C2 fake: 0.000000], [G loss: 0.037001, mse: 0.031582]\n",
      "Epoch 489/10001\n",
      "[C1 valid: 0.013890, C2 fake: 0.000000], [G loss: 0.039054, mse: 0.033763]\n",
      "Epoch 490/10001\n",
      "[C1 valid: 0.014610, C2 fake: 0.000000], [G loss: 0.038196, mse: 0.032909]\n",
      "Epoch 491/10001\n",
      "[C1 valid: 0.013275, C2 fake: 0.000000], [G loss: 0.038227, mse: 0.033081]\n",
      "Epoch 492/10001\n",
      "[C1 valid: 0.012351, C2 fake: 0.000000], [G loss: 0.038980, mse: 0.032800]\n",
      "Epoch 493/10001\n",
      "[C1 valid: 0.013108, C2 fake: 0.000000], [G loss: 0.036205, mse: 0.030847]\n",
      "Epoch 494/10001\n",
      "[C1 valid: 0.012813, C2 fake: 0.000000], [G loss: 0.036714, mse: 0.031459]\n",
      "Epoch 495/10001\n",
      "[C1 valid: 0.014290, C2 fake: 0.000000], [G loss: 0.038986, mse: 0.033916]\n",
      "Epoch 496/10001\n",
      "[C1 valid: 0.013053, C2 fake: 0.000000], [G loss: 0.039771, mse: 0.033733]\n",
      "Epoch 497/10001\n",
      "[C1 valid: 0.013741, C2 fake: 0.000000], [G loss: 0.036928, mse: 0.032165]\n",
      "Epoch 498/10001\n",
      "[C1 valid: 0.014756, C2 fake: 0.000000], [G loss: 0.035834, mse: 0.031246]\n",
      "Epoch 499/10001\n",
      "[C1 valid: 0.013696, C2 fake: 0.000000], [G loss: 0.035802, mse: 0.031046]\n",
      "Epoch 500/10001\n",
      "[C1 valid: 0.013245, C2 fake: 0.000000], [G loss: 0.038976, mse: 0.032199]\n",
      "Epoch 501/10001\n",
      "[C1 valid: 0.013979, C2 fake: 0.000000], [G loss: 0.037614, mse: 0.033008]\n",
      "Epoch 502/10001\n",
      "[C1 valid: 0.014903, C2 fake: 0.000000], [G loss: 0.035470, mse: 0.030798]\n",
      "Epoch 503/10001\n",
      "[C1 valid: 0.013274, C2 fake: 0.000000], [G loss: 0.035262, mse: 0.030475]\n",
      "Epoch 504/10001\n",
      "[C1 valid: 0.014224, C2 fake: 0.000000], [G loss: 0.034876, mse: 0.030303]\n",
      "Epoch 505/10001\n",
      "[C1 valid: 0.012615, C2 fake: 0.000000], [G loss: 0.036778, mse: 0.032130]\n",
      "Epoch 506/10001\n",
      "[C1 valid: 0.014279, C2 fake: 0.000000], [G loss: 0.035697, mse: 0.031191]\n",
      "Epoch 507/10001\n",
      "[C1 valid: 0.011779, C2 fake: 0.000000], [G loss: 0.035377, mse: 0.030852]\n",
      "Epoch 508/10001\n",
      "[C1 valid: 0.014166, C2 fake: 0.000000], [G loss: 0.036815, mse: 0.031601]\n",
      "Epoch 509/10001\n",
      "[C1 valid: 0.012135, C2 fake: 0.000000], [G loss: 0.035188, mse: 0.030977]\n",
      "Epoch 510/10001\n",
      "[C1 valid: 0.013231, C2 fake: 0.000000], [G loss: 0.034316, mse: 0.030106]\n",
      "Epoch 511/10001\n",
      "[C1 valid: 0.012906, C2 fake: 0.000000], [G loss: 0.035516, mse: 0.030153]\n",
      "Epoch 512/10001\n",
      "[C1 valid: 0.012273, C2 fake: 0.000000], [G loss: 0.037488, mse: 0.033114]\n",
      "Epoch 513/10001\n",
      "[C1 valid: 0.012520, C2 fake: 0.000000], [G loss: 0.034873, mse: 0.030630]\n",
      "Epoch 514/10001\n",
      "[C1 valid: 0.012978, C2 fake: 0.000000], [G loss: 0.035487, mse: 0.031148]\n",
      "Epoch 515/10001\n",
      "[C1 valid: 0.011563, C2 fake: 0.000000], [G loss: 0.036790, mse: 0.032445]\n",
      "Epoch 516/10001\n",
      "[C1 valid: 0.012085, C2 fake: 0.000000], [G loss: 0.035763, mse: 0.031562]\n",
      "Epoch 517/10001\n",
      "[C1 valid: 0.011344, C2 fake: 0.000000], [G loss: 0.033700, mse: 0.029390]\n",
      "Epoch 518/10001\n",
      "[C1 valid: 0.012055, C2 fake: 0.000000], [G loss: 0.035263, mse: 0.031077]\n",
      "Epoch 519/10001\n",
      "[C1 valid: 0.012566, C2 fake: 0.000000], [G loss: 0.035009, mse: 0.031014]\n",
      "Epoch 520/10001\n",
      "[C1 valid: 0.011761, C2 fake: 0.000000], [G loss: 0.034066, mse: 0.029977]\n",
      "Epoch 521/10001\n",
      "[C1 valid: 0.011665, C2 fake: 0.000000], [G loss: 0.032801, mse: 0.028782]\n",
      "Epoch 522/10001\n",
      "[C1 valid: 0.012228, C2 fake: 0.000000], [G loss: 0.035644, mse: 0.031697]\n",
      "Epoch 523/10001\n",
      "[C1 valid: 0.011397, C2 fake: 0.000000], [G loss: 0.033624, mse: 0.029631]\n",
      "Epoch 524/10001\n",
      "[C1 valid: 0.012052, C2 fake: 0.000000], [G loss: 0.035264, mse: 0.031259]\n",
      "Epoch 525/10001\n",
      "[C1 valid: 0.011580, C2 fake: 0.000000], [G loss: 0.032554, mse: 0.028520]\n",
      "Epoch 526/10001\n",
      "[C1 valid: 0.011061, C2 fake: 0.000000], [G loss: 0.035332, mse: 0.031294]\n",
      "Epoch 527/10001\n",
      "[C1 valid: 0.012570, C2 fake: 0.000000], [G loss: 0.034253, mse: 0.030317]\n",
      "Epoch 528/10001\n",
      "[C1 valid: 0.010904, C2 fake: 0.000000], [G loss: 0.034799, mse: 0.030816]\n",
      "Epoch 529/10001\n",
      "[C1 valid: 0.011377, C2 fake: 0.000000], [G loss: 0.032329, mse: 0.028322]\n",
      "Epoch 530/10001\n",
      "[C1 valid: 0.011498, C2 fake: 0.000000], [G loss: 0.032610, mse: 0.028508]\n",
      "Epoch 531/10001\n",
      "[C1 valid: 0.011126, C2 fake: 0.000000], [G loss: 0.034255, mse: 0.030070]\n",
      "Epoch 532/10001\n",
      "[C1 valid: 0.012463, C2 fake: 0.000000], [G loss: 0.032407, mse: 0.028350]\n",
      "Epoch 533/10001\n",
      "[C1 valid: 0.010706, C2 fake: 0.000000], [G loss: 0.032089, mse: 0.028233]\n",
      "Epoch 534/10001\n",
      "[C1 valid: 0.010680, C2 fake: 0.000000], [G loss: 0.036491, mse: 0.032625]\n",
      "Epoch 535/10001\n",
      "[C1 valid: 0.011154, C2 fake: 0.000000], [G loss: 0.033541, mse: 0.029813]\n",
      "Epoch 536/10001\n",
      "[C1 valid: 0.010661, C2 fake: 0.000000], [G loss: 0.032240, mse: 0.028343]\n",
      "Epoch 537/10001\n",
      "[C1 valid: 0.010026, C2 fake: 0.000000], [G loss: 0.035519, mse: 0.031616]\n",
      "Epoch 538/10001\n",
      "[C1 valid: 0.010950, C2 fake: 0.000000], [G loss: 0.034575, mse: 0.030718]\n",
      "Epoch 539/10001\n",
      "[C1 valid: 0.011656, C2 fake: 0.000000], [G loss: 0.032265, mse: 0.028668]\n",
      "Epoch 540/10001\n",
      "[C1 valid: 0.011119, C2 fake: 0.000000], [G loss: 0.034932, mse: 0.031260]\n",
      "Epoch 541/10001\n",
      "[C1 valid: 0.010446, C2 fake: 0.000000], [G loss: 0.033978, mse: 0.030141]\n",
      "Epoch 542/10001\n",
      "[C1 valid: 0.011072, C2 fake: 0.000000], [G loss: 0.031775, mse: 0.027935]\n",
      "Epoch 543/10001\n",
      "[C1 valid: 0.009717, C2 fake: 0.000000], [G loss: 0.030550, mse: 0.026686]\n",
      "Epoch 544/10001\n",
      "[C1 valid: 0.010245, C2 fake: 0.000000], [G loss: 0.033331, mse: 0.029526]\n",
      "Epoch 545/10001\n",
      "[C1 valid: 0.013097, C2 fake: 0.000000], [G loss: 0.033159, mse: 0.029435]\n",
      "Epoch 546/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.010180, C2 fake: 0.000000], [G loss: 0.033473, mse: 0.029752]\n",
      "Epoch 547/10001\n",
      "[C1 valid: 0.011411, C2 fake: 0.000000], [G loss: 0.033544, mse: 0.029812]\n",
      "Epoch 548/10001\n",
      "[C1 valid: 0.010807, C2 fake: 0.000000], [G loss: 0.031962, mse: 0.028338]\n",
      "Epoch 549/10001\n",
      "[C1 valid: 0.010660, C2 fake: 0.000000], [G loss: 0.033699, mse: 0.030113]\n",
      "Epoch 550/10001\n",
      "[C1 valid: 0.011954, C2 fake: 0.000000], [G loss: 0.034263, mse: 0.030912]\n",
      "Epoch 551/10001\n",
      "[C1 valid: 0.010621, C2 fake: 0.000000], [G loss: 0.030901, mse: 0.027537]\n",
      "Epoch 552/10001\n",
      "[C1 valid: 0.009597, C2 fake: 0.000000], [G loss: 0.033276, mse: 0.029943]\n",
      "Epoch 553/10001\n",
      "[C1 valid: 0.010284, C2 fake: 0.000000], [G loss: 0.032670, mse: 0.029043]\n",
      "Epoch 554/10001\n",
      "[C1 valid: 0.011518, C2 fake: 0.000000], [G loss: 0.032143, mse: 0.028680]\n",
      "Epoch 555/10001\n",
      "[C1 valid: 0.009807, C2 fake: 0.000000], [G loss: 0.032221, mse: 0.028811]\n",
      "Epoch 556/10001\n",
      "[C1 valid: 0.009620, C2 fake: 0.000000], [G loss: 0.032571, mse: 0.029193]\n",
      "Epoch 557/10001\n",
      "[C1 valid: 0.010148, C2 fake: 0.000000], [G loss: 0.032375, mse: 0.028994]\n",
      "Epoch 558/10001\n",
      "[C1 valid: 0.009789, C2 fake: 0.000000], [G loss: 0.032958, mse: 0.029726]\n",
      "Epoch 559/10001\n",
      "[C1 valid: 0.010377, C2 fake: 0.000000], [G loss: 0.030198, mse: 0.026845]\n",
      "Epoch 560/10001\n",
      "[C1 valid: 0.010637, C2 fake: 0.000000], [G loss: 0.031144, mse: 0.027972]\n",
      "Epoch 561/10001\n",
      "[C1 valid: 0.010429, C2 fake: 0.000000], [G loss: 0.029121, mse: 0.025841]\n",
      "Epoch 562/10001\n",
      "[C1 valid: 0.008296, C2 fake: 0.000000], [G loss: 0.028984, mse: 0.024796]\n",
      "Epoch 563/10001\n",
      "[C1 valid: 0.009378, C2 fake: 0.000000], [G loss: 0.031224, mse: 0.027933]\n",
      "Epoch 564/10001\n",
      "[C1 valid: 0.011245, C2 fake: 0.000000], [G loss: 0.031373, mse: 0.028105]\n",
      "Epoch 565/10001\n",
      "[C1 valid: 0.009343, C2 fake: 0.000000], [G loss: 0.030048, mse: 0.026804]\n",
      "Epoch 566/10001\n",
      "[C1 valid: 0.009228, C2 fake: 0.000000], [G loss: 0.033543, mse: 0.029309]\n",
      "Epoch 567/10001\n",
      "[C1 valid: 0.009850, C2 fake: 0.000000], [G loss: 0.030483, mse: 0.027258]\n",
      "Epoch 568/10001\n",
      "[C1 valid: 0.009114, C2 fake: 0.000000], [G loss: 0.032247, mse: 0.029000]\n",
      "Epoch 569/10001\n",
      "[C1 valid: 0.010577, C2 fake: 0.000000], [G loss: 0.029353, mse: 0.026233]\n",
      "Epoch 570/10001\n",
      "[C1 valid: 0.009153, C2 fake: 0.000000], [G loss: 0.028591, mse: 0.025569]\n",
      "Epoch 571/10001\n",
      "[C1 valid: 0.008979, C2 fake: 0.000000], [G loss: 0.031815, mse: 0.028668]\n",
      "Epoch 572/10001\n",
      "[C1 valid: 0.009015, C2 fake: 0.000000], [G loss: 0.029833, mse: 0.026816]\n",
      "Epoch 573/10001\n",
      "[C1 valid: 0.008522, C2 fake: 0.000000], [G loss: 0.032734, mse: 0.028672]\n",
      "Epoch 574/10001\n",
      "[C1 valid: 0.009993, C2 fake: 0.000000], [G loss: 0.030858, mse: 0.027694]\n",
      "Epoch 575/10001\n",
      "[C1 valid: 0.010747, C2 fake: 0.000000], [G loss: 0.029694, mse: 0.026825]\n",
      "Epoch 576/10001\n",
      "[C1 valid: 0.009136, C2 fake: 0.000000], [G loss: 0.029560, mse: 0.026663]\n",
      "Epoch 577/10001\n",
      "[C1 valid: 0.007855, C2 fake: 0.000000], [G loss: 0.029596, mse: 0.026763]\n",
      "Epoch 578/10001\n",
      "[C1 valid: 0.009826, C2 fake: 0.000000], [G loss: 0.029666, mse: 0.026780]\n",
      "Epoch 579/10001\n",
      "[C1 valid: 0.009957, C2 fake: 0.000000], [G loss: 0.029519, mse: 0.026630]\n",
      "Epoch 580/10001\n",
      "[C1 valid: 0.009402, C2 fake: 0.000000], [G loss: 0.029960, mse: 0.027081]\n",
      "Epoch 581/10001\n",
      "[C1 valid: 0.008457, C2 fake: 0.000000], [G loss: 0.030156, mse: 0.027361]\n",
      "Epoch 582/10001\n",
      "[C1 valid: 0.010049, C2 fake: 0.000000], [G loss: 0.028382, mse: 0.025543]\n",
      "Epoch 583/10001\n",
      "[C1 valid: 0.008672, C2 fake: 0.000000], [G loss: 0.031005, mse: 0.028200]\n",
      "Epoch 584/10001\n",
      "[C1 valid: 0.009836, C2 fake: 0.000000], [G loss: 0.031429, mse: 0.028680]\n",
      "Epoch 585/10001\n",
      "[C1 valid: 0.009313, C2 fake: 0.000000], [G loss: 0.029643, mse: 0.026920]\n",
      "Epoch 586/10001\n",
      "[C1 valid: 0.008910, C2 fake: 0.000000], [G loss: 0.030463, mse: 0.027705]\n",
      "Epoch 587/10001\n",
      "[C1 valid: 0.008494, C2 fake: 0.000000], [G loss: 0.029530, mse: 0.026750]\n",
      "Epoch 588/10001\n",
      "[C1 valid: 0.009552, C2 fake: 0.000000], [G loss: 0.030787, mse: 0.027122]\n",
      "Epoch 589/10001\n",
      "[C1 valid: 0.007504, C2 fake: 0.000000], [G loss: 0.028710, mse: 0.026004]\n",
      "Epoch 590/10001\n",
      "[C1 valid: 0.007883, C2 fake: 0.000000], [G loss: 0.029269, mse: 0.026533]\n",
      "Epoch 591/10001\n",
      "[C1 valid: 0.007916, C2 fake: 0.000000], [G loss: 0.027853, mse: 0.025194]\n",
      "Epoch 592/10001\n",
      "[C1 valid: 0.009097, C2 fake: 0.000000], [G loss: 0.029967, mse: 0.027243]\n",
      "Epoch 593/10001\n",
      "[C1 valid: 0.008897, C2 fake: 0.000000], [G loss: 0.028434, mse: 0.025760]\n",
      "Epoch 594/10001\n",
      "[C1 valid: 0.007835, C2 fake: 0.000000], [G loss: 0.030605, mse: 0.027952]\n",
      "Epoch 595/10001\n",
      "[C1 valid: 0.008072, C2 fake: 0.000000], [G loss: 0.029458, mse: 0.026849]\n",
      "Epoch 596/10001\n",
      "[C1 valid: 0.009046, C2 fake: 0.000000], [G loss: 0.030600, mse: 0.026955]\n",
      "Epoch 597/10001\n",
      "[C1 valid: 0.007623, C2 fake: 0.000000], [G loss: 0.028388, mse: 0.025699]\n",
      "Epoch 598/10001\n",
      "[C1 valid: 0.007417, C2 fake: 0.000000], [G loss: 0.027921, mse: 0.025295]\n",
      "Epoch 599/10001\n",
      "[C1 valid: 0.008011, C2 fake: 0.000000], [G loss: 0.030185, mse: 0.027521]\n",
      "Epoch 600/10001\n",
      "[C1 valid: 0.007528, C2 fake: 0.000000], [G loss: 0.028990, mse: 0.026319]\n",
      "Epoch 601/10001\n",
      "[C1 valid: 0.009189, C2 fake: 0.000000], [G loss: 0.029198, mse: 0.026762]\n",
      "Epoch 602/10001\n",
      "[C1 valid: 0.008318, C2 fake: 0.000000], [G loss: 0.030677, mse: 0.028172]\n",
      "Epoch 603/10001\n",
      "[C1 valid: 0.008524, C2 fake: 0.000000], [G loss: 0.028891, mse: 0.026480]\n",
      "Epoch 604/10001\n",
      "[C1 valid: 0.007951, C2 fake: 0.000000], [G loss: 0.030898, mse: 0.028483]\n",
      "Epoch 605/10001\n",
      "[C1 valid: 0.007282, C2 fake: 0.000000], [G loss: 0.030331, mse: 0.027900]\n",
      "Epoch 606/10001\n",
      "[C1 valid: 0.007316, C2 fake: 0.000000], [G loss: 0.029772, mse: 0.027299]\n",
      "Epoch 607/10001\n",
      "[C1 valid: 0.007312, C2 fake: 0.000000], [G loss: 0.028528, mse: 0.026084]\n",
      "Epoch 608/10001\n",
      "[C1 valid: 0.008261, C2 fake: 0.000000], [G loss: 0.027037, mse: 0.024534]\n",
      "Epoch 609/10001\n",
      "[C1 valid: 0.008830, C2 fake: 0.000000], [G loss: 0.029661, mse: 0.027147]\n",
      "Epoch 610/10001\n",
      "[C1 valid: 0.009812, C2 fake: 0.000000], [G loss: 0.028607, mse: 0.026163]\n",
      "Epoch 611/10001\n",
      "[C1 valid: 0.007173, C2 fake: 0.000000], [G loss: 0.028170, mse: 0.025850]\n",
      "Epoch 612/10001\n",
      "[C1 valid: 0.008890, C2 fake: 0.000000], [G loss: 0.027866, mse: 0.025547]\n",
      "Epoch 613/10001\n",
      "[C1 valid: 0.008945, C2 fake: 0.000000], [G loss: 0.028600, mse: 0.026238]\n",
      "Epoch 614/10001\n",
      "[C1 valid: 0.007546, C2 fake: 0.000000], [G loss: 0.027947, mse: 0.025574]\n",
      "Epoch 615/10001\n",
      "[C1 valid: 0.007873, C2 fake: 0.000000], [G loss: 0.029138, mse: 0.026800]\n",
      "Epoch 616/10001\n",
      "[C1 valid: 0.008021, C2 fake: 0.000000], [G loss: 0.028358, mse: 0.026075]\n",
      "Epoch 617/10001\n",
      "[C1 valid: 0.008092, C2 fake: 0.000000], [G loss: 0.029971, mse: 0.027602]\n",
      "Epoch 618/10001\n",
      "[C1 valid: 0.007207, C2 fake: 0.000000], [G loss: 0.026466, mse: 0.024070]\n",
      "Epoch 619/10001\n",
      "[C1 valid: 0.007947, C2 fake: 0.000000], [G loss: 0.029044, mse: 0.026747]\n",
      "Epoch 620/10001\n",
      "[C1 valid: 0.009686, C2 fake: 0.000000], [G loss: 0.028376, mse: 0.026181]\n",
      "Epoch 621/10001\n",
      "[C1 valid: 0.008660, C2 fake: 0.000000], [G loss: 0.028241, mse: 0.026061]\n",
      "Epoch 622/10001\n",
      "[C1 valid: 0.010254, C2 fake: 0.000000], [G loss: 0.027642, mse: 0.025561]\n",
      "Epoch 623/10001\n",
      "[C1 valid: 0.008215, C2 fake: 0.000000], [G loss: 0.026495, mse: 0.024403]\n",
      "Epoch 624/10001\n",
      "[C1 valid: 0.008494, C2 fake: 0.000000], [G loss: 0.025975, mse: 0.023890]\n",
      "Epoch 625/10001\n",
      "[C1 valid: 0.006881, C2 fake: 0.000000], [G loss: 0.027283, mse: 0.025163]\n",
      "Epoch 626/10001\n",
      "[C1 valid: 0.007323, C2 fake: 0.000000], [G loss: 0.026689, mse: 0.024554]\n",
      "Epoch 627/10001\n",
      "[C1 valid: 0.007224, C2 fake: 0.000000], [G loss: 0.027437, mse: 0.025326]\n",
      "Epoch 628/10001\n",
      "[C1 valid: 0.006692, C2 fake: 0.000000], [G loss: 0.027456, mse: 0.025391]\n",
      "Epoch 629/10001\n",
      "[C1 valid: 0.020137, C2 fake: 0.000000], [G loss: 0.028794, mse: 0.026786]\n",
      "Epoch 630/10001\n",
      "[C1 valid: 0.008536, C2 fake: 0.000000], [G loss: 0.027302, mse: 0.025373]\n",
      "Epoch 631/10001\n",
      "[C1 valid: 0.008347, C2 fake: 0.000000], [G loss: 0.027274, mse: 0.025373]\n",
      "Epoch 632/10001\n",
      "[C1 valid: 0.008711, C2 fake: 0.000000], [G loss: 0.025965, mse: 0.024016]\n",
      "Epoch 633/10001\n",
      "[C1 valid: 0.008006, C2 fake: 0.000000], [G loss: 0.027108, mse: 0.025140]\n",
      "Epoch 634/10001\n",
      "[C1 valid: 0.007254, C2 fake: 0.000000], [G loss: 0.027681, mse: 0.025651]\n",
      "Epoch 635/10001\n",
      "[C1 valid: 0.008225, C2 fake: 0.000000], [G loss: 0.025921, mse: 0.023930]\n",
      "Epoch 636/10001\n",
      "[C1 valid: 0.007929, C2 fake: 0.000000], [G loss: 0.026684, mse: 0.024636]\n",
      "Epoch 637/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.008250, C2 fake: 0.000000], [G loss: 0.027241, mse: 0.025273]\n",
      "Epoch 638/10001\n",
      "[C1 valid: 0.008833, C2 fake: 0.000000], [G loss: 0.028456, mse: 0.026546]\n",
      "Epoch 639/10001\n",
      "[C1 valid: 0.009147, C2 fake: 0.000000], [G loss: 0.026531, mse: 0.024610]\n",
      "Epoch 640/10001\n",
      "[C1 valid: 0.008587, C2 fake: 0.000000], [G loss: 0.027894, mse: 0.026044]\n",
      "Epoch 641/10001\n",
      "[C1 valid: 0.008192, C2 fake: 0.000000], [G loss: 0.025620, mse: 0.022716]\n",
      "Epoch 642/10001\n",
      "[C1 valid: 0.006975, C2 fake: 0.000000], [G loss: 0.025097, mse: 0.023222]\n",
      "Epoch 643/10001\n",
      "[C1 valid: 0.008465, C2 fake: 0.000000], [G loss: 0.027023, mse: 0.025190]\n",
      "Epoch 644/10001\n",
      "[C1 valid: 0.014937, C2 fake: 0.000000], [G loss: 0.028853, mse: 0.027058]\n",
      "Epoch 645/10001\n",
      "[C1 valid: 0.009258, C2 fake: 0.000000], [G loss: 0.028230, mse: 0.026554]\n",
      "Epoch 646/10001\n",
      "[C1 valid: 0.008102, C2 fake: 0.000000], [G loss: 0.027386, mse: 0.024675]\n",
      "Epoch 647/10001\n",
      "[C1 valid: 0.008500, C2 fake: 0.000000], [G loss: 0.027676, mse: 0.025971]\n",
      "Epoch 648/10001\n",
      "[C1 valid: 0.007819, C2 fake: 0.000000], [G loss: 0.023764, mse: 0.022060]\n",
      "Epoch 649/10001\n",
      "[C1 valid: 0.008785, C2 fake: 0.000000], [G loss: 0.027907, mse: 0.026204]\n",
      "Epoch 650/10001\n",
      "[C1 valid: 0.007094, C2 fake: 0.000000], [G loss: 0.026223, mse: 0.024486]\n",
      "Epoch 651/10001\n",
      "[C1 valid: 0.008528, C2 fake: 0.000000], [G loss: 0.027288, mse: 0.025591]\n",
      "Epoch 652/10001\n",
      "[C1 valid: 0.008760, C2 fake: 0.000000], [G loss: 0.025557, mse: 0.023880]\n",
      "Epoch 653/10001\n",
      "[C1 valid: 0.006948, C2 fake: 0.000000], [G loss: 0.025225, mse: 0.023560]\n",
      "Epoch 654/10001\n",
      "[C1 valid: 0.008462, C2 fake: 0.000000], [G loss: 0.026433, mse: 0.024818]\n",
      "Epoch 655/10001\n",
      "[C1 valid: 0.008450, C2 fake: 0.000000], [G loss: 0.025512, mse: 0.023883]\n",
      "Epoch 656/10001\n",
      "[C1 valid: 0.007667, C2 fake: 0.000000], [G loss: 0.026773, mse: 0.025170]\n",
      "Epoch 657/10001\n",
      "[C1 valid: 0.008029, C2 fake: 0.000000], [G loss: 0.025772, mse: 0.024194]\n",
      "Epoch 658/10001\n",
      "[C1 valid: 0.007368, C2 fake: 0.000000], [G loss: 0.025437, mse: 0.023889]\n",
      "Epoch 659/10001\n",
      "[C1 valid: 0.009046, C2 fake: 0.000000], [G loss: 0.024256, mse: 0.022720]\n",
      "Epoch 660/10001\n",
      "[C1 valid: 0.008080, C2 fake: 0.000000], [G loss: 0.024860, mse: 0.023320]\n",
      "Epoch 661/10001\n",
      "[C1 valid: 0.007247, C2 fake: 0.000000], [G loss: 0.025967, mse: 0.024425]\n",
      "Epoch 662/10001\n",
      "[C1 valid: 0.007538, C2 fake: 0.000000], [G loss: 0.024118, mse: 0.022619]\n",
      "Epoch 663/10001\n",
      "[C1 valid: 0.006889, C2 fake: 0.000000], [G loss: 0.023596, mse: 0.022050]\n",
      "Epoch 664/10001\n",
      "[C1 valid: 0.006896, C2 fake: 0.000000], [G loss: 0.024516, mse: 0.022998]\n",
      "Epoch 665/10001\n",
      "[C1 valid: 0.006405, C2 fake: 0.000000], [G loss: 0.024776, mse: 0.023240]\n",
      "Epoch 666/10001\n",
      "[C1 valid: 0.007641, C2 fake: 0.000000], [G loss: 0.024107, mse: 0.022573]\n",
      "Epoch 667/10001\n",
      "[C1 valid: 0.006913, C2 fake: 0.000000], [G loss: 0.025486, mse: 0.023962]\n",
      "Epoch 668/10001\n",
      "[C1 valid: 0.006204, C2 fake: 0.000000], [G loss: 0.024905, mse: 0.022413]\n",
      "Epoch 669/10001\n",
      "[C1 valid: 0.007712, C2 fake: 0.000000], [G loss: 0.025568, mse: 0.024083]\n",
      "Epoch 670/10001\n",
      "[C1 valid: 0.006676, C2 fake: 0.000000], [G loss: 0.025962, mse: 0.024517]\n",
      "Epoch 671/10001\n",
      "[C1 valid: 0.008492, C2 fake: 0.000000], [G loss: 0.024482, mse: 0.023015]\n",
      "Epoch 672/10001\n",
      "[C1 valid: 0.006901, C2 fake: 0.000000], [G loss: 0.024751, mse: 0.023296]\n",
      "Epoch 673/10001\n",
      "[C1 valid: 0.008043, C2 fake: 0.000000], [G loss: 0.024205, mse: 0.022781]\n",
      "Epoch 674/10001\n",
      "[C1 valid: 0.007696, C2 fake: 0.000000], [G loss: 0.027168, mse: 0.024730]\n",
      "Epoch 675/10001\n",
      "[C1 valid: 0.006523, C2 fake: 0.000000], [G loss: 0.026356, mse: 0.023944]\n",
      "Epoch 676/10001\n",
      "[C1 valid: 0.006613, C2 fake: 0.000000], [G loss: 0.023960, mse: 0.022543]\n",
      "Epoch 677/10001\n",
      "[C1 valid: 0.006117, C2 fake: 0.000000], [G loss: 0.024608, mse: 0.023159]\n",
      "Epoch 678/10001\n",
      "[C1 valid: 0.006545, C2 fake: 0.000000], [G loss: 0.025054, mse: 0.023647]\n",
      "Epoch 679/10001\n",
      "[C1 valid: 0.006207, C2 fake: 0.000000], [G loss: 0.024953, mse: 0.023518]\n",
      "Epoch 680/10001\n",
      "[C1 valid: 0.007741, C2 fake: 0.000000], [G loss: 0.025467, mse: 0.024071]\n",
      "Epoch 681/10001\n",
      "[C1 valid: 0.006290, C2 fake: 0.000000], [G loss: 0.025531, mse: 0.024146]\n",
      "Epoch 682/10001\n",
      "[C1 valid: 0.005476, C2 fake: 0.000000], [G loss: 0.024349, mse: 0.022930]\n",
      "Epoch 683/10001\n",
      "[C1 valid: 0.006378, C2 fake: 0.000000], [G loss: 0.025330, mse: 0.023918]\n",
      "Epoch 684/10001\n",
      "[C1 valid: 0.005334, C2 fake: 0.000000], [G loss: 0.024487, mse: 0.023061]\n",
      "Epoch 685/10001\n",
      "[C1 valid: 0.006690, C2 fake: 0.000000], [G loss: 0.026757, mse: 0.024373]\n",
      "Epoch 686/10001\n",
      "[C1 valid: 0.007614, C2 fake: 0.000000], [G loss: 0.025381, mse: 0.023973]\n",
      "Epoch 687/10001\n",
      "[C1 valid: 0.005972, C2 fake: 0.000000], [G loss: 0.024203, mse: 0.022783]\n",
      "Epoch 688/10001\n",
      "[C1 valid: 0.006235, C2 fake: 0.000000], [G loss: 0.025397, mse: 0.023949]\n",
      "Epoch 689/10001\n",
      "[C1 valid: 0.007275, C2 fake: 0.000000], [G loss: 0.025850, mse: 0.024455]\n",
      "Epoch 690/10001\n",
      "[C1 valid: 0.006851, C2 fake: 0.000000], [G loss: 0.022759, mse: 0.021282]\n",
      "Epoch 691/10001\n",
      "[C1 valid: 0.007158, C2 fake: 0.000000], [G loss: 0.025727, mse: 0.024231]\n",
      "Epoch 692/10001\n",
      "[C1 valid: 0.006820, C2 fake: 0.000000], [G loss: 0.025168, mse: 0.023757]\n",
      "Epoch 693/10001\n",
      "[C1 valid: 0.006018, C2 fake: 0.000000], [G loss: 0.024655, mse: 0.023213]\n",
      "Epoch 694/10001\n",
      "[C1 valid: 0.006709, C2 fake: 0.000000], [G loss: 0.023968, mse: 0.022551]\n",
      "Epoch 695/10001\n",
      "[C1 valid: 0.005801, C2 fake: 0.000000], [G loss: 0.024833, mse: 0.023450]\n",
      "Epoch 696/10001\n",
      "[C1 valid: 0.009313, C2 fake: 0.000000], [G loss: 0.023393, mse: 0.022096]\n",
      "Epoch 697/10001\n",
      "[C1 valid: 0.006779, C2 fake: 0.000000], [G loss: 0.024736, mse: 0.023442]\n",
      "Epoch 698/10001\n",
      "[C1 valid: 0.006166, C2 fake: 0.000000], [G loss: 0.024676, mse: 0.023334]\n",
      "Epoch 699/10001\n",
      "[C1 valid: 0.006933, C2 fake: 0.000000], [G loss: 0.024884, mse: 0.023564]\n",
      "Epoch 700/10001\n",
      "[C1 valid: 0.006473, C2 fake: 0.000000], [G loss: 0.024224, mse: 0.022839]\n",
      "Epoch 701/10001\n",
      "[C1 valid: 0.007422, C2 fake: 0.000000], [G loss: 0.024070, mse: 0.022706]\n",
      "Epoch 702/10001\n",
      "[C1 valid: 0.007234, C2 fake: 0.000000], [G loss: 0.023832, mse: 0.022410]\n",
      "Epoch 703/10001\n",
      "[C1 valid: 0.006309, C2 fake: 0.000000], [G loss: 0.024133, mse: 0.022771]\n",
      "Epoch 704/10001\n",
      "[C1 valid: 0.007498, C2 fake: 0.000000], [G loss: 0.022006, mse: 0.020676]\n",
      "Epoch 705/10001\n",
      "[C1 valid: 0.006806, C2 fake: 0.000000], [G loss: 0.023194, mse: 0.021874]\n",
      "Epoch 706/10001\n",
      "[C1 valid: 0.006523, C2 fake: 0.000000], [G loss: 0.022820, mse: 0.021507]\n",
      "Epoch 707/10001\n",
      "[C1 valid: 0.006025, C2 fake: 0.000000], [G loss: 0.024642, mse: 0.023296]\n",
      "Epoch 708/10001\n",
      "[C1 valid: 0.005475, C2 fake: 0.000000], [G loss: 0.024802, mse: 0.023428]\n",
      "Epoch 709/10001\n",
      "[C1 valid: 0.006233, C2 fake: 0.000000], [G loss: 0.025059, mse: 0.023745]\n",
      "Epoch 710/10001\n",
      "[C1 valid: 0.005841, C2 fake: 0.000000], [G loss: 0.023115, mse: 0.021791]\n",
      "Epoch 711/10001\n",
      "[C1 valid: 0.007169, C2 fake: 0.000000], [G loss: 0.023740, mse: 0.022420]\n",
      "Epoch 712/10001\n",
      "[C1 valid: 0.007806, C2 fake: 0.000000], [G loss: 0.024035, mse: 0.022825]\n",
      "Epoch 713/10001\n",
      "[C1 valid: 0.005543, C2 fake: 0.000000], [G loss: 0.022846, mse: 0.021601]\n",
      "Epoch 714/10001\n",
      "[C1 valid: 0.004916, C2 fake: 0.000000], [G loss: 0.023695, mse: 0.022436]\n",
      "Epoch 715/10001\n",
      "[C1 valid: 0.005977, C2 fake: 0.000000], [G loss: 0.024281, mse: 0.023015]\n",
      "Epoch 716/10001\n",
      "[C1 valid: 0.007531, C2 fake: 0.000000], [G loss: 0.023808, mse: 0.022566]\n",
      "Epoch 717/10001\n",
      "[C1 valid: 0.006729, C2 fake: 0.000000], [G loss: 0.023333, mse: 0.022116]\n",
      "Epoch 718/10001\n",
      "[C1 valid: 0.005789, C2 fake: 0.000000], [G loss: 0.022610, mse: 0.021366]\n",
      "Epoch 719/10001\n",
      "[C1 valid: 0.007016, C2 fake: 0.000000], [G loss: 0.023041, mse: 0.021823]\n",
      "Epoch 720/10001\n",
      "[C1 valid: 0.005470, C2 fake: 0.000000], [G loss: 0.023231, mse: 0.022011]\n",
      "Epoch 721/10001\n",
      "[C1 valid: 0.006175, C2 fake: 0.000000], [G loss: 0.024632, mse: 0.023439]\n",
      "Epoch 722/10001\n",
      "[C1 valid: 0.006711, C2 fake: 0.000000], [G loss: 0.023594, mse: 0.022386]\n",
      "Epoch 723/10001\n",
      "[C1 valid: 0.005602, C2 fake: 0.000000], [G loss: 0.022704, mse: 0.021528]\n",
      "Epoch 724/10001\n",
      "[C1 valid: 0.005586, C2 fake: 0.000000], [G loss: 0.022775, mse: 0.021576]\n",
      "Epoch 725/10001\n",
      "[C1 valid: 0.004784, C2 fake: 0.000000], [G loss: 0.022817, mse: 0.021619]\n",
      "Epoch 726/10001\n",
      "[C1 valid: 0.005308, C2 fake: 0.000000], [G loss: 0.023494, mse: 0.022284]\n",
      "Epoch 727/10001\n",
      "[C1 valid: 0.004736, C2 fake: 0.000000], [G loss: 0.023585, mse: 0.022354]\n",
      "Epoch 728/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.005844, C2 fake: 0.000000], [G loss: 0.023353, mse: 0.022141]\n",
      "Epoch 729/10001\n",
      "[C1 valid: 0.005973, C2 fake: 0.000000], [G loss: 0.022054, mse: 0.020827]\n",
      "Epoch 730/10001\n",
      "[C1 valid: 0.005228, C2 fake: 0.000000], [G loss: 0.023029, mse: 0.021789]\n",
      "Epoch 731/10001\n",
      "[C1 valid: 0.005378, C2 fake: 0.000000], [G loss: 0.021342, mse: 0.020125]\n",
      "Epoch 732/10001\n",
      "[C1 valid: 0.005389, C2 fake: 0.000000], [G loss: 0.023201, mse: 0.021989]\n",
      "Epoch 733/10001\n",
      "[C1 valid: 0.007140, C2 fake: 0.000000], [G loss: 0.024248, mse: 0.023062]\n",
      "Epoch 734/10001\n",
      "[C1 valid: 0.005546, C2 fake: 0.000000], [G loss: 0.022536, mse: 0.021406]\n",
      "Epoch 735/10001\n",
      "[C1 valid: 0.004943, C2 fake: 0.000000], [G loss: 0.022072, mse: 0.020894]\n",
      "Epoch 736/10001\n",
      "[C1 valid: 0.006105, C2 fake: 0.000000], [G loss: 0.025216, mse: 0.024039]\n",
      "Epoch 737/10001\n",
      "[C1 valid: 0.009943, C2 fake: 0.000000], [G loss: 0.022075, mse: 0.020887]\n",
      "Epoch 738/10001\n",
      "[C1 valid: 0.005741, C2 fake: 0.000000], [G loss: 0.021921, mse: 0.020764]\n",
      "Epoch 739/10001\n",
      "[C1 valid: 0.006073, C2 fake: 0.000000], [G loss: 0.023229, mse: 0.022076]\n",
      "Epoch 740/10001\n",
      "[C1 valid: 0.005615, C2 fake: 0.000000], [G loss: 0.022904, mse: 0.021718]\n",
      "Epoch 741/10001\n",
      "[C1 valid: 0.005566, C2 fake: 0.000000], [G loss: 0.021619, mse: 0.020391]\n",
      "Epoch 742/10001\n",
      "[C1 valid: 0.006460, C2 fake: 0.000000], [G loss: 0.023998, mse: 0.022774]\n",
      "Epoch 743/10001\n",
      "[C1 valid: 0.004680, C2 fake: 0.000000], [G loss: 0.022992, mse: 0.021783]\n",
      "Epoch 744/10001\n",
      "[C1 valid: 0.006195, C2 fake: 0.000000], [G loss: 0.022671, mse: 0.021498]\n",
      "Epoch 745/10001\n",
      "[C1 valid: 0.004446, C2 fake: 0.000000], [G loss: 0.024147, mse: 0.022967]\n",
      "Epoch 746/10001\n",
      "[C1 valid: 0.005183, C2 fake: 0.000000], [G loss: 0.022082, mse: 0.020919]\n",
      "Epoch 747/10001\n",
      "[C1 valid: 0.004725, C2 fake: 0.000000], [G loss: 0.021965, mse: 0.020854]\n",
      "Epoch 748/10001\n",
      "[C1 valid: 0.006800, C2 fake: 0.000000], [G loss: 0.023290, mse: 0.022142]\n",
      "Epoch 749/10001\n",
      "[C1 valid: 0.004919, C2 fake: 0.000000], [G loss: 0.022906, mse: 0.021806]\n",
      "Epoch 750/10001\n",
      "[C1 valid: 0.005968, C2 fake: 0.000000], [G loss: 0.021857, mse: 0.020751]\n",
      "Epoch 751/10001\n",
      "[C1 valid: 0.005439, C2 fake: 0.000000], [G loss: 0.021132, mse: 0.020050]\n",
      "Epoch 752/10001\n",
      "[C1 valid: 0.005609, C2 fake: 0.000000], [G loss: 0.020849, mse: 0.019805]\n",
      "Epoch 753/10001\n",
      "[C1 valid: 0.005916, C2 fake: 0.000000], [G loss: 0.023808, mse: 0.022740]\n",
      "Epoch 754/10001\n",
      "[C1 valid: 0.005008, C2 fake: 0.000000], [G loss: 0.020760, mse: 0.019741]\n",
      "Epoch 755/10001\n",
      "[C1 valid: 0.006256, C2 fake: 0.000000], [G loss: 0.022676, mse: 0.021596]\n",
      "Epoch 756/10001\n",
      "[C1 valid: 0.004437, C2 fake: 0.000000], [G loss: 0.021494, mse: 0.020424]\n",
      "Epoch 757/10001\n",
      "[C1 valid: 0.006053, C2 fake: 0.000000], [G loss: 0.022985, mse: 0.021922]\n",
      "Epoch 758/10001\n",
      "[C1 valid: 0.005232, C2 fake: 0.000000], [G loss: 0.021689, mse: 0.020646]\n",
      "Epoch 759/10001\n",
      "[C1 valid: 0.005336, C2 fake: 0.000000], [G loss: 0.021518, mse: 0.020475]\n",
      "Epoch 760/10001\n",
      "[C1 valid: 0.006883, C2 fake: 0.000000], [G loss: 0.021104, mse: 0.020065]\n",
      "Epoch 761/10001\n",
      "[C1 valid: 0.004956, C2 fake: 0.000000], [G loss: 0.021382, mse: 0.020324]\n",
      "Epoch 762/10001\n",
      "[C1 valid: 0.004651, C2 fake: 0.000000], [G loss: 0.022781, mse: 0.021764]\n",
      "Epoch 763/10001\n",
      "[C1 valid: 0.004316, C2 fake: 0.000000], [G loss: 0.021632, mse: 0.020605]\n",
      "Epoch 764/10001\n",
      "[C1 valid: 0.005699, C2 fake: 0.000000], [G loss: 0.022468, mse: 0.021464]\n",
      "Epoch 765/10001\n",
      "[C1 valid: 0.004830, C2 fake: 0.000000], [G loss: 0.021887, mse: 0.020890]\n",
      "Epoch 766/10001\n",
      "[C1 valid: 0.004588, C2 fake: 0.000000], [G loss: 0.022433, mse: 0.021463]\n",
      "Epoch 767/10001\n",
      "[C1 valid: 0.005427, C2 fake: 0.000000], [G loss: 0.023391, mse: 0.022412]\n",
      "Epoch 768/10001\n",
      "[C1 valid: 0.004159, C2 fake: 0.000000], [G loss: 0.022259, mse: 0.021260]\n",
      "Epoch 769/10001\n",
      "[C1 valid: 0.005613, C2 fake: 0.000000], [G loss: 0.021765, mse: 0.020804]\n",
      "Epoch 770/10001\n",
      "[C1 valid: 0.004463, C2 fake: 0.000000], [G loss: 0.023026, mse: 0.022043]\n",
      "Epoch 771/10001\n",
      "[C1 valid: 0.006114, C2 fake: 0.000000], [G loss: 0.022436, mse: 0.021485]\n",
      "Epoch 772/10001\n",
      "[C1 valid: 0.005664, C2 fake: 0.000000], [G loss: 0.020996, mse: 0.020043]\n",
      "Epoch 773/10001\n",
      "[C1 valid: 0.004833, C2 fake: 0.000000], [G loss: 0.020891, mse: 0.019956]\n",
      "Epoch 774/10001\n",
      "[C1 valid: 0.005456, C2 fake: 0.000000], [G loss: 0.020424, mse: 0.019501]\n",
      "Epoch 775/10001\n",
      "[C1 valid: 0.030301, C2 fake: 0.000000], [G loss: 0.021364, mse: 0.020540]\n",
      "Epoch 776/10001\n",
      "[C1 valid: 0.006133, C2 fake: 0.000000], [G loss: 0.021940, mse: 0.021145]\n",
      "Epoch 777/10001\n",
      "[C1 valid: 0.005467, C2 fake: 0.000000], [G loss: 0.020413, mse: 0.019650]\n",
      "Epoch 778/10001\n",
      "[C1 valid: 0.006107, C2 fake: 0.000000], [G loss: 0.022263, mse: 0.021485]\n",
      "Epoch 779/10001\n",
      "[C1 valid: 0.005349, C2 fake: 0.000000], [G loss: 0.019957, mse: 0.019183]\n",
      "Epoch 780/10001\n",
      "[C1 valid: 0.005899, C2 fake: 0.000000], [G loss: 0.021109, mse: 0.020315]\n",
      "Epoch 781/10001\n",
      "[C1 valid: 0.005556, C2 fake: 0.000000], [G loss: 0.021406, mse: 0.020608]\n",
      "Epoch 782/10001\n",
      "[C1 valid: 0.005635, C2 fake: 0.000000], [G loss: 0.021668, mse: 0.020875]\n",
      "Epoch 783/10001\n",
      "[C1 valid: 0.006110, C2 fake: 0.000000], [G loss: 0.019924, mse: 0.019129]\n",
      "Epoch 784/10001\n",
      "[C1 valid: 0.006409, C2 fake: 0.000000], [G loss: 0.021919, mse: 0.020100]\n",
      "Epoch 785/10001\n",
      "[C1 valid: 0.005431, C2 fake: 0.000000], [G loss: 0.021594, mse: 0.020787]\n",
      "Epoch 786/10001\n",
      "[C1 valid: 0.005203, C2 fake: 0.000000], [G loss: 0.021554, mse: 0.020734]\n",
      "Epoch 787/10001\n",
      "[C1 valid: 0.005445, C2 fake: 0.000000], [G loss: 0.020048, mse: 0.019221]\n",
      "Epoch 788/10001\n",
      "[C1 valid: 0.004911, C2 fake: 0.000000], [G loss: 0.021729, mse: 0.020897]\n",
      "Epoch 789/10001\n",
      "[C1 valid: 0.005193, C2 fake: 0.000000], [G loss: 0.020851, mse: 0.020024]\n",
      "Epoch 790/10001\n",
      "[C1 valid: 0.004913, C2 fake: 0.000000], [G loss: 0.022005, mse: 0.020142]\n",
      "Epoch 791/10001\n",
      "[C1 valid: 0.004648, C2 fake: 0.000000], [G loss: 0.021685, mse: 0.019859]\n",
      "Epoch 792/10001\n",
      "[C1 valid: 0.005531, C2 fake: 0.000000], [G loss: 0.021543, mse: 0.019713]\n",
      "Epoch 793/10001\n",
      "[C1 valid: 0.004852, C2 fake: 0.000000], [G loss: 0.021025, mse: 0.020182]\n",
      "Epoch 794/10001\n",
      "[C1 valid: 0.004329, C2 fake: 0.000000], [G loss: 0.020825, mse: 0.019981]\n",
      "Epoch 795/10001\n",
      "[C1 valid: 0.004342, C2 fake: 0.000000], [G loss: 0.023152, mse: 0.021309]\n",
      "Epoch 796/10001\n",
      "[C1 valid: 0.004773, C2 fake: 0.000000], [G loss: 0.020825, mse: 0.019972]\n",
      "Epoch 797/10001\n",
      "[C1 valid: 0.004803, C2 fake: 0.000000], [G loss: 0.020964, mse: 0.020162]\n",
      "Epoch 798/10001\n",
      "[C1 valid: 0.003887, C2 fake: 0.000000], [G loss: 0.021359, mse: 0.020548]\n",
      "Epoch 799/10001\n",
      "[C1 valid: 0.005021, C2 fake: 0.000000], [G loss: 0.021543, mse: 0.020735]\n",
      "Epoch 800/10001\n",
      "[C1 valid: 0.012202, C2 fake: 0.000000], [G loss: 0.019904, mse: 0.019099]\n",
      "Epoch 801/10001\n",
      "[C1 valid: 0.004629, C2 fake: 0.000000], [G loss: 0.019506, mse: 0.018738]\n",
      "Epoch 802/10001\n",
      "[C1 valid: 0.004891, C2 fake: 0.000000], [G loss: 0.019973, mse: 0.019222]\n",
      "Epoch 803/10001\n",
      "[C1 valid: 0.005027, C2 fake: 0.000000], [G loss: 0.019634, mse: 0.018849]\n",
      "Epoch 804/10001\n",
      "[C1 valid: 0.005063, C2 fake: 0.000000], [G loss: 0.021663, mse: 0.020912]\n",
      "Epoch 805/10001\n",
      "[C1 valid: 0.006276, C2 fake: 0.000000], [G loss: 0.021170, mse: 0.020419]\n",
      "Epoch 806/10001\n",
      "[C1 valid: 0.006275, C2 fake: 0.000000], [G loss: 0.020435, mse: 0.019710]\n",
      "Epoch 807/10001\n",
      "[C1 valid: 0.006214, C2 fake: 0.000000], [G loss: 0.021999, mse: 0.021282]\n",
      "Epoch 808/10001\n",
      "[C1 valid: 0.005448, C2 fake: 0.000000], [G loss: 0.019687, mse: 0.018967]\n",
      "Epoch 809/10001\n",
      "[C1 valid: 0.005257, C2 fake: 0.000000], [G loss: 0.019474, mse: 0.018766]\n",
      "Epoch 810/10001\n",
      "[C1 valid: 0.006014, C2 fake: 0.000000], [G loss: 0.020639, mse: 0.019938]\n",
      "Epoch 811/10001\n",
      "[C1 valid: 0.005087, C2 fake: 0.000000], [G loss: 0.020565, mse: 0.019848]\n",
      "Epoch 812/10001\n",
      "[C1 valid: 0.004892, C2 fake: 0.000000], [G loss: 0.019444, mse: 0.018748]\n",
      "Epoch 813/10001\n",
      "[C1 valid: 0.005451, C2 fake: 0.000000], [G loss: 0.020818, mse: 0.020134]\n",
      "Epoch 814/10001\n",
      "[C1 valid: 0.004888, C2 fake: 0.000000], [G loss: 0.020366, mse: 0.019670]\n",
      "Epoch 815/10001\n",
      "[C1 valid: 0.006179, C2 fake: 0.000000], [G loss: 0.020265, mse: 0.019566]\n",
      "Epoch 816/10001\n",
      "[C1 valid: 0.005397, C2 fake: 0.000000], [G loss: 0.021183, mse: 0.020449]\n",
      "Epoch 817/10001\n",
      "[C1 valid: 0.005739, C2 fake: 0.000000], [G loss: 0.019588, mse: 0.018903]\n",
      "Epoch 818/10001\n",
      "[C1 valid: 0.005092, C2 fake: 0.000000], [G loss: 0.021316, mse: 0.020618]\n",
      "Epoch 819/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.004715, C2 fake: 0.000000], [G loss: 0.019713, mse: 0.019025]\n",
      "Epoch 820/10001\n",
      "[C1 valid: 0.003959, C2 fake: 0.000000], [G loss: 0.019738, mse: 0.019057]\n",
      "Epoch 821/10001\n",
      "[C1 valid: 0.004355, C2 fake: 0.000000], [G loss: 0.020383, mse: 0.019691]\n",
      "Epoch 822/10001\n",
      "[C1 valid: 0.004316, C2 fake: 0.000000], [G loss: 0.019953, mse: 0.019275]\n",
      "Epoch 823/10001\n",
      "[C1 valid: 0.004299, C2 fake: 0.000000], [G loss: 0.021660, mse: 0.020963]\n",
      "Epoch 824/10001\n",
      "[C1 valid: 0.004973, C2 fake: 0.000000], [G loss: 0.019035, mse: 0.018352]\n",
      "Epoch 825/10001\n",
      "[C1 valid: 0.005030, C2 fake: 0.000000], [G loss: 0.019658, mse: 0.018978]\n",
      "Epoch 826/10001\n",
      "[C1 valid: 0.004697, C2 fake: 0.000000], [G loss: 0.020107, mse: 0.019415]\n",
      "Epoch 827/10001\n",
      "[C1 valid: 0.005823, C2 fake: 0.000000], [G loss: 0.020436, mse: 0.019764]\n",
      "Epoch 828/10001\n",
      "[C1 valid: 0.005837, C2 fake: 0.000000], [G loss: 0.019964, mse: 0.019296]\n",
      "Epoch 829/10001\n",
      "[C1 valid: 0.004520, C2 fake: 0.000000], [G loss: 0.019495, mse: 0.018817]\n",
      "Epoch 830/10001\n",
      "[C1 valid: 0.004841, C2 fake: 0.000000], [G loss: 0.020073, mse: 0.019391]\n",
      "Epoch 831/10001\n",
      "[C1 valid: 0.003761, C2 fake: 0.000000], [G loss: 0.019145, mse: 0.018485]\n",
      "Epoch 832/10001\n",
      "[C1 valid: 0.005751, C2 fake: 0.000000], [G loss: 0.020141, mse: 0.019499]\n",
      "Epoch 833/10001\n",
      "[C1 valid: 0.005772, C2 fake: 0.000000], [G loss: 0.020830, mse: 0.019204]\n",
      "Epoch 834/10001\n",
      "[C1 valid: 0.005008, C2 fake: 0.000000], [G loss: 0.021129, mse: 0.020514]\n",
      "Epoch 835/10001\n",
      "[C1 valid: 0.005930, C2 fake: 0.000000], [G loss: 0.019003, mse: 0.018379]\n",
      "Epoch 836/10001\n",
      "[C1 valid: 0.005539, C2 fake: 0.000000], [G loss: 0.019950, mse: 0.019308]\n",
      "Epoch 837/10001\n",
      "[C1 valid: 0.005412, C2 fake: 0.000000], [G loss: 0.019568, mse: 0.018913]\n",
      "Epoch 838/10001\n",
      "[C1 valid: 0.004459, C2 fake: 0.000000], [G loss: 0.019129, mse: 0.018490]\n",
      "Epoch 839/10001\n",
      "[C1 valid: 0.004208, C2 fake: 0.000000], [G loss: 0.020948, mse: 0.020313]\n",
      "Epoch 840/10001\n",
      "[C1 valid: 0.004702, C2 fake: 0.000000], [G loss: 0.019374, mse: 0.018746]\n",
      "Epoch 841/10001\n",
      "[C1 valid: 0.004226, C2 fake: 0.000000], [G loss: 0.019487, mse: 0.018863]\n",
      "Epoch 842/10001\n",
      "[C1 valid: 0.004226, C2 fake: 0.000000], [G loss: 0.019596, mse: 0.018961]\n",
      "Epoch 843/10001\n",
      "[C1 valid: 0.004471, C2 fake: 0.000000], [G loss: 0.019530, mse: 0.018880]\n",
      "Epoch 844/10001\n",
      "[C1 valid: 0.004398, C2 fake: 0.000000], [G loss: 0.020706, mse: 0.020075]\n",
      "Epoch 845/10001\n",
      "[C1 valid: 0.005074, C2 fake: 0.000000], [G loss: 0.018598, mse: 0.017966]\n",
      "Epoch 846/10001\n",
      "[C1 valid: 0.005391, C2 fake: 0.000000], [G loss: 0.019452, mse: 0.018812]\n",
      "Epoch 847/10001\n",
      "[C1 valid: 0.006430, C2 fake: 0.000000], [G loss: 0.019069, mse: 0.018404]\n",
      "Epoch 848/10001\n",
      "[C1 valid: 0.004789, C2 fake: 0.000000], [G loss: 0.019118, mse: 0.018467]\n",
      "Epoch 849/10001\n",
      "[C1 valid: 0.004604, C2 fake: 0.000000], [G loss: 0.019007, mse: 0.018358]\n",
      "Epoch 850/10001\n",
      "[C1 valid: 0.004117, C2 fake: 0.000000], [G loss: 0.018929, mse: 0.018289]\n",
      "Epoch 851/10001\n",
      "[C1 valid: 0.003965, C2 fake: 0.000000], [G loss: 0.019266, mse: 0.018618]\n",
      "Epoch 852/10001\n",
      "[C1 valid: 0.004884, C2 fake: 0.000000], [G loss: 0.019139, mse: 0.018501]\n",
      "Epoch 853/10001\n",
      "[C1 valid: 0.004839, C2 fake: 0.000000], [G loss: 0.020111, mse: 0.019488]\n",
      "Epoch 854/10001\n",
      "[C1 valid: 0.004805, C2 fake: 0.000000], [G loss: 0.021063, mse: 0.020428]\n",
      "Epoch 855/10001\n",
      "[C1 valid: 0.004261, C2 fake: 0.000000], [G loss: 0.019499, mse: 0.018869]\n",
      "Epoch 856/10001\n",
      "[C1 valid: 0.004182, C2 fake: 0.000000], [G loss: 0.019519, mse: 0.018880]\n",
      "Epoch 857/10001\n",
      "[C1 valid: 0.004678, C2 fake: 0.000000], [G loss: 0.019276, mse: 0.018639]\n",
      "Epoch 858/10001\n",
      "[C1 valid: 0.004386, C2 fake: 0.000000], [G loss: 0.018499, mse: 0.017884]\n",
      "Epoch 859/10001\n",
      "[C1 valid: 0.004063, C2 fake: 0.000000], [G loss: 0.019280, mse: 0.018657]\n",
      "Epoch 860/10001\n",
      "[C1 valid: 0.003258, C2 fake: 0.000000], [G loss: 0.018912, mse: 0.018300]\n",
      "Epoch 861/10001\n",
      "[C1 valid: 0.004207, C2 fake: 0.000000], [G loss: 0.019721, mse: 0.019122]\n",
      "Epoch 862/10001\n",
      "[C1 valid: 0.003865, C2 fake: 0.000000], [G loss: 0.017353, mse: 0.016743]\n",
      "Epoch 863/10001\n",
      "[C1 valid: 0.003830, C2 fake: 0.000000], [G loss: 0.019324, mse: 0.018706]\n",
      "Epoch 864/10001\n",
      "[C1 valid: 0.004780, C2 fake: 0.000000], [G loss: 0.018873, mse: 0.018250]\n",
      "Epoch 865/10001\n",
      "[C1 valid: 0.004905, C2 fake: 0.000000], [G loss: 0.019240, mse: 0.018634]\n",
      "Epoch 866/10001\n",
      "[C1 valid: 0.004127, C2 fake: 0.000000], [G loss: 0.019038, mse: 0.018429]\n",
      "Epoch 867/10001\n",
      "[C1 valid: 0.004368, C2 fake: 0.000000], [G loss: 0.018846, mse: 0.018245]\n",
      "Epoch 868/10001\n",
      "[C1 valid: 0.004359, C2 fake: 0.000000], [G loss: 0.020206, mse: 0.019580]\n",
      "Epoch 869/10001\n",
      "[C1 valid: 0.004537, C2 fake: 0.000000], [G loss: 0.018613, mse: 0.018018]\n",
      "Epoch 870/10001\n",
      "[C1 valid: 0.004561, C2 fake: 0.000000], [G loss: 0.018362, mse: 0.017776]\n",
      "Epoch 871/10001\n",
      "[C1 valid: 0.003387, C2 fake: 0.000000], [G loss: 0.018278, mse: 0.017683]\n",
      "Epoch 872/10001\n",
      "[C1 valid: 0.003988, C2 fake: 0.000000], [G loss: 0.019105, mse: 0.018510]\n",
      "Epoch 873/10001\n",
      "[C1 valid: 0.004155, C2 fake: 0.000000], [G loss: 0.018408, mse: 0.017820]\n",
      "Epoch 874/10001\n",
      "[C1 valid: 0.005336, C2 fake: 0.000000], [G loss: 0.019186, mse: 0.018598]\n",
      "Epoch 875/10001\n",
      "[C1 valid: 0.003752, C2 fake: 0.000000], [G loss: 0.019570, mse: 0.018977]\n",
      "Epoch 876/10001\n",
      "[C1 valid: 0.003837, C2 fake: 0.000000], [G loss: 0.018637, mse: 0.018061]\n",
      "Epoch 877/10001\n",
      "[C1 valid: 0.004550, C2 fake: 0.000000], [G loss: 0.018658, mse: 0.018075]\n",
      "Epoch 878/10001\n",
      "[C1 valid: 0.010519, C2 fake: 0.000000], [G loss: 0.018446, mse: 0.017872]\n",
      "Epoch 879/10001\n",
      "[C1 valid: 0.004134, C2 fake: 0.000000], [G loss: 0.017340, mse: 0.016767]\n",
      "Epoch 880/10001\n",
      "[C1 valid: 0.004768, C2 fake: 0.000000], [G loss: 0.018677, mse: 0.018128]\n",
      "Epoch 881/10001\n",
      "[C1 valid: 0.004283, C2 fake: 0.000000], [G loss: 0.017165, mse: 0.016629]\n",
      "Epoch 882/10001\n",
      "[C1 valid: 0.003924, C2 fake: 0.000000], [G loss: 0.018059, mse: 0.017542]\n",
      "Epoch 883/10001\n",
      "[C1 valid: 0.004019, C2 fake: 0.000000], [G loss: 0.019066, mse: 0.018517]\n",
      "Epoch 884/10001\n",
      "[C1 valid: 0.003767, C2 fake: 0.000000], [G loss: 0.018968, mse: 0.018430]\n",
      "Epoch 885/10001\n",
      "[C1 valid: 0.003503, C2 fake: 0.000000], [G loss: 0.018946, mse: 0.018421]\n",
      "Epoch 886/10001\n",
      "[C1 valid: 0.003924, C2 fake: 0.000000], [G loss: 0.018896, mse: 0.018381]\n",
      "Epoch 887/10001\n",
      "[C1 valid: 0.005013, C2 fake: 0.000000], [G loss: 0.018801, mse: 0.018286]\n",
      "Epoch 888/10001\n",
      "[C1 valid: 0.003778, C2 fake: 0.000000], [G loss: 0.018995, mse: 0.018495]\n",
      "Epoch 889/10001\n",
      "[C1 valid: 0.006722, C2 fake: 0.000000], [G loss: 0.018706, mse: 0.018208]\n",
      "Epoch 890/10001\n",
      "[C1 valid: 0.004442, C2 fake: 0.000000], [G loss: 0.017376, mse: 0.016883]\n",
      "Epoch 891/10001\n",
      "[C1 valid: 0.003894, C2 fake: 0.000000], [G loss: 0.017894, mse: 0.017400]\n",
      "Epoch 892/10001\n",
      "[C1 valid: 0.004558, C2 fake: 0.000000], [G loss: 0.019416, mse: 0.018933]\n",
      "Epoch 893/10001\n",
      "[C1 valid: 0.004543, C2 fake: 0.000000], [G loss: 0.017978, mse: 0.017482]\n",
      "Epoch 894/10001\n",
      "[C1 valid: 0.004191, C2 fake: 0.000000], [G loss: 0.018436, mse: 0.017941]\n",
      "Epoch 895/10001\n",
      "[C1 valid: 0.004395, C2 fake: 0.000000], [G loss: 0.018117, mse: 0.017626]\n",
      "Epoch 896/10001\n",
      "[C1 valid: 0.004887, C2 fake: 0.000000], [G loss: 0.018496, mse: 0.017996]\n",
      "Epoch 897/10001\n",
      "[C1 valid: 0.005274, C2 fake: 0.000000], [G loss: 0.017761, mse: 0.017291]\n",
      "Epoch 898/10001\n",
      "[C1 valid: 0.003748, C2 fake: 0.000000], [G loss: 0.019727, mse: 0.019191]\n",
      "Epoch 899/10001\n",
      "[C1 valid: 0.003460, C2 fake: 0.000000], [G loss: 0.018688, mse: 0.018202]\n",
      "Epoch 900/10001\n",
      "[C1 valid: 0.004283, C2 fake: 0.000000], [G loss: 0.016962, mse: 0.016477]\n",
      "Epoch 901/10001\n",
      "[C1 valid: 0.003918, C2 fake: 0.000000], [G loss: 0.017687, mse: 0.017211]\n",
      "Epoch 902/10001\n",
      "[C1 valid: 0.003763, C2 fake: 0.000000], [G loss: 0.018963, mse: 0.018495]\n",
      "Epoch 903/10001\n",
      "[C1 valid: 0.004162, C2 fake: 0.000000], [G loss: 0.017048, mse: 0.016571]\n",
      "Epoch 904/10001\n",
      "[C1 valid: 0.007111, C2 fake: 0.000000], [G loss: 0.017659, mse: 0.017121]\n",
      "Epoch 905/10001\n",
      "[C1 valid: 0.005107, C2 fake: 0.000000], [G loss: 0.019417, mse: 0.018912]\n",
      "Epoch 906/10001\n",
      "[C1 valid: 0.004771, C2 fake: 0.000000], [G loss: 0.018019, mse: 0.017514]\n",
      "Epoch 907/10001\n",
      "[C1 valid: 0.004398, C2 fake: 0.000000], [G loss: 0.017095, mse: 0.016608]\n",
      "Epoch 908/10001\n",
      "[C1 valid: 0.003920, C2 fake: 0.000000], [G loss: 0.017720, mse: 0.017227]\n",
      "Epoch 909/10001\n",
      "[C1 valid: 0.004490, C2 fake: 0.000000], [G loss: 0.018590, mse: 0.018107]\n",
      "Epoch 910/10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C1 valid: 0.003399, C2 fake: 0.000000], [G loss: 0.017678, mse: 0.017218]\n",
      "Epoch 911/10001\n",
      "[C1 valid: 0.004841, C2 fake: 0.000000], [G loss: 0.020139, mse: 0.018679]\n",
      "Epoch 912/10001\n",
      "[C1 valid: 0.003168, C2 fake: 0.000000], [G loss: 0.017461, mse: 0.016991]\n",
      "Epoch 913/10001\n",
      "[C1 valid: 0.003931, C2 fake: 0.000000], [G loss: 0.017624, mse: 0.017154]\n",
      "Epoch 914/10001\n",
      "[C1 valid: 0.003934, C2 fake: 0.000000], [G loss: 0.017888, mse: 0.017417]\n",
      "Epoch 915/10001\n",
      "[C1 valid: 0.003499, C2 fake: 0.000000], [G loss: 0.018943, mse: 0.018496]\n",
      "Epoch 916/10001\n",
      "[C1 valid: 0.004108, C2 fake: 0.000000], [G loss: 0.017795, mse: 0.017345]\n",
      "Epoch 917/10001\n",
      "[C1 valid: 0.003353, C2 fake: 0.000000], [G loss: 0.018250, mse: 0.017816]\n",
      "Epoch 918/10001\n",
      "[C1 valid: 0.003927, C2 fake: 0.000000], [G loss: 0.018117, mse: 0.017663]\n",
      "Epoch 919/10001\n",
      "[C1 valid: 0.003874, C2 fake: 0.000000], [G loss: 0.018325, mse: 0.017896]\n",
      "Epoch 920/10001\n",
      "[C1 valid: 0.003594, C2 fake: 0.000000], [G loss: 0.018106, mse: 0.017676]\n",
      "Epoch 921/10001\n",
      "[C1 valid: 0.003811, C2 fake: 0.000000], [G loss: 0.017964, mse: 0.017520]\n",
      "Epoch 922/10001\n",
      "[C1 valid: 0.003702, C2 fake: 0.000000], [G loss: 0.018662, mse: 0.018226]\n",
      "Epoch 923/10001\n",
      "[C1 valid: 0.004058, C2 fake: 0.000000], [G loss: 0.017223, mse: 0.016767]\n",
      "Epoch 924/10001\n",
      "[C1 valid: 0.003718, C2 fake: 0.000000], [G loss: 0.016733, mse: 0.016308]\n",
      "Epoch 925/10001\n",
      "[C1 valid: 0.003147, C2 fake: 0.000000], [G loss: 0.017456, mse: 0.017028]\n",
      "Epoch 926/10001\n",
      "[C1 valid: 0.003889, C2 fake: 0.000000], [G loss: 0.017379, mse: 0.016959]\n",
      "Epoch 927/10001\n",
      "[C1 valid: 0.003556, C2 fake: 0.000000], [G loss: 0.017010, mse: 0.016573]\n",
      "Epoch 928/10001\n",
      "[C1 valid: 0.003106, C2 fake: 0.000000], [G loss: 0.016765, mse: 0.016336]\n",
      "Epoch 929/10001\n",
      "[C1 valid: 0.003630, C2 fake: 0.000000], [G loss: 0.017336, mse: 0.016908]\n",
      "Epoch 930/10001\n",
      "[C1 valid: 0.002836, C2 fake: 0.000000], [G loss: 0.018343, mse: 0.017909]\n",
      "Epoch 931/10001\n",
      "[C1 valid: 0.004209, C2 fake: 0.000000], [G loss: 0.017767, mse: 0.017324]\n",
      "Epoch 932/10001\n",
      "[C1 valid: 0.015552, C2 fake: 0.000000], [G loss: 0.017549, mse: 0.017120]\n",
      "Epoch 933/10001\n",
      "[C1 valid: 0.004119, C2 fake: 0.000000], [G loss: 0.017464, mse: 0.017037]\n",
      "Epoch 934/10001\n",
      "[C1 valid: 0.003973, C2 fake: 0.000000], [G loss: 0.016972, mse: 0.016551]\n",
      "Epoch 935/10001\n",
      "[C1 valid: 0.003344, C2 fake: 0.000000], [G loss: 0.017180, mse: 0.016756]\n",
      "Epoch 936/10001\n",
      "[C1 valid: 0.004605, C2 fake: 0.000000], [G loss: 0.017403, mse: 0.017009]\n",
      "Epoch 937/10001\n",
      "[C1 valid: 0.003411, C2 fake: 0.000000], [G loss: 0.017902, mse: 0.017507]\n",
      "Epoch 938/10001\n",
      "[C1 valid: 0.003657, C2 fake: 0.000000], [G loss: 0.016216, mse: 0.015841]\n",
      "Epoch 939/10001\n",
      "[C1 valid: 0.004002, C2 fake: 0.000000], [G loss: 0.017077, mse: 0.016691]\n",
      "Epoch 940/10001\n",
      "[C1 valid: 0.004070, C2 fake: 0.000000], [G loss: 0.016944, mse: 0.016556]\n",
      "Epoch 941/10001\n",
      "[C1 valid: 0.002866, C2 fake: 0.000000], [G loss: 0.017771, mse: 0.017394]\n",
      "Epoch 942/10001\n",
      "[C1 valid: 0.004103, C2 fake: 0.000000], [G loss: 0.017156, mse: 0.016790]\n",
      "Epoch 943/10001\n",
      "[C1 valid: 0.003721, C2 fake: 0.000000], [G loss: 0.017683, mse: 0.017329]\n",
      "Epoch 944/10001\n",
      "[C1 valid: 0.003838, C2 fake: 0.000000], [G loss: 0.015752, mse: 0.015395]\n",
      "Epoch 945/10001\n",
      "[C1 valid: 0.003208, C2 fake: 0.000000], [G loss: 0.016080, mse: 0.015715]\n",
      "Epoch 946/10001\n",
      "[C1 valid: 0.003318, C2 fake: 0.000000], [G loss: 0.016827, mse: 0.016487]\n",
      "Epoch 947/10001\n",
      "[C1 valid: 0.003036, C2 fake: 0.000000], [G loss: 0.017667, mse: 0.017306]\n",
      "Epoch 948/10001\n",
      "[C1 valid: 0.003032, C2 fake: 0.000000], [G loss: 0.018116, mse: 0.017779]\n",
      "Epoch 949/10001\n",
      "[C1 valid: 0.005134, C2 fake: 0.000000], [G loss: 0.015854, mse: 0.015504]\n",
      "Epoch 950/10001\n",
      "[C1 valid: 0.003012, C2 fake: 0.000000], [G loss: 0.016823, mse: 0.016473]\n",
      "Epoch 951/10001\n",
      "[C1 valid: 0.004249, C2 fake: 0.000000], [G loss: 0.017423, mse: 0.017066]\n",
      "Epoch 952/10001\n",
      "[C1 valid: 0.003979, C2 fake: 0.000000], [G loss: 0.017415, mse: 0.017076]\n",
      "Epoch 953/10001\n",
      "[C1 valid: 0.004293, C2 fake: 0.000000], [G loss: 0.016889, mse: 0.016556]\n",
      "Epoch 954/10001\n",
      "[C1 valid: 0.003554, C2 fake: 0.000000], [G loss: 0.016275, mse: 0.015937]\n",
      "Epoch 955/10001\n",
      "[C1 valid: 0.004538, C2 fake: 0.000000], [G loss: 0.016521, mse: 0.016171]\n",
      "Epoch 956/10001\n",
      "[C1 valid: 0.003171, C2 fake: 0.000000], [G loss: 0.015982, mse: 0.015632]\n",
      "Epoch 957/10001\n",
      "[C1 valid: 0.003377, C2 fake: 0.000000], [G loss: 0.017506, mse: 0.017165]\n",
      "Epoch 958/10001\n",
      "[C1 valid: 0.003683, C2 fake: 0.000000], [G loss: 0.017439, mse: 0.017081]\n",
      "Epoch 959/10001\n",
      "[C1 valid: 0.003567, C2 fake: 0.000000], [G loss: 0.017163, mse: 0.016798]\n",
      "Epoch 960/10001\n",
      "[C1 valid: 0.003225, C2 fake: 0.000000], [G loss: 0.017023, mse: 0.016678]\n",
      "Epoch 961/10001\n",
      "[C1 valid: 0.003963, C2 fake: 0.000000], [G loss: 0.018094, mse: 0.017748]\n",
      "Epoch 962/10001\n",
      "[C1 valid: 0.004122, C2 fake: 0.000000], [G loss: 0.016143, mse: 0.015816]\n",
      "Epoch 963/10001\n",
      "[C1 valid: 0.003723, C2 fake: 0.000000], [G loss: 0.016767, mse: 0.016437]\n",
      "Epoch 964/10001\n",
      "[C1 valid: 0.003174, C2 fake: 0.000000], [G loss: 0.017434, mse: 0.017104]\n",
      "Epoch 965/10001\n",
      "[C1 valid: 0.004159, C2 fake: 0.000000], [G loss: 0.016061, mse: 0.015733]\n",
      "Epoch 966/10001\n",
      "[C1 valid: 0.002467, C2 fake: 0.000000], [G loss: 0.016713, mse: 0.016381]\n",
      "Epoch 967/10001\n",
      "[C1 valid: 0.004513, C2 fake: 0.000000], [G loss: 0.016909, mse: 0.016581]\n",
      "Epoch 968/10001\n",
      "[C1 valid: 0.003190, C2 fake: 0.000000], [G loss: 0.016264, mse: 0.015934]\n",
      "Epoch 969/10001\n",
      "[C1 valid: 0.003232, C2 fake: 0.000000], [G loss: 0.015868, mse: 0.015528]\n",
      "Epoch 970/10001\n",
      "[C1 valid: 0.003385, C2 fake: 0.000000], [G loss: 0.015230, mse: 0.014893]\n",
      "Epoch 971/10001\n",
      "[C1 valid: 0.002990, C2 fake: 0.000000], [G loss: 0.016420, mse: 0.016079]\n",
      "Epoch 972/10001\n",
      "[C1 valid: 0.003778, C2 fake: 0.000000], [G loss: 0.016126, mse: 0.015785]\n",
      "Epoch 973/10001\n",
      "[C1 valid: 0.003324, C2 fake: 0.000000], [G loss: 0.017549, mse: 0.017203]\n",
      "Epoch 974/10001\n",
      "[C1 valid: 0.003993, C2 fake: 0.000000], [G loss: 0.017249, mse: 0.016908]\n",
      "Epoch 975/10001\n",
      "[C1 valid: 0.003934, C2 fake: 0.000000], [G loss: 0.016222, mse: 0.015879]\n",
      "Epoch 976/10001\n",
      "[C1 valid: 0.003180, C2 fake: 0.000000], [G loss: 0.016943, mse: 0.016601]\n",
      "Epoch 977/10001\n",
      "[C1 valid: 0.002756, C2 fake: 0.000000], [G loss: 0.016675, mse: 0.016337]\n",
      "Epoch 978/10001\n",
      "[C1 valid: 0.003924, C2 fake: 0.000000], [G loss: 0.016585, mse: 0.016249]\n",
      "Epoch 979/10001\n",
      "[C1 valid: 0.003145, C2 fake: 0.000000], [G loss: 0.017040, mse: 0.016706]\n",
      "Epoch 980/10001\n",
      "[C1 valid: 0.003479, C2 fake: 0.000000], [G loss: 0.016317, mse: 0.015990]\n",
      "Epoch 981/10001\n",
      "[C1 valid: 0.004142, C2 fake: 0.000000], [G loss: 0.016592, mse: 0.016270]\n",
      "Epoch 982/10001\n",
      "[C1 valid: 0.003639, C2 fake: 0.000000], [G loss: 0.016469, mse: 0.016145]\n",
      "Epoch 983/10001\n",
      "[C1 valid: 0.003402, C2 fake: 0.000000], [G loss: 0.017569, mse: 0.016247]\n",
      "Epoch 984/10001\n",
      "[C1 valid: 0.002747, C2 fake: 0.000000], [G loss: 0.016870, mse: 0.016544]\n",
      "Epoch 985/10001\n",
      "[C1 valid: 0.003928, C2 fake: 0.000000], [G loss: 0.015857, mse: 0.015534]\n",
      "Epoch 986/10001\n",
      "[C1 valid: 0.003899, C2 fake: 0.000000], [G loss: 0.017645, mse: 0.017312]\n",
      "Epoch 987/10001\n",
      "[C1 valid: 0.007124, C2 fake: 0.000000], [G loss: 0.016987, mse: 0.016640]\n",
      "Epoch 988/10001\n",
      "[C1 valid: 0.003132, C2 fake: 0.000000], [G loss: 0.015873, mse: 0.015516]\n",
      "Epoch 989/10001\n",
      "[C1 valid: 0.003515, C2 fake: 0.000000], [G loss: 0.017554, mse: 0.017190]\n",
      "Epoch 990/10001\n",
      "[C1 valid: 0.003372, C2 fake: 0.000000], [G loss: 0.016094, mse: 0.015729]\n",
      "Epoch 991/10001\n",
      "[C1 valid: 0.003468, C2 fake: 0.000000], [G loss: 0.016553, mse: 0.016194]\n",
      "Epoch 992/10001\n",
      "[C1 valid: 0.003542, C2 fake: 0.000000], [G loss: 0.015043, mse: 0.014682]\n",
      "Epoch 993/10001\n",
      "[C1 valid: 0.003399, C2 fake: 0.000000], [G loss: 0.015711, mse: 0.015355]\n",
      "Epoch 994/10001\n",
      "[C1 valid: 0.002823, C2 fake: 0.000000], [G loss: 0.016834, mse: 0.016439]\n",
      "Epoch 995/10001\n",
      "[C1 valid: 0.003606, C2 fake: 0.000000], [G loss: 0.015749, mse: 0.015411]\n",
      "Epoch 996/10001\n",
      "[C1 valid: 0.003345, C2 fake: 0.000000], [G loss: 0.015588, mse: 0.015256]\n",
      "Epoch 997/10001\n",
      "[C1 valid: 0.003567, C2 fake: 0.000000], [G loss: 0.016525, mse: 0.016205]\n",
      "Epoch 998/10001\n",
      "[C1 valid: 0.003311, C2 fake: 0.000000], [G loss: 0.016127, mse: 0.015799]\n",
      "Epoch 999/10001\n",
      "[C1 valid: 0.002832, C2 fake: 0.000000], [G loss: 0.014935, mse: 0.014618]\n",
      "Epoch 1000/10001\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(Z,BATCH_SIZE,train_dataset, epochs, scaler, scaled,X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict from the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the labels of the data values on the basis of the trained model.\n",
    "#sampling from the latent space without prediction\n",
    "\n",
    "latent_values = np.random.normal(loc=0, scale=1, size=([1000, Z]))\n",
    "predicted_values = aae.decoder.predict(latent_values)\n",
    "\n",
    "predicted_values2 = aae.decoder.predict(aae.encoder(X_train_scaled))\n",
    "\n",
    "\n",
    "if scaled == '-1-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "\n",
    "if n_features==3:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    print(\"latent_space:\",Z)\n",
    "    print(\"BATCH_SIZE:\",BATCH_SIZE)\n",
    "    print(\"epochs:\",epochs)\n",
    "    \n",
    "\n",
    "    ab = plt.subplot(projection='3d')\n",
    "    ab.scatter(predicted_values[:,0],predicted_values[:,1],predicted_values[:,2])\n",
    "    ab.set_ylabel('Y')\n",
    "    ab.set_zlabel('Z')\n",
    "    ab.set_xlabel('X')\n",
    "    \n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(predicted_values[:,1],predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,0]>=-0.8-0.05,predicted_values[:,0]<=-0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,0]>=0.0-0.05,predicted_values[:,0]<=0.0+0.05),predicted_values[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,0]>=0.8-0.05,predicted_values[:,0]<=0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,1]>=0.2-0.05,predicted_values[:,1]<=0.2+0.05),predicted_values[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,1]>=0.5-0.05,predicted_values[:,1]<=0.5+0.05),predicted_values[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,1]>=0.8-0.05,predicted_values[:,1]<=0.8+0.05),predicted_values[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    print(\"Predicted Values:\",predicted_values2.shape)\n",
    "    plt.scatter(X_train, y_train)\n",
    "    plt.scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input = [-4,-3,-2,-1,0,1,2,3,4]\n",
    "n_points = 900\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//9, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//9, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//9, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//9, n_features), x_input[3])\n",
    "predict5 = np.full((n_points//9, n_features), x_input[4])\n",
    "predict6 = np.full((n_points//9, n_features), x_input[5])\n",
    "predict7 = np.full((n_points//9, n_features), x_input[6])\n",
    "predict8 = np.full((n_points//9, n_features), x_input[7])\n",
    "predict9 = np.full((n_points//9, n_features), x_input[8])\n",
    "\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4, predict5, predict6, predict7, predict8, predict9))\n",
    "predictthis = scaler.fit_transform(predictthis)\n",
    "input_test = predictthis.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_generated = aae.generator.predict(input_test)\n",
    "X_generated = aae.decoder.predict(aae.encoder(input_test))\n",
    "X_generated = scaler.inverse_transform(X_generated)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    print(\"latent_space=\",latent_space)\n",
    "    print(\"Epochs=\",epochs)\n",
    "    print(\"BATCH_SIZE=\",BATCH_SIZE)\n",
    "    print(\"use_bias=\",use_bias)\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,label=\"Sample Data\")\n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    #plt.scatter(predicted_values2[:,0],predicted_values2[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
