{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import python dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"sinus\" #sinus, helix\n",
    "#n_instance = 1000\n",
    "n_instance = 10000\n",
    "n_features = 2\n",
    "Z = 6 #3的倍數\n",
    "nodes = 8 #4\n",
    "var = 4\n",
    "use_bias = 'True'\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "export_excel(X_train, 'Dataset/X_train')\n",
    "export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2048        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1024)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 32)       0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32)       128         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 32, 32)       1024        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32)       128         conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 32, 32)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 32, 8)        256         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 8)        32          conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 8)        0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            1536        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            1536        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6)            24          lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 8,604\n",
      "Non-trainable params: 2,204\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,302\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 16, 32)            512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 32)            128       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 16)            512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16)            64        \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 256       \n",
      "=================================================================\n",
      "Total params: 4,032\n",
      "Trainable params: 3,424\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=network.build_encoder(Z, nodes, n_features)\n",
    "decoder=network.build_decoder(Z, var, n_features, use_bias)\n",
    "discriminator=network.build_discriminator(Z, nodes)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model\n",
    "\n",
    "GANorWGAN='WGAN' #GAN\n",
    "epochs = 2000 #2000\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         2048        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1024)         4096        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 1024)         0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 32, 32)       0           re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32)       128         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 32, 32)       1024        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32)       128         conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 32, 32)       0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTrans (None, 32, 8)        256         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 8)        32          conv1d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 32, 8)        0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            1536        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 6)            1536        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6)            0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 6)            24          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 8,604\n",
      "Non-trainable params: 2,204\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,302\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aae = AAE_Model.AAE(i, Z, n_features, batch_size, GANorWGAN, nodes, var, use_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (1000, 2)\n",
      "data shape_2 (1000, 2)\n",
      "data shape_3 (1000, 2)\n",
      "data shape_4 (1000, 2)\n",
      "data shape_5 (1000, 2)\n",
      "data shape_6 (1000, 2)\n",
      "data shape_7 (1000, 2)\n",
      "data shape_8 (1000, 2)\n",
      "data shape_9 (1000, 2)\n",
      "data shape_10 (1000, 2)\n",
      "Cycles:  10\n",
      "X_train (10000, 1)\n",
      "y_train (10000, 1)\n",
      "X_train_scaled (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "1 [D real: -0.226509, D fake: 0.260163], [Enc/Dec loss: 0.416009, Enc/Dis: 0.421250]\n",
      "2 [D real: -0.240287, D fake: 0.259748], [Enc/Dec loss: 0.244932, Enc/Dis: 0.249918]\n",
      "3 [D real: -0.248006, D fake: 0.262039], [Enc/Dec loss: 0.188901, Enc/Dis: 0.193700]\n",
      "4 [D real: -0.252970, D fake: 0.263504], [Enc/Dec loss: 0.157240, Enc/Dis: 0.161869]\n",
      "5 [D real: -0.256993, D fake: 0.266023], [Enc/Dec loss: 0.128085, Enc/Dis: 0.132546]\n",
      "6 [D real: -0.259467, D fake: 0.267567], [Enc/Dec loss: 0.107470, Enc/Dis: 0.111780]\n",
      "7 [D real: -0.260895, D fake: 0.269527], [Enc/Dec loss: 0.099317, Enc/Dis: 0.103477]\n",
      "8 [D real: -0.262094, D fake: 0.271276], [Enc/Dec loss: 0.089300, Enc/Dis: 0.093306]\n",
      "9 [D real: -0.263230, D fake: 0.271724], [Enc/Dec loss: 0.083872, Enc/Dis: 0.087734]\n",
      "10 [D real: -0.264230, D fake: 0.271793], [Enc/Dec loss: 0.080873, Enc/Dis: 0.084595]\n",
      "11 [D real: -0.270976, D fake: 0.277539], [Enc/Dec loss: 0.078753, Enc/Dis: 0.082344]\n",
      "12 [D real: -0.272508, D fake: 0.275751], [Enc/Dec loss: 0.074690, Enc/Dis: 0.078175]\n",
      "13 [D real: -0.274653, D fake: 0.275112], [Enc/Dec loss: 0.071616, Enc/Dis: 0.074993]\n",
      "14 [D real: -0.275721, D fake: 0.274790], [Enc/Dec loss: 0.070274, Enc/Dis: 0.073567]\n",
      "15 [D real: -0.274701, D fake: 0.275506], [Enc/Dec loss: 0.069752, Enc/Dis: 0.072965]\n",
      "16 [D real: -0.274730, D fake: 0.275540], [Enc/Dec loss: 0.069110, Enc/Dis: 0.072287]\n",
      "17 [D real: -0.274315, D fake: 0.276337], [Enc/Dec loss: 0.066863, Enc/Dis: 0.070001]\n",
      "18 [D real: -0.274062, D fake: 0.276464], [Enc/Dec loss: 0.067188, Enc/Dis: 0.070218]\n",
      "19 [D real: -0.273967, D fake: 0.276696], [Enc/Dec loss: 0.066014, Enc/Dis: 0.068901]\n",
      "20 [D real: -0.274228, D fake: 0.276159], [Enc/Dec loss: 0.064443, Enc/Dis: 0.067248]\n",
      "21 [D real: -0.269954, D fake: 0.273401], [Enc/Dec loss: 0.065850, Enc/Dis: 0.068569]\n",
      "22 [D real: -0.269890, D fake: 0.273221], [Enc/Dec loss: 0.065526, Enc/Dis: 0.068217]\n",
      "23 [D real: -0.272271, D fake: 0.273197], [Enc/Dec loss: 0.063575, Enc/Dis: 0.066239]\n",
      "24 [D real: -0.272487, D fake: 0.274856], [Enc/Dec loss: 0.065197, Enc/Dis: 0.067844]\n",
      "25 [D real: -0.273463, D fake: 0.275327], [Enc/Dec loss: 0.062494, Enc/Dis: 0.065145]\n",
      "26 [D real: -0.273060, D fake: 0.275471], [Enc/Dec loss: 0.063812, Enc/Dis: 0.066487]\n",
      "27 [D real: -0.273060, D fake: 0.275226], [Enc/Dec loss: 0.062242, Enc/Dis: 0.064966]\n",
      "28 [D real: -0.273722, D fake: 0.275457], [Enc/Dec loss: 0.063689, Enc/Dis: 0.066442]\n",
      "29 [D real: -0.273382, D fake: 0.276009], [Enc/Dec loss: 0.061608, Enc/Dis: 0.064585]\n",
      "30 [D real: -0.273127, D fake: 0.276554], [Enc/Dec loss: 0.063168, Enc/Dis: 0.066350]\n",
      "31 [D real: -0.273936, D fake: 0.267695], [Enc/Dec loss: 0.062347, Enc/Dis: 0.065712]\n",
      "32 [D real: -0.272466, D fake: 0.271482], [Enc/Dec loss: 0.061004, Enc/Dis: 0.064422]\n",
      "33 [D real: -0.272662, D fake: 0.270910], [Enc/Dec loss: 0.061117, Enc/Dis: 0.064556]\n",
      "34 [D real: -0.272622, D fake: 0.271589], [Enc/Dec loss: 0.059547, Enc/Dis: 0.063050]\n",
      "35 [D real: -0.272689, D fake: 0.271596], [Enc/Dec loss: 0.060036, Enc/Dis: 0.063700]\n",
      "36 [D real: -0.272972, D fake: 0.272319], [Enc/Dec loss: 0.060648, Enc/Dis: 0.064354]\n",
      "37 [D real: -0.272770, D fake: 0.272687], [Enc/Dec loss: 0.058189, Enc/Dis: 0.061957]\n",
      "38 [D real: -0.272878, D fake: 0.272610], [Enc/Dec loss: 0.060604, Enc/Dis: 0.064340]\n",
      "39 [D real: -0.273075, D fake: 0.273109], [Enc/Dec loss: 0.060012, Enc/Dis: 0.063685]\n",
      "40 [D real: -0.272780, D fake: 0.273420], [Enc/Dec loss: 0.059370, Enc/Dis: 0.063179]\n",
      "41 [D real: -0.276747, D fake: 0.273441], [Enc/Dec loss: 0.059646, Enc/Dis: 0.063615]\n",
      "42 [D real: -0.274922, D fake: 0.270777], [Enc/Dec loss: 0.057915, Enc/Dis: 0.061785]\n",
      "43 [D real: -0.274198, D fake: 0.271976], [Enc/Dec loss: 0.059121, Enc/Dis: 0.062975]\n",
      "44 [D real: -0.274357, D fake: 0.272031], [Enc/Dec loss: 0.058921, Enc/Dis: 0.062863]\n",
      "45 [D real: -0.273198, D fake: 0.272789], [Enc/Dec loss: 0.055973, Enc/Dis: 0.060078]\n",
      "46 [D real: -0.272858, D fake: 0.273978], [Enc/Dec loss: 0.059775, Enc/Dis: 0.063918]\n",
      "47 [D real: -0.272970, D fake: 0.273851], [Enc/Dec loss: 0.056568, Enc/Dis: 0.061084]\n",
      "48 [D real: -0.272693, D fake: 0.273784], [Enc/Dec loss: 0.058553, Enc/Dis: 0.063339]\n",
      "49 [D real: -0.272652, D fake: 0.274171], [Enc/Dec loss: 0.056205, Enc/Dis: 0.061078]\n",
      "50 [D real: -0.273030, D fake: 0.273911], [Enc/Dec loss: 0.055188, Enc/Dis: 0.060556]\n",
      "51 [D real: -0.268173, D fake: 0.274966], [Enc/Dec loss: 0.057596, Enc/Dis: 0.063129]\n",
      "52 [D real: -0.269179, D fake: 0.275059], [Enc/Dec loss: 0.055262, Enc/Dis: 0.061088]\n",
      "53 [D real: -0.271578, D fake: 0.275753], [Enc/Dec loss: 0.056546, Enc/Dis: 0.062699]\n",
      "54 [D real: -0.270849, D fake: 0.275416], [Enc/Dec loss: 0.056614, Enc/Dis: 0.062734]\n",
      "55 [D real: -0.271070, D fake: 0.276707], [Enc/Dec loss: 0.055574, Enc/Dis: 0.061605]\n",
      "56 [D real: -0.271775, D fake: 0.275791], [Enc/Dec loss: 0.057145, Enc/Dis: 0.063482]\n",
      "57 [D real: -0.271446, D fake: 0.275678], [Enc/Dec loss: 0.055299, Enc/Dis: 0.061715]\n",
      "58 [D real: -0.271678, D fake: 0.275898], [Enc/Dec loss: 0.055352, Enc/Dis: 0.061864]\n",
      "59 [D real: -0.271778, D fake: 0.275563], [Enc/Dec loss: 0.056427, Enc/Dis: 0.062682]\n",
      "60 [D real: -0.272311, D fake: 0.275505], [Enc/Dec loss: 0.055316, Enc/Dis: 0.061496]\n",
      "61 [D real: -0.273594, D fake: 0.271539], [Enc/Dec loss: 0.054481, Enc/Dis: 0.060847]\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(i, Z, batch_size, train_dataset, epochs, scaler, X_train_scaled, scaled, X_train, y_train )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#Discriminator Loss\n",
    "Dloss = Image.open('AAE/Losses/D_loss_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"D_loss\",figsize=[15,10])\n",
    "plt.imshow(Dloss)\n",
    "#Encoder Loss\n",
    "Gloss = Image.open('AAE/Losses/G_loss_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"G_loss\",figsize=[15,10])\n",
    "plt.imshow(Gloss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict from the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('AAE/Result/v'+str(i)+'_latent_space 3D_'+str(epochs)+'.png')\n",
    "plt.figure(\"3D\",figsize=[15,10])\n",
    "plt.imshow(img)\n",
    "\n",
    "img2 = Image.open('AAE/Result/v'+str(i)+'_Latent_Space 2D_'+str(epochs)+'.png')\n",
    "plt.figure(\"2D\",figsize=[15,10])\n",
    "plt.imshow(img2)\n",
    "\n",
    "img3 = Image.open('AAE/Result/v_'+str(i)+'_epochs_'+str(epochs)+'.png')\n",
    "plt.figure(\"Autoencoder\",figsize=[15,10])\n",
    "plt.imshow(img3)\n",
    "\n",
    "img4 = Image.open('AAE/Result/'+'countour_line_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"countour_line\",figsize=[15,10])\n",
    "plt.imshow(img4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "latent_values = tf.random.normal([10000, Z])\n",
    "predicted_values = aae.decoder(latent_values)\n",
    "\n",
    "predicted_values2 = aae.decoder(aae.encoder(X_train_scaled))\n",
    "predicted_values3 = aae.encoder(X_train_scaled)\n",
    "#predicted_values4 = scaler.inverse_transform(X_train_scaled)\n",
    "\n",
    "if scaled == '-1-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "    \n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if n_features==3:\n",
    "    \n",
    "    ab = plt.subplot(projection='3d')\n",
    "    ab.scatter(predicted_values5[:,0],predicted_values5[:,1],predicted_values5[:,2])\n",
    "    ab.set_ylabel('Y')\n",
    "    ab.set_zlabel('Z')\n",
    "    ab.set_xlabel('X')\n",
    "    \n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(predicted_values[:,1],predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,0]>=-0.8-0.05,predicted_values[:,0]<=-0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,0]>=0.0-0.05,predicted_values[:,0]<=0.0+0.05),predicted_values[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,0]>=0.8-0.05,predicted_values[:,0]<=0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,1]>=0.2-0.05,predicted_values[:,1]<=0.2+0.05),predicted_values[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,1]>=0.5-0.05,predicted_values[:,1]<=0.5+0.05),predicted_values[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,1]>=0.8-0.05,predicted_values[:,1]<=0.8+0.05),predicted_values[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    \n",
    "    if Z>=6:\n",
    "        # set up a figure twice as wide as it is tall\n",
    "        fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "        aa = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        aa.scatter(predicted_values3[:,0],predicted_values3[:,1],predicted_values3[:,2],c='pink')\n",
    "        aa.scatter(latent_values[:,0],latent_values[:,1],latent_values[:,2],c='grey')\n",
    "        aa.set_ylabel('Y')\n",
    "        aa.set_zlabel('Z')\n",
    "        aa.set_xlabel('X')\n",
    "        aa.set_title('Latent Space 3D - 0,1,2')\n",
    "    \n",
    "        ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        ax.scatter(predicted_values3[:,3],predicted_values3[:,4],predicted_values3[:,5],c='pink')\n",
    "        ax.scatter(latent_values[:,3],latent_values[:,4],latent_values[:,5],c='grey')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_title('Latent Space 3D - 3,4,5')\n",
    "\n",
    "        plt.savefig('AAE/Result/v'+str(i)+'_latent_space 3D_'+str(epochs)+'.png')\n",
    "    \n",
    "    \n",
    "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10), sharey=False, sharex=False)\n",
    "        axes[0][0].scatter(predicted_values3[:,0],predicted_values3[:,1],c='pink')\n",
    "        axes[0][0].scatter(latent_values[:,0],latent_values[:,1],c='grey')\n",
    "        axes[0][0].set_xlabel(\"X\")\n",
    "        axes[0][0].set_ylabel(\"Y\")\n",
    "        axes[0][0].set_title(\"Latent Space 2D- XY\")\n",
    "\n",
    "    \n",
    "\n",
    "        axes[0][1].scatter(predicted_values3[:,1],predicted_values3[:,2],c='pink')\n",
    "        axes[0][1].scatter(latent_values[:,1],latent_values[:,2],c='grey')\n",
    "        axes[0][1].set_xlabel(\"Y\")\n",
    "        axes[0][1].set_ylabel(\"Z\")\n",
    "        axes[0][1].set_title(\"Latent Space 2D- YZ\")\n",
    "\n",
    "    \n",
    "\n",
    "        axes[0][2].scatter(predicted_values3[:,0],predicted_values3[:,2],c='pink')\n",
    "        axes[0][2].scatter(latent_values[:,0],latent_values[:,2],c='grey')\n",
    "        axes[0][2].set_xlabel(\"X\")\n",
    "        axes[0][2].set_ylabel(\"Z\")\n",
    "        axes[0][2].set_title(\"Latent Space 2D- XZ\")\n",
    "    \n",
    "    \n",
    "        axes[1][0].scatter(predicted_values3[:,3],predicted_values3[:,4],c='pink')\n",
    "        axes[1][0].scatter(latent_values[:,3],latent_values[:,4],c='grey')\n",
    "        axes[1][0].set_xlabel(\"X\")\n",
    "        axes[1][0].set_ylabel(\"Y\")\n",
    "        axes[1][0].set_title(\"Latent Space 2D- 3,4\")\n",
    "    \n",
    "        axes[1][1].scatter(predicted_values3[:,4],predicted_values3[:,5],c='pink')\n",
    "        axes[1][1].scatter(latent_values[:,4],latent_values[:,5],c='grey')\n",
    "        axes[1][1].set_xlabel(\"Y\")\n",
    "        axes[1][1].set_ylabel(\"Z\")\n",
    "        axes[1][1].set_title(\"Latent Space 2D- 4,5\")\n",
    "    \n",
    "        axes[1][2].scatter(predicted_values3[:,3],predicted_values3[:,5],c='pink')\n",
    "        axes[1][2].scatter(latent_values[:,3],latent_values[:,5],c='grey')\n",
    "        axes[1][2].set_xlabel(\"X\")\n",
    "        axes[1][2].set_ylabel(\"Z\")\n",
    "        axes[1][2].set_title(\"Latent Space 2D- 3,5\")\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('AAE/Result/v'+str(i)+'_Latent_Space 2D_'+str(epochs)+'.png')\n",
    "    \n",
    "    ############################################\n",
    "    ###############Latent Space#################\n",
    "    ############################################\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    axes[0].scatter(predicted_values2[:,0],predicted_values2[:,1],)#encoder/decoder\n",
    "    #axes[0].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_title('Autoencoder (X_trained_scaled)')\n",
    "\n",
    "    axes[1].scatter(predicted_values[:,0],predicted_values[:,1],c='red') #decoder(latent space)\n",
    "    #axes[1].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[1].set_ylabel('Y')\n",
    "    axes[1].set_xlabel('X')\n",
    "    axes[1].set_title('Decoder (latent space)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Result/v_'+str(i)+'_epochs_'+str(epochs)+'.png')\n",
    "    \n",
    "    ############################################\n",
    "    ###############Discriminator################\n",
    "    ############################################\n",
    "    \n",
    "\n",
    "print('encoder output shape',predicted_values3.shape)\n",
    "encoder_output = predicted_values3\n",
    "    \n",
    "dis_predicted_values = aae.discriminator(encoder_output)\n",
    "#dis_predicted_values = scaler.inverse_transform(dis_predicted_values)\n",
    "print('discriminator shape',dis_predicted_values.shape)\n",
    "\n",
    "\n",
    "\n",
    "#import seed ()\n",
    "x = np.ndarray.tolist(predicted_values2[:, 0])\n",
    "y = np.ndarray.tolist(predicted_values2[:, 1])\n",
    "#z = np.ndarray.tolist(dis_predicted_values)\n",
    "#x = np.random.choice(x)\n",
    "#y = np.random.choice(y)\n",
    "#z = np.random.choice(z)\n",
    "\n",
    "resolution_x = 100\n",
    "resolution_y = 100\n",
    "x = np.linspace(np.min(predicted_values2[:, 0]), np.max(predicted_values2[:, 0]), resolution_x)\n",
    "#x = predicted_values2[:, 0]\n",
    "y = np.linspace(np.min(predicted_values2[:, 1]), np.max(predicted_values2[:, 1]), resolution_y)\n",
    "#y = predicted_values2[:, 1]\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = dis_predicted_values\n",
    "z = np.array(z)\n",
    "z = z.reshape((len(x), len(y)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.contourf(x, y, z)\n",
    "plt.colorbar()\n",
    "\n",
    "#fig, ax = plt.subplots(1,1, figsize=[10,5])\n",
    "#ax.plot(dis_predicted_values)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.xlabel('X')\n",
    "#plt.ylabel('Y')\n",
    "#plt.title(\"AAE Discriminator\")\n",
    "plt.savefig('AAE/Result/'+'countour_line_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.models.load_model('./AAE/Models/encoder_v'+str(i)+'_'+str(epochs))\n",
    "decoder = keras.models.load_model('./AAE/Models/decoder_v'+str(i)+'_'+str(epochs))\n",
    "discriminator = keras.models.load_model('./AAE/Models/discriminator_v'+str(i)+'_'+str(epochs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input = [-4,-3,-2,-1,0,1,2,3,4]\n",
    "n_points = 900\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//9, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//9, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//9, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//9, n_features), x_input[3])\n",
    "predict5 = np.full((n_points//9, n_features), x_input[4])\n",
    "predict6 = np.full((n_points//9, n_features), x_input[5])\n",
    "predict7 = np.full((n_points//9, n_features), x_input[6])\n",
    "predict8 = np.full((n_points//9, n_features), x_input[7])\n",
    "predict9 = np.full((n_points//9, n_features), x_input[8])\n",
    "\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4, predict5, predict6, predict7, predict8, predict9))\n",
    "predictthis_scaled = scaler.transform(predictthis)\n",
    "input_test = predictthis_scaled.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated = aae.predict(input_test, scaler)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,c='orange') \n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    #plt.scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    #plt.scatter(predicted_values2[:,0],predicted_values2[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Prediction/'+str(epochs)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
