{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network_ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"sinus\" #sinus, helix\n",
    "n_instance = 1000\n",
    "n_features = 2\n",
    "Z=2\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'\n",
    "nodes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "#export_excel(X_train, 'Dataset/X_train')\n",
    "#export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=network_ReLU.build_encoder(Z, nodes, n_features)\n",
    "#print(\"Encoder:\\n\")\n",
    "#encoder.summary()\n",
    "\n",
    "\n",
    "decoder=network_ReLU.build_decoder(Z,nodes, n_features)\n",
    "#print(\"Decoder:\\n\")\n",
    "#decoder.summary()\n",
    "\n",
    "discriminator=network_ReLU.build_discriminator(Z,nodes)\n",
    "#print(\"Discriminator:\\n\")\n",
    "#discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model_ReLU\n",
    "\n",
    "GANorWGAN='WGAN'\n",
    "epochs =2000\n",
    "BATCH_SIZE = 100\n",
    "n_dis=4\n",
    "n_endis=1\n",
    "n_decoder=2\n",
    "#n_autoencoder=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE_Model_ReLU.AAE(Z, n_features, BATCH_SIZE,GANorWGAN,nodes,n_dis,n_endis,n_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (100, 2)\n",
      "data shape_2 (100, 2)\n",
      "data shape_3 (100, 2)\n",
      "data shape_4 (100, 2)\n",
      "data shape_5 (100, 2)\n",
      "data shape_6 (100, 2)\n",
      "data shape_7 (100, 2)\n",
      "data shape_8 (100, 2)\n",
      "data shape_9 (100, 2)\n",
      "data shape_10 (100, 2)\n",
      "Cycles:  10\n",
      "X_train (1000, 1)\n",
      "y_train (1000, 1)\n",
      "X_train_scaled (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "[Dis(w): 0.264131], [endis(w)]: 0.484878, [decoder(mse)]: 0.413676]\n",
      "Epoch 2/2000\n",
      "[Dis(w): 0.263622], [endis(w)]: 0.503784, [decoder(mse)]: 0.424308]\n",
      "Epoch 3/2000\n",
      "[Dis(w): 0.263678], [endis(w)]: 0.490581, [decoder(mse)]: 0.407251]\n",
      "Epoch 4/2000\n",
      "[Dis(w): 0.264121], [endis(w)]: 0.488779, [decoder(mse)]: 0.412007]\n",
      "Epoch 5/2000\n",
      "[Dis(w): 0.264183], [endis(w)]: 0.495670, [decoder(mse)]: 0.423683]\n",
      "Epoch 6/2000\n",
      "[Dis(w): 0.264256], [endis(w)]: 0.505586, [decoder(mse)]: 0.424551]\n",
      "Epoch 7/2000\n",
      "[Dis(w): 0.264119], [endis(w)]: 0.489569, [decoder(mse)]: 0.428714]\n",
      "Epoch 8/2000\n",
      "[Dis(w): 0.264278], [endis(w)]: 0.499004, [decoder(mse)]: 0.429634]\n",
      "Epoch 9/2000\n",
      "[Dis(w): 0.264431], [endis(w)]: 0.499520, [decoder(mse)]: 0.429282]\n",
      "Epoch 10/2000\n",
      "[Dis(w): 0.264301], [endis(w)]: 0.488325, [decoder(mse)]: 0.427883]\n",
      "Epoch 11/2000\n",
      "[Dis(w): 0.265080], [endis(w)]: 0.483022, [decoder(mse)]: 0.429160]\n",
      "Epoch 12/2000\n",
      "[Dis(w): 0.264509], [endis(w)]: 0.509203, [decoder(mse)]: 0.427133]\n",
      "Epoch 13/2000\n",
      "[Dis(w): 0.264144], [endis(w)]: 0.502747, [decoder(mse)]: 0.438285]\n",
      "Epoch 14/2000\n",
      "[Dis(w): 0.263970], [endis(w)]: 0.494865, [decoder(mse)]: 0.432196]\n",
      "Epoch 15/2000\n",
      "[Dis(w): 0.263822], [endis(w)]: 0.492319, [decoder(mse)]: 0.428212]\n",
      "Epoch 16/2000\n",
      "[Dis(w): 0.263991], [endis(w)]: 0.506107, [decoder(mse)]: 0.425831]\n",
      "Epoch 17/2000\n",
      "[Dis(w): 0.264084], [endis(w)]: 0.501197, [decoder(mse)]: 0.422060]\n",
      "Epoch 18/2000\n",
      "[Dis(w): 0.264128], [endis(w)]: 0.510281, [decoder(mse)]: 0.423436]\n",
      "Epoch 19/2000\n",
      "[Dis(w): 0.264132], [endis(w)]: 0.498279, [decoder(mse)]: 0.419924]\n",
      "Epoch 20/2000\n",
      "[Dis(w): 0.264273], [endis(w)]: 0.498032, [decoder(mse)]: 0.420024]\n",
      "Epoch 21/2000\n",
      "[Dis(w): 0.264343], [endis(w)]: 0.495406, [decoder(mse)]: 0.406551]\n",
      "Epoch 22/2000\n",
      "[Dis(w): 0.264180], [endis(w)]: 0.494838, [decoder(mse)]: 0.400576]\n",
      "Epoch 23/2000\n",
      "[Dis(w): 0.264052], [endis(w)]: 0.488771, [decoder(mse)]: 0.415690]\n",
      "Epoch 24/2000\n",
      "[Dis(w): 0.264172], [endis(w)]: 0.502204, [decoder(mse)]: 0.416863]\n",
      "Epoch 25/2000\n",
      "[Dis(w): 0.264168], [endis(w)]: 0.496159, [decoder(mse)]: 0.429785]\n",
      "Epoch 26/2000\n",
      "[Dis(w): 0.264059], [endis(w)]: 0.511087, [decoder(mse)]: 0.429997]\n",
      "Epoch 27/2000\n",
      "[Dis(w): 0.263941], [endis(w)]: 0.498235, [decoder(mse)]: 0.429057]\n",
      "Epoch 28/2000\n",
      "[Dis(w): 0.263979], [endis(w)]: 0.489020, [decoder(mse)]: 0.436072]\n",
      "Epoch 29/2000\n",
      "[Dis(w): 0.263966], [endis(w)]: 0.487309, [decoder(mse)]: 0.438745]\n",
      "Epoch 30/2000\n",
      "[Dis(w): 0.264075], [endis(w)]: 0.512945, [decoder(mse)]: 0.433929]\n",
      "Epoch 31/2000\n",
      "[Dis(w): 0.263218], [endis(w)]: 0.502126, [decoder(mse)]: 0.436593]\n",
      "Epoch 32/2000\n",
      "[Dis(w): 0.263526], [endis(w)]: 0.495908, [decoder(mse)]: 0.433200]\n",
      "Epoch 33/2000\n",
      "[Dis(w): 0.263417], [endis(w)]: 0.485530, [decoder(mse)]: 0.424960]\n",
      "Epoch 34/2000\n",
      "[Dis(w): 0.263519], [endis(w)]: 0.492202, [decoder(mse)]: 0.410030]\n",
      "Epoch 35/2000\n",
      "[Dis(w): 0.263613], [endis(w)]: 0.519140, [decoder(mse)]: 0.422683]\n",
      "Epoch 36/2000\n",
      "[Dis(w): 0.263693], [endis(w)]: 0.486993, [decoder(mse)]: 0.426899]\n",
      "Epoch 37/2000\n",
      "[Dis(w): 0.263658], [endis(w)]: 0.498853, [decoder(mse)]: 0.428054]\n",
      "Epoch 38/2000\n",
      "[Dis(w): 0.263794], [endis(w)]: 0.488745, [decoder(mse)]: 0.420551]\n",
      "Epoch 39/2000\n",
      "[Dis(w): 0.263901], [endis(w)]: 0.497197, [decoder(mse)]: 0.419132]\n",
      "Epoch 40/2000\n",
      "[Dis(w): 0.263925], [endis(w)]: 0.497662, [decoder(mse)]: 0.422295]\n",
      "Epoch 41/2000\n",
      "[Dis(w): 0.263645], [endis(w)]: 0.483752, [decoder(mse)]: 0.453029]\n",
      "Epoch 42/2000\n",
      "[Dis(w): 0.263660], [endis(w)]: 0.510626, [decoder(mse)]: 0.442697]\n",
      "Epoch 43/2000\n",
      "[Dis(w): 0.263630], [endis(w)]: 0.495439, [decoder(mse)]: 0.437901]\n",
      "Epoch 44/2000\n",
      "[Dis(w): 0.263939], [endis(w)]: 0.503893, [decoder(mse)]: 0.440425]\n",
      "Epoch 45/2000\n",
      "[Dis(w): 0.263932], [endis(w)]: 0.497887, [decoder(mse)]: 0.440660]\n",
      "Epoch 46/2000\n",
      "[Dis(w): 0.264110], [endis(w)]: 0.511047, [decoder(mse)]: 0.431472]\n",
      "Epoch 47/2000\n",
      "[Dis(w): 0.264147], [endis(w)]: 0.505482, [decoder(mse)]: 0.426509]\n",
      "Epoch 48/2000\n",
      "[Dis(w): 0.264217], [endis(w)]: 0.497984, [decoder(mse)]: 0.420029]\n",
      "Epoch 49/2000\n",
      "[Dis(w): 0.264265], [endis(w)]: 0.489805, [decoder(mse)]: 0.426032]\n",
      "Epoch 50/2000\n",
      "[Dis(w): 0.264291], [endis(w)]: 0.492738, [decoder(mse)]: 0.423146]\n",
      "Epoch 51/2000\n",
      "[Dis(w): 0.264275], [endis(w)]: 0.499308, [decoder(mse)]: 0.404262]\n",
      "Epoch 52/2000\n",
      "[Dis(w): 0.264533], [endis(w)]: 0.497064, [decoder(mse)]: 0.404176]\n",
      "Epoch 53/2000\n",
      "[Dis(w): 0.264706], [endis(w)]: 0.496667, [decoder(mse)]: 0.417643]\n",
      "Epoch 54/2000\n",
      "[Dis(w): 0.264348], [endis(w)]: 0.491535, [decoder(mse)]: 0.418207]\n",
      "Epoch 55/2000\n",
      "[Dis(w): 0.264211], [endis(w)]: 0.490578, [decoder(mse)]: 0.428005]\n",
      "Epoch 56/2000\n",
      "[Dis(w): 0.264094], [endis(w)]: 0.504771, [decoder(mse)]: 0.432455]\n",
      "Epoch 57/2000\n",
      "[Dis(w): 0.264227], [endis(w)]: 0.509675, [decoder(mse)]: 0.437398]\n",
      "Epoch 58/2000\n",
      "[Dis(w): 0.264280], [endis(w)]: 0.504133, [decoder(mse)]: 0.439286]\n",
      "Epoch 59/2000\n",
      "[Dis(w): 0.264206], [endis(w)]: 0.500132, [decoder(mse)]: 0.439952]\n",
      "Epoch 60/2000\n",
      "[Dis(w): 0.264248], [endis(w)]: 0.510979, [decoder(mse)]: 0.435161]\n",
      "Epoch 61/2000\n",
      "[Dis(w): 0.263854], [endis(w)]: 0.516674, [decoder(mse)]: 0.404378]\n",
      "Epoch 62/2000\n",
      "[Dis(w): 0.264153], [endis(w)]: 0.492766, [decoder(mse)]: 0.421444]\n",
      "Epoch 63/2000\n",
      "[Dis(w): 0.264170], [endis(w)]: 0.514118, [decoder(mse)]: 0.427327]\n",
      "Epoch 64/2000\n",
      "[Dis(w): 0.264272], [endis(w)]: 0.491079, [decoder(mse)]: 0.429133]\n",
      "Epoch 65/2000\n",
      "[Dis(w): 0.264335], [endis(w)]: 0.509256, [decoder(mse)]: 0.426010]\n",
      "Epoch 66/2000\n",
      "[Dis(w): 0.264336], [endis(w)]: 0.516175, [decoder(mse)]: 0.425531]\n",
      "Epoch 67/2000\n",
      "[Dis(w): 0.264381], [endis(w)]: 0.489716, [decoder(mse)]: 0.426786]\n",
      "Epoch 68/2000\n",
      "[Dis(w): 0.264298], [endis(w)]: 0.491292, [decoder(mse)]: 0.427558]\n",
      "Epoch 69/2000\n",
      "[Dis(w): 0.264311], [endis(w)]: 0.509289, [decoder(mse)]: 0.432946]\n",
      "Epoch 70/2000\n",
      "[Dis(w): 0.264261], [endis(w)]: 0.488030, [decoder(mse)]: 0.436390]\n",
      "Epoch 71/2000\n",
      "[Dis(w): 0.264655], [endis(w)]: 0.512626, [decoder(mse)]: 0.401647]\n",
      "Epoch 72/2000\n",
      "[Dis(w): 0.264557], [endis(w)]: 0.510037, [decoder(mse)]: 0.413447]\n",
      "Epoch 73/2000\n",
      "[Dis(w): 0.264353], [endis(w)]: 0.487539, [decoder(mse)]: 0.418925]\n",
      "Epoch 74/2000\n",
      "[Dis(w): 0.264283], [endis(w)]: 0.507559, [decoder(mse)]: 0.410914]\n",
      "Epoch 75/2000\n",
      "[Dis(w): 0.264166], [endis(w)]: 0.500076, [decoder(mse)]: 0.414037]\n",
      "Epoch 76/2000\n",
      "[Dis(w): 0.264113], [endis(w)]: 0.510968, [decoder(mse)]: 0.418910]\n",
      "Epoch 77/2000\n",
      "[Dis(w): 0.263830], [endis(w)]: 0.499385, [decoder(mse)]: 0.425977]\n",
      "Epoch 78/2000\n",
      "[Dis(w): 0.263917], [endis(w)]: 0.487555, [decoder(mse)]: 0.431427]\n",
      "Epoch 79/2000\n",
      "[Dis(w): 0.263807], [endis(w)]: 0.492238, [decoder(mse)]: 0.429008]\n",
      "Epoch 80/2000\n",
      "[Dis(w): 0.263815], [endis(w)]: 0.502155, [decoder(mse)]: 0.428905]\n",
      "Epoch 81/2000\n",
      "[Dis(w): 0.262894], [endis(w)]: 0.494762, [decoder(mse)]: 0.450962]\n",
      "Epoch 82/2000\n",
      "[Dis(w): 0.263193], [endis(w)]: 0.507887, [decoder(mse)]: 0.429416]\n",
      "Epoch 83/2000\n",
      "[Dis(w): 0.263588], [endis(w)]: 0.499952, [decoder(mse)]: 0.433341]\n",
      "Epoch 84/2000\n",
      "[Dis(w): 0.264007], [endis(w)]: 0.496882, [decoder(mse)]: 0.425985]\n",
      "Epoch 85/2000\n",
      "[Dis(w): 0.263989], [endis(w)]: 0.493986, [decoder(mse)]: 0.424689]\n",
      "Epoch 86/2000\n",
      "[Dis(w): 0.263901], [endis(w)]: 0.492793, [decoder(mse)]: 0.418469]\n",
      "Epoch 87/2000\n",
      "[Dis(w): 0.264105], [endis(w)]: 0.483166, [decoder(mse)]: 0.422404]\n",
      "Epoch 88/2000\n",
      "[Dis(w): 0.264209], [endis(w)]: 0.475182, [decoder(mse)]: 0.425686]\n",
      "Epoch 89/2000\n",
      "[Dis(w): 0.264208], [endis(w)]: 0.495284, [decoder(mse)]: 0.427310]\n",
      "Epoch 90/2000\n",
      "[Dis(w): 0.264079], [endis(w)]: 0.508528, [decoder(mse)]: 0.423593]\n",
      "Epoch 91/2000\n",
      "[Dis(w): 0.263797], [endis(w)]: 0.519258, [decoder(mse)]: 0.396359]\n",
      "Epoch 92/2000\n",
      "[Dis(w): 0.263809], [endis(w)]: 0.515489, [decoder(mse)]: 0.403354]\n",
      "Epoch 93/2000\n",
      "[Dis(w): 0.264112], [endis(w)]: 0.508260, [decoder(mse)]: 0.418060]\n",
      "Epoch 94/2000\n",
      "[Dis(w): 0.263971], [endis(w)]: 0.500466, [decoder(mse)]: 0.423521]\n",
      "Epoch 95/2000\n",
      "[Dis(w): 0.264048], [endis(w)]: 0.510326, [decoder(mse)]: 0.417539]\n",
      "Epoch 96/2000\n",
      "[Dis(w): 0.264066], [endis(w)]: 0.514167, [decoder(mse)]: 0.423003]\n",
      "Epoch 97/2000\n",
      "[Dis(w): 0.264120], [endis(w)]: 0.480967, [decoder(mse)]: 0.422202]\n",
      "Epoch 98/2000\n",
      "[Dis(w): 0.264151], [endis(w)]: 0.511057, [decoder(mse)]: 0.421020]\n",
      "Epoch 99/2000\n",
      "[Dis(w): 0.264092], [endis(w)]: 0.515794, [decoder(mse)]: 0.421499]\n",
      "Epoch 100/2000\n",
      "[Dis(w): 0.264116], [endis(w)]: 0.504121, [decoder(mse)]: 0.424324]\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dis(w): 0.264842], [endis(w)]: 0.510174, [decoder(mse)]: 0.442591]\n",
      "Epoch 102/2000\n",
      "[Dis(w): 0.265091], [endis(w)]: 0.507934, [decoder(mse)]: 0.430078]\n",
      "Epoch 103/2000\n",
      "[Dis(w): 0.265091], [endis(w)]: 0.510624, [decoder(mse)]: 0.424878]\n",
      "Epoch 104/2000\n",
      "[Dis(w): 0.264774], [endis(w)]: 0.512174, [decoder(mse)]: 0.417525]\n",
      "Epoch 105/2000\n",
      "[Dis(w): 0.264791], [endis(w)]: 0.488981, [decoder(mse)]: 0.420628]\n",
      "Epoch 106/2000\n",
      "[Dis(w): 0.264841], [endis(w)]: 0.513353, [decoder(mse)]: 0.423578]\n",
      "Epoch 107/2000\n",
      "[Dis(w): 0.264485], [endis(w)]: 0.510347, [decoder(mse)]: 0.419193]\n",
      "Epoch 108/2000\n",
      "[Dis(w): 0.264415], [endis(w)]: 0.497456, [decoder(mse)]: 0.419914]\n",
      "Epoch 109/2000\n",
      "[Dis(w): 0.264434], [endis(w)]: 0.503266, [decoder(mse)]: 0.417118]\n",
      "Epoch 110/2000\n",
      "[Dis(w): 0.264375], [endis(w)]: 0.499035, [decoder(mse)]: 0.419977]\n",
      "Epoch 111/2000\n",
      "[Dis(w): 0.263858], [endis(w)]: 0.491554, [decoder(mse)]: 0.404532]\n",
      "Epoch 112/2000\n",
      "[Dis(w): 0.263290], [endis(w)]: 0.508962, [decoder(mse)]: 0.455607]\n",
      "Epoch 113/2000\n",
      "[Dis(w): 0.263471], [endis(w)]: 0.514362, [decoder(mse)]: 0.430394]\n",
      "Epoch 114/2000\n",
      "[Dis(w): 0.263677], [endis(w)]: 0.502659, [decoder(mse)]: 0.446293]\n",
      "Epoch 115/2000\n",
      "[Dis(w): 0.263752], [endis(w)]: 0.519533, [decoder(mse)]: 0.441335]\n",
      "Epoch 116/2000\n",
      "[Dis(w): 0.263865], [endis(w)]: 0.514312, [decoder(mse)]: 0.434372]\n",
      "Epoch 117/2000\n",
      "[Dis(w): 0.263914], [endis(w)]: 0.501596, [decoder(mse)]: 0.428679]\n",
      "Epoch 118/2000\n",
      "[Dis(w): 0.263904], [endis(w)]: 0.509217, [decoder(mse)]: 0.430200]\n",
      "Epoch 119/2000\n",
      "[Dis(w): 0.263880], [endis(w)]: 0.493182, [decoder(mse)]: 0.430720]\n",
      "Epoch 120/2000\n",
      "[Dis(w): 0.263816], [endis(w)]: 0.514941, [decoder(mse)]: 0.426664]\n",
      "Epoch 121/2000\n",
      "[Dis(w): 0.262243], [endis(w)]: 0.508817, [decoder(mse)]: 0.448373]\n",
      "Epoch 122/2000\n",
      "[Dis(w): 0.262863], [endis(w)]: 0.491545, [decoder(mse)]: 0.432323]\n",
      "Epoch 123/2000\n",
      "[Dis(w): 0.263417], [endis(w)]: 0.509013, [decoder(mse)]: 0.426445]\n",
      "Epoch 124/2000\n",
      "[Dis(w): 0.263720], [endis(w)]: 0.478930, [decoder(mse)]: 0.421279]\n",
      "Epoch 125/2000\n",
      "[Dis(w): 0.263896], [endis(w)]: 0.497417, [decoder(mse)]: 0.427529]\n",
      "Epoch 126/2000\n",
      "[Dis(w): 0.264063], [endis(w)]: 0.485684, [decoder(mse)]: 0.423603]\n",
      "Epoch 127/2000\n",
      "[Dis(w): 0.263814], [endis(w)]: 0.504640, [decoder(mse)]: 0.424970]\n",
      "Epoch 128/2000\n",
      "[Dis(w): 0.263818], [endis(w)]: 0.500981, [decoder(mse)]: 0.427687]\n",
      "Epoch 129/2000\n",
      "[Dis(w): 0.264059], [endis(w)]: 0.487226, [decoder(mse)]: 0.426403]\n",
      "Epoch 130/2000\n",
      "[Dis(w): 0.263982], [endis(w)]: 0.493856, [decoder(mse)]: 0.432475]\n",
      "Epoch 131/2000\n",
      "[Dis(w): 0.262275], [endis(w)]: 0.501201, [decoder(mse)]: 0.453757]\n",
      "Epoch 132/2000\n",
      "[Dis(w): 0.263135], [endis(w)]: 0.495859, [decoder(mse)]: 0.452699]\n",
      "Epoch 133/2000\n",
      "[Dis(w): 0.263782], [endis(w)]: 0.507533, [decoder(mse)]: 0.430859]\n",
      "Epoch 134/2000\n",
      "[Dis(w): 0.263975], [endis(w)]: 0.487959, [decoder(mse)]: 0.428072]\n",
      "Epoch 135/2000\n",
      "[Dis(w): 0.264243], [endis(w)]: 0.508088, [decoder(mse)]: 0.424086]\n",
      "Epoch 136/2000\n",
      "[Dis(w): 0.264334], [endis(w)]: 0.490482, [decoder(mse)]: 0.416965]\n",
      "Epoch 137/2000\n",
      "[Dis(w): 0.264200], [endis(w)]: 0.517481, [decoder(mse)]: 0.421039]\n",
      "Epoch 138/2000\n",
      "[Dis(w): 0.264153], [endis(w)]: 0.525649, [decoder(mse)]: 0.418443]\n",
      "Epoch 139/2000\n",
      "[Dis(w): 0.264365], [endis(w)]: 0.498236, [decoder(mse)]: 0.418219]\n",
      "Epoch 140/2000\n",
      "[Dis(w): 0.264236], [endis(w)]: 0.505035, [decoder(mse)]: 0.421289]\n",
      "Epoch 141/2000\n",
      "[Dis(w): 0.263411], [endis(w)]: 0.502106, [decoder(mse)]: 0.414635]\n",
      "Epoch 142/2000\n",
      "[Dis(w): 0.263669], [endis(w)]: 0.521226, [decoder(mse)]: 0.420773]\n",
      "Epoch 143/2000\n",
      "[Dis(w): 0.263422], [endis(w)]: 0.505635, [decoder(mse)]: 0.414631]\n",
      "Epoch 144/2000\n",
      "[Dis(w): 0.263492], [endis(w)]: 0.523770, [decoder(mse)]: 0.422838]\n",
      "Epoch 145/2000\n",
      "[Dis(w): 0.263513], [endis(w)]: 0.512454, [decoder(mse)]: 0.416789]\n",
      "Epoch 146/2000\n",
      "[Dis(w): 0.263580], [endis(w)]: 0.507885, [decoder(mse)]: 0.419131]\n",
      "Epoch 147/2000\n",
      "[Dis(w): 0.263688], [endis(w)]: 0.514704, [decoder(mse)]: 0.419468]\n",
      "Epoch 148/2000\n",
      "[Dis(w): 0.263775], [endis(w)]: 0.487657, [decoder(mse)]: 0.418417]\n",
      "Epoch 149/2000\n",
      "[Dis(w): 0.263958], [endis(w)]: 0.504610, [decoder(mse)]: 0.421729]\n",
      "Epoch 150/2000\n",
      "[Dis(w): 0.264004], [endis(w)]: 0.510967, [decoder(mse)]: 0.420907]\n",
      "Epoch 151/2000\n",
      "[Dis(w): 0.264879], [endis(w)]: 0.507142, [decoder(mse)]: 0.405135]\n",
      "Epoch 152/2000\n",
      "[Dis(w): 0.264116], [endis(w)]: 0.512545, [decoder(mse)]: 0.409547]\n",
      "Epoch 153/2000\n",
      "[Dis(w): 0.263957], [endis(w)]: 0.501138, [decoder(mse)]: 0.406587]\n",
      "Epoch 154/2000\n",
      "[Dis(w): 0.264022], [endis(w)]: 0.488864, [decoder(mse)]: 0.412450]\n",
      "Epoch 155/2000\n",
      "[Dis(w): 0.263927], [endis(w)]: 0.506001, [decoder(mse)]: 0.415417]\n",
      "Epoch 156/2000\n",
      "[Dis(w): 0.263995], [endis(w)]: 0.479624, [decoder(mse)]: 0.419512]\n",
      "Epoch 157/2000\n",
      "[Dis(w): 0.264032], [endis(w)]: 0.518047, [decoder(mse)]: 0.421177]\n",
      "Epoch 158/2000\n",
      "[Dis(w): 0.264175], [endis(w)]: 0.514430, [decoder(mse)]: 0.426026]\n",
      "Epoch 159/2000\n",
      "[Dis(w): 0.264124], [endis(w)]: 0.513844, [decoder(mse)]: 0.420548]\n",
      "Epoch 160/2000\n",
      "[Dis(w): 0.264141], [endis(w)]: 0.505654, [decoder(mse)]: 0.421562]\n",
      "Epoch 161/2000\n",
      "[Dis(w): 0.264943], [endis(w)]: 0.508682, [decoder(mse)]: 0.433165]\n",
      "Epoch 162/2000\n",
      "[Dis(w): 0.264439], [endis(w)]: 0.489574, [decoder(mse)]: 0.430085]\n",
      "Epoch 163/2000\n",
      "[Dis(w): 0.264803], [endis(w)]: 0.483393, [decoder(mse)]: 0.429369]\n",
      "Epoch 164/2000\n",
      "[Dis(w): 0.264842], [endis(w)]: 0.502495, [decoder(mse)]: 0.440497]\n",
      "Epoch 165/2000\n",
      "[Dis(w): 0.264702], [endis(w)]: 0.485313, [decoder(mse)]: 0.448536]\n",
      "Epoch 166/2000\n",
      "[Dis(w): 0.264649], [endis(w)]: 0.501699, [decoder(mse)]: 0.440632]\n",
      "Epoch 167/2000\n",
      "[Dis(w): 0.264324], [endis(w)]: 0.502347, [decoder(mse)]: 0.435448]\n",
      "Epoch 168/2000\n",
      "[Dis(w): 0.264157], [endis(w)]: 0.523317, [decoder(mse)]: 0.442068]\n",
      "Epoch 169/2000\n",
      "[Dis(w): 0.264000], [endis(w)]: 0.524678, [decoder(mse)]: 0.442830]\n",
      "Epoch 170/2000\n",
      "[Dis(w): 0.263902], [endis(w)]: 0.485931, [decoder(mse)]: 0.438947]\n",
      "Epoch 171/2000\n",
      "[Dis(w): 0.264177], [endis(w)]: 0.510787, [decoder(mse)]: 0.397171]\n",
      "Epoch 172/2000\n",
      "[Dis(w): 0.264334], [endis(w)]: 0.515116, [decoder(mse)]: 0.423031]\n",
      "Epoch 173/2000\n",
      "[Dis(w): 0.264437], [endis(w)]: 0.513533, [decoder(mse)]: 0.411937]\n",
      "Epoch 174/2000\n",
      "[Dis(w): 0.264334], [endis(w)]: 0.502501, [decoder(mse)]: 0.426375]\n",
      "Epoch 175/2000\n",
      "[Dis(w): 0.264205], [endis(w)]: 0.496878, [decoder(mse)]: 0.419907]\n",
      "Epoch 176/2000\n",
      "[Dis(w): 0.264154], [endis(w)]: 0.492367, [decoder(mse)]: 0.432782]\n",
      "Epoch 177/2000\n",
      "[Dis(w): 0.264216], [endis(w)]: 0.505485, [decoder(mse)]: 0.437906]\n",
      "Epoch 178/2000\n",
      "[Dis(w): 0.264079], [endis(w)]: 0.483928, [decoder(mse)]: 0.434259]\n",
      "Epoch 179/2000\n",
      "[Dis(w): 0.264114], [endis(w)]: 0.514743, [decoder(mse)]: 0.430603]\n",
      "Epoch 180/2000\n",
      "[Dis(w): 0.264127], [endis(w)]: 0.526278, [decoder(mse)]: 0.428625]\n",
      "Epoch 181/2000\n",
      "[Dis(w): 0.263531], [endis(w)]: 0.483022, [decoder(mse)]: 0.428014]\n",
      "Epoch 182/2000\n",
      "[Dis(w): 0.264033], [endis(w)]: 0.504290, [decoder(mse)]: 0.427454]\n",
      "Epoch 183/2000\n",
      "[Dis(w): 0.263917], [endis(w)]: 0.533580, [decoder(mse)]: 0.427792]\n",
      "Epoch 184/2000\n",
      "[Dis(w): 0.264336], [endis(w)]: 0.523880, [decoder(mse)]: 0.428376]\n",
      "Epoch 185/2000\n",
      "[Dis(w): 0.264516], [endis(w)]: 0.493779, [decoder(mse)]: 0.437666]\n",
      "Epoch 186/2000\n",
      "[Dis(w): 0.264536], [endis(w)]: 0.515655, [decoder(mse)]: 0.438695]\n",
      "Epoch 187/2000\n",
      "[Dis(w): 0.264309], [endis(w)]: 0.499094, [decoder(mse)]: 0.440335]\n",
      "Epoch 188/2000\n",
      "[Dis(w): 0.264273], [endis(w)]: 0.511845, [decoder(mse)]: 0.440819]\n",
      "Epoch 189/2000\n",
      "[Dis(w): 0.264246], [endis(w)]: 0.509971, [decoder(mse)]: 0.438817]\n",
      "Epoch 190/2000\n",
      "[Dis(w): 0.264207], [endis(w)]: 0.491447, [decoder(mse)]: 0.437079]\n",
      "Epoch 191/2000\n",
      "[Dis(w): 0.264114], [endis(w)]: 0.520703, [decoder(mse)]: 0.412140]\n",
      "Epoch 192/2000\n",
      "[Dis(w): 0.264301], [endis(w)]: 0.508746, [decoder(mse)]: 0.423910]\n",
      "Epoch 193/2000\n",
      "[Dis(w): 0.264658], [endis(w)]: 0.501887, [decoder(mse)]: 0.443595]\n",
      "Epoch 194/2000\n",
      "[Dis(w): 0.264305], [endis(w)]: 0.517381, [decoder(mse)]: 0.447882]\n",
      "Epoch 195/2000\n",
      "[Dis(w): 0.264311], [endis(w)]: 0.506724, [decoder(mse)]: 0.444539]\n",
      "Epoch 196/2000\n",
      "[Dis(w): 0.264286], [endis(w)]: 0.493765, [decoder(mse)]: 0.433620]\n",
      "Epoch 197/2000\n",
      "[Dis(w): 0.264261], [endis(w)]: 0.516584, [decoder(mse)]: 0.433843]\n",
      "Epoch 198/2000\n",
      "[Dis(w): 0.264295], [endis(w)]: 0.511203, [decoder(mse)]: 0.434009]\n",
      "Epoch 199/2000\n",
      "[Dis(w): 0.264269], [endis(w)]: 0.509353, [decoder(mse)]: 0.429605]\n",
      "Epoch 200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dis(w): 0.264232], [endis(w)]: 0.518917, [decoder(mse)]: 0.430137]\n",
      "Epoch 201/2000\n",
      "[Dis(w): 0.263669], [endis(w)]: 0.502124, [decoder(mse)]: 0.439471]\n",
      "Epoch 202/2000\n",
      "[Dis(w): 0.264036], [endis(w)]: 0.501076, [decoder(mse)]: 0.428029]\n",
      "Epoch 203/2000\n",
      "[Dis(w): 0.263952], [endis(w)]: 0.508496, [decoder(mse)]: 0.410538]\n",
      "Epoch 204/2000\n",
      "[Dis(w): 0.264066], [endis(w)]: 0.526354, [decoder(mse)]: 0.425109]\n",
      "Epoch 205/2000\n",
      "[Dis(w): 0.263958], [endis(w)]: 0.510444, [decoder(mse)]: 0.427476]\n",
      "Epoch 206/2000\n",
      "[Dis(w): 0.263936], [endis(w)]: 0.495176, [decoder(mse)]: 0.433005]\n",
      "Epoch 207/2000\n",
      "[Dis(w): 0.264066], [endis(w)]: 0.489410, [decoder(mse)]: 0.432212]\n",
      "Epoch 208/2000\n",
      "[Dis(w): 0.264052], [endis(w)]: 0.502519, [decoder(mse)]: 0.428737]\n",
      "Epoch 209/2000\n",
      "[Dis(w): 0.264088], [endis(w)]: 0.492911, [decoder(mse)]: 0.433930]\n",
      "Epoch 210/2000\n",
      "[Dis(w): 0.264198], [endis(w)]: 0.502225, [decoder(mse)]: 0.436298]\n",
      "Epoch 211/2000\n",
      "[Dis(w): 0.263169], [endis(w)]: 0.516623, [decoder(mse)]: 0.431213]\n",
      "Epoch 212/2000\n",
      "[Dis(w): 0.264168], [endis(w)]: 0.508072, [decoder(mse)]: 0.423814]\n",
      "Epoch 213/2000\n",
      "[Dis(w): 0.264533], [endis(w)]: 0.498927, [decoder(mse)]: 0.428173]\n",
      "Epoch 214/2000\n",
      "[Dis(w): 0.264171], [endis(w)]: 0.509011, [decoder(mse)]: 0.433056]\n",
      "Epoch 215/2000\n",
      "[Dis(w): 0.264100], [endis(w)]: 0.513963, [decoder(mse)]: 0.435792]\n",
      "Epoch 216/2000\n",
      "[Dis(w): 0.263996], [endis(w)]: 0.492330, [decoder(mse)]: 0.432089]\n",
      "Epoch 217/2000\n",
      "[Dis(w): 0.264150], [endis(w)]: 0.502194, [decoder(mse)]: 0.425813]\n",
      "Epoch 218/2000\n",
      "[Dis(w): 0.264128], [endis(w)]: 0.509710, [decoder(mse)]: 0.426152]\n",
      "Epoch 219/2000\n",
      "[Dis(w): 0.264122], [endis(w)]: 0.513848, [decoder(mse)]: 0.424367]\n",
      "Epoch 220/2000\n",
      "[Dis(w): 0.264053], [endis(w)]: 0.520169, [decoder(mse)]: 0.422991]\n",
      "Epoch 221/2000\n",
      "[Dis(w): 0.263963], [endis(w)]: 0.508581, [decoder(mse)]: 0.414393]\n",
      "Epoch 222/2000\n",
      "[Dis(w): 0.264429], [endis(w)]: 0.500742, [decoder(mse)]: 0.446988]\n",
      "Epoch 223/2000\n",
      "[Dis(w): 0.264343], [endis(w)]: 0.504992, [decoder(mse)]: 0.436709]\n",
      "Epoch 224/2000\n",
      "[Dis(w): 0.264306], [endis(w)]: 0.518569, [decoder(mse)]: 0.432115]\n",
      "Epoch 225/2000\n",
      "[Dis(w): 0.264094], [endis(w)]: 0.513029, [decoder(mse)]: 0.427801]\n",
      "Epoch 226/2000\n",
      "[Dis(w): 0.264067], [endis(w)]: 0.512417, [decoder(mse)]: 0.432230]\n",
      "Epoch 227/2000\n",
      "[Dis(w): 0.263954], [endis(w)]: 0.513393, [decoder(mse)]: 0.430261]\n",
      "Epoch 228/2000\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(Z,BATCH_SIZE,train_dataset, epochs, scaler, scaled,X_train_scaled)\n",
    "#Dropout0.8+delete Flatten, epoch=2000  \n",
    "#0126Dropout0.6+delete Flatten+encoder/decoder\n",
    "\n",
    "\n",
    "#1203LeakyReLU+Flatten\n",
    "#Change e/d architexture+1203\n",
    "#backend/4\n",
    "\n",
    "\n",
    "#self.n_critic=10\n",
    "#n_c=5\n",
    "#complex dis_network + more n_autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict from the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the labels of the data values on the basis of the trained model.\n",
    "#sampling from the latent space without prediction\n",
    "\n",
    "latent_values = np.random.normal(loc=0, scale=1, size=([1000, Z]))\n",
    "predicted_values = aae.decoder(latent_values)\n",
    "\n",
    "predicted_values2 = aae.decoder(aae.encoder(X_train_scaled))\n",
    "predicted_values3 = aae.encoder(X_train_scaled)\n",
    "predicted_values4 = scaler.inverse_transform(X_train_scaled)\n",
    "\n",
    "if scaled == '-1-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    #predicted_values3 = scaler.inverse_transform(predicted_values3)\n",
    "    \n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "\n",
    "\n",
    "if n_features==3:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    print(\"latent_space:\",Z)\n",
    "    print(\"BATCH_SIZE:\",BATCH_SIZE)\n",
    "    print(\"epochs:\",epochs)\n",
    "    \n",
    "\n",
    "    ab = plt.subplot(projection='3d')\n",
    "    ab.scatter(predicted_values[:,0],predicted_values[:,1],predicted_values[:,2])\n",
    "    ab.set_ylabel('Y')\n",
    "    ab.set_zlabel('Z')\n",
    "    ab.set_xlabel('X')\n",
    "    \n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(predicted_values[:,1],predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,0]>=-0.8-0.05,predicted_values[:,0]<=-0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,0]>=0.0-0.05,predicted_values[:,0]<=0.0+0.05),predicted_values[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,0]>=0.8-0.05,predicted_values[:,0]<=0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,1]>=0.2-0.05,predicted_values[:,1]<=0.2+0.05),predicted_values[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,1]>=0.5-0.05,predicted_values[:,1]<=0.5+0.05),predicted_values[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,1]>=0.8-0.05,predicted_values[:,1]<=0.8+0.05),predicted_values[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    #plt.scatter(X_train, y_train,c='orange') #sample\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "\n",
    "    axes[0].scatter(predicted_values3[:,0],predicted_values3[:,1],c='pink')#encoder(X_train_scaled)\n",
    "    axes[0].scatter(latent_values[:,0],latent_values[:,1],c='grey')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].set_xlabel('X')\n",
    "\n",
    "    \n",
    "    \n",
    "    axes[1].scatter(predicted_values2[:,0],predicted_values2[:,1],)#encoder/decoder\n",
    "    #axes[1].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[1].set_ylabel('Y')\n",
    "    axes[1].set_xlabel('X')\n",
    "\n",
    "    \n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,1],c='red') #decoder(latent space)\n",
    "    #axes[2].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[2].set_ylabel('Y')\n",
    "    axes[2].set_xlabel('X')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input = [-4,-3,-2,-1,0,1,2,3,4]\n",
    "n_points = 900\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//9, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//9, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//9, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//9, n_features), x_input[3])\n",
    "predict5 = np.full((n_points//9, n_features), x_input[4])\n",
    "predict6 = np.full((n_points//9, n_features), x_input[5])\n",
    "predict7 = np.full((n_points//9, n_features), x_input[6])\n",
    "predict8 = np.full((n_points//9, n_features), x_input[7])\n",
    "predict9 = np.full((n_points//9, n_features), x_input[8])\n",
    "\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4, predict5, predict6, predict7, predict8, predict9))\n",
    "predictthis = scaler.fit_transform(predictthis)\n",
    "input_test = predictthis.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_generated = aae.generator.predict(input_test)\n",
    "X_generated = aae.decoder(aae.encoder.predict(input_test))\n",
    "X_generated = scaler.inverse_transform(X_generated)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    print(\"latent_space=\",latent_space)\n",
    "    print(\"Epochs=\",epochs)\n",
    "    print(\"BATCH_SIZE=\",BATCH_SIZE)\n",
    "    print(\"use_bias=\",use_bias)\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,c='orange') \n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    plt.scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    #plt.scatter(predicted_values2[:,0],predicted_values2[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
