{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import python dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"sinus\" #sinus, helix\n",
    "#n_instance = 1000\n",
    "n_instance = 1000\n",
    "n_features = 2\n",
    "Z = 6 #3的倍數\n",
    "nodes = 8 #4\n",
    "var = 4\n",
    "use_bias = 'True'\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "export_excel(X_train, 'Dataset/X_train')\n",
    "export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2048        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1024)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 32)       0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32)       128         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 32, 32)       1024        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32)       128         conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 32, 32)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 32, 8)        256         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 8)        32          conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 8)        0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            1536        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            1536        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6)            24          lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 8,604\n",
      "Non-trainable params: 2,204\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,302\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 16, 32)            512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 32)            128       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 16)            512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16)            64        \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 16, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 256       \n",
      "=================================================================\n",
      "Total params: 4,032\n",
      "Trainable params: 3,424\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=network.build_encoder(Z, nodes, n_features)\n",
    "decoder=network.build_decoder(Z, var, n_features, use_bias)\n",
    "discriminator=network.build_discriminator(Z, nodes)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model\n",
    "\n",
    "GANorWGAN='WGAN' #GAN\n",
    "epochs = 2000 #2000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         2048        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1024)         4096        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 1024)         0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 32, 32)       0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32)       128         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 32, 32)       1024        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32)       128         conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 32, 32)       0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTrans (None, 32, 8)        256         re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 8)        32          conv1d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 32, 8)        0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            1536        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 6)            1536        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6)            0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 6)            24          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,808\n",
      "Trainable params: 8,604\n",
      "Non-trainable params: 2,204\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,302\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aae = AAE_Model.AAE(i, Z, n_features, batch_size, GANorWGAN, nodes, var, use_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (100, 2)\n",
      "data shape_2 (100, 2)\n",
      "data shape_3 (100, 2)\n",
      "data shape_4 (100, 2)\n",
      "data shape_5 (100, 2)\n",
      "data shape_6 (100, 2)\n",
      "data shape_7 (100, 2)\n",
      "data shape_8 (100, 2)\n",
      "data shape_9 (100, 2)\n",
      "data shape_10 (100, 2)\n",
      "Cycles:  10\n",
      "X_train (1000, 1)\n",
      "y_train (1000, 1)\n",
      "X_train_scaled (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "1 [D real: -0.487808, D fake: 0.519029], [Enc/Dec loss: 0.573836, Enc/Dis: 0.579523]\n",
      "2 [D real: -0.495592, D fake: 0.522446], [Enc/Dec loss: 0.352840, Enc/Dis: 0.358225]\n",
      "3 [D real: -0.510981, D fake: 0.530587], [Enc/Dec loss: 0.277295, Enc/Dis: 0.282565]\n",
      "4 [D real: -0.516084, D fake: 0.534379], [Enc/Dec loss: 0.198007, Enc/Dis: 0.203188]\n",
      "5 [D real: -0.525385, D fake: 0.537889], [Enc/Dec loss: 0.177486, Enc/Dis: 0.182635]\n",
      "6 [D real: -0.529801, D fake: 0.538169], [Enc/Dec loss: 0.146531, Enc/Dis: 0.151682]\n",
      "7 [D real: -0.531990, D fake: 0.539190], [Enc/Dec loss: 0.141370, Enc/Dis: 0.146546]\n",
      "8 [D real: -0.534987, D fake: 0.541342], [Enc/Dec loss: 0.118334, Enc/Dis: 0.123527]\n",
      "9 [D real: -0.538387, D fake: 0.543215], [Enc/Dec loss: 0.114841, Enc/Dis: 0.120036]\n",
      "10 [D real: -0.539304, D fake: 0.545237], [Enc/Dec loss: 0.106700, Enc/Dis: 0.111861]\n",
      "11 [D real: -0.553649, D fake: 0.548186], [Enc/Dec loss: 0.108424, Enc/Dis: 0.113560]\n",
      "12 [D real: -0.548135, D fake: 0.554119], [Enc/Dec loss: 0.102069, Enc/Dis: 0.107253]\n",
      "13 [D real: -0.552795, D fake: 0.556558], [Enc/Dec loss: 0.099767, Enc/Dis: 0.104893]\n",
      "14 [D real: -0.550481, D fake: 0.555782], [Enc/Dec loss: 0.095894, Enc/Dis: 0.101079]\n",
      "15 [D real: -0.551360, D fake: 0.555352], [Enc/Dec loss: 0.092151, Enc/Dis: 0.097336]\n",
      "16 [D real: -0.555008, D fake: 0.552954], [Enc/Dec loss: 0.086153, Enc/Dis: 0.091448]\n",
      "17 [D real: -0.554422, D fake: 0.554070], [Enc/Dec loss: 0.085716, Enc/Dis: 0.090952]\n",
      "18 [D real: -0.553268, D fake: 0.555024], [Enc/Dec loss: 0.080258, Enc/Dis: 0.085507]\n",
      "19 [D real: -0.553315, D fake: 0.553683], [Enc/Dec loss: 0.088037, Enc/Dis: 0.093410]\n",
      "20 [D real: -0.552029, D fake: 0.553434], [Enc/Dec loss: 0.081266, Enc/Dis: 0.086615]\n",
      "21 [D real: -0.551341, D fake: 0.552514], [Enc/Dec loss: 0.080029, Enc/Dis: 0.085401]\n",
      "22 [D real: -0.544339, D fake: 0.545804], [Enc/Dec loss: 0.077615, Enc/Dis: 0.083081]\n",
      "23 [D real: -0.549718, D fake: 0.542673], [Enc/Dec loss: 0.085796, Enc/Dis: 0.091261]\n",
      "24 [D real: -0.546457, D fake: 0.549736], [Enc/Dec loss: 0.076313, Enc/Dis: 0.081758]\n",
      "25 [D real: -0.552780, D fake: 0.551653], [Enc/Dec loss: 0.079058, Enc/Dis: 0.084545]\n",
      "26 [D real: -0.553765, D fake: 0.550459], [Enc/Dec loss: 0.072218, Enc/Dis: 0.077771]\n",
      "27 [D real: -0.554162, D fake: 0.553197], [Enc/Dec loss: 0.073481, Enc/Dis: 0.079123]\n",
      "28 [D real: -0.553737, D fake: 0.554997], [Enc/Dec loss: 0.076768, Enc/Dis: 0.082646]\n",
      "29 [D real: -0.554171, D fake: 0.554895], [Enc/Dec loss: 0.075177, Enc/Dis: 0.081045]\n",
      "30 [D real: -0.553216, D fake: 0.556813], [Enc/Dec loss: 0.078995, Enc/Dis: 0.084833]\n",
      "31 [D real: -0.557935, D fake: 0.559168], [Enc/Dec loss: 0.074043, Enc/Dis: 0.079843]\n",
      "32 [D real: -0.551579, D fake: 0.556903], [Enc/Dec loss: 0.070551, Enc/Dis: 0.076072]\n",
      "33 [D real: -0.552527, D fake: 0.551855], [Enc/Dec loss: 0.066749, Enc/Dis: 0.072180]\n",
      "34 [D real: -0.554542, D fake: 0.550503], [Enc/Dec loss: 0.070210, Enc/Dis: 0.075648]\n",
      "35 [D real: -0.552582, D fake: 0.551656], [Enc/Dec loss: 0.071151, Enc/Dis: 0.076549]\n",
      "36 [D real: -0.553998, D fake: 0.552291], [Enc/Dec loss: 0.072318, Enc/Dis: 0.077577]\n",
      "37 [D real: -0.554096, D fake: 0.554193], [Enc/Dec loss: 0.068826, Enc/Dis: 0.074039]\n",
      "38 [D real: -0.555233, D fake: 0.554873], [Enc/Dec loss: 0.067645, Enc/Dis: 0.072914]\n",
      "39 [D real: -0.555504, D fake: 0.552098], [Enc/Dec loss: 0.074835, Enc/Dis: 0.079920]\n",
      "40 [D real: -0.553598, D fake: 0.551828], [Enc/Dec loss: 0.067682, Enc/Dis: 0.072567]\n",
      "41 [D real: -0.557028, D fake: 0.548193], [Enc/Dec loss: 0.067831, Enc/Dis: 0.072678]\n",
      "42 [D real: -0.552133, D fake: 0.554538], [Enc/Dec loss: 0.070013, Enc/Dis: 0.074850]\n",
      "43 [D real: -0.553756, D fake: 0.561654], [Enc/Dec loss: 0.065160, Enc/Dis: 0.069702]\n",
      "44 [D real: -0.555244, D fake: 0.562613], [Enc/Dec loss: 0.077044, Enc/Dis: 0.081324]\n",
      "45 [D real: -0.554928, D fake: 0.558356], [Enc/Dec loss: 0.064696, Enc/Dis: 0.068798]\n",
      "46 [D real: -0.554238, D fake: 0.557296], [Enc/Dec loss: 0.071522, Enc/Dis: 0.075478]\n",
      "47 [D real: -0.552985, D fake: 0.555732], [Enc/Dec loss: 0.067224, Enc/Dis: 0.071307]\n",
      "48 [D real: -0.551722, D fake: 0.556675], [Enc/Dec loss: 0.069639, Enc/Dis: 0.073601]\n",
      "49 [D real: -0.552053, D fake: 0.556319], [Enc/Dec loss: 0.073208, Enc/Dis: 0.077069]\n",
      "50 [D real: -0.553702, D fake: 0.557165], [Enc/Dec loss: 0.065870, Enc/Dis: 0.069705]\n",
      "51 [D real: -0.562541, D fake: 0.580526], [Enc/Dec loss: 0.066487, Enc/Dis: 0.070089]\n",
      "52 [D real: -0.556428, D fake: 0.578450], [Enc/Dec loss: 0.066297, Enc/Dis: 0.070237]\n",
      "53 [D real: -0.565384, D fake: 0.566579], [Enc/Dec loss: 0.068475, Enc/Dis: 0.072573]\n",
      "54 [D real: -0.562554, D fake: 0.559089], [Enc/Dec loss: 0.067331, Enc/Dis: 0.071628]\n",
      "55 [D real: -0.568584, D fake: 0.558822], [Enc/Dec loss: 0.063811, Enc/Dis: 0.068112]\n",
      "56 [D real: -0.568546, D fake: 0.559326], [Enc/Dec loss: 0.070029, Enc/Dis: 0.074569]\n",
      "57 [D real: -0.562737, D fake: 0.557312], [Enc/Dec loss: 0.067798, Enc/Dis: 0.072504]\n",
      "58 [D real: -0.561537, D fake: 0.557666], [Enc/Dec loss: 0.060798, Enc/Dis: 0.065533]\n",
      "59 [D real: -0.563328, D fake: 0.559386], [Enc/Dec loss: 0.066616, Enc/Dis: 0.071749]\n",
      "60 [D real: -0.562974, D fake: 0.560783], [Enc/Dec loss: 0.069009, Enc/Dis: 0.074012]\n",
      "61 [D real: -0.553709, D fake: 0.562842], [Enc/Dec loss: 0.072976, Enc/Dis: 0.078183]\n",
      "62 [D real: -0.555544, D fake: 0.564174], [Enc/Dec loss: 0.065828, Enc/Dis: 0.071121]\n",
      "63 [D real: -0.553010, D fake: 0.563771], [Enc/Dec loss: 0.062567, Enc/Dis: 0.067956]\n",
      "64 [D real: -0.551946, D fake: 0.563381], [Enc/Dec loss: 0.070674, Enc/Dis: 0.075938]\n",
      "65 [D real: -0.556597, D fake: 0.565886], [Enc/Dec loss: 0.063570, Enc/Dis: 0.068232]\n",
      "66 [D real: -0.559549, D fake: 0.565890], [Enc/Dec loss: 0.070865, Enc/Dis: 0.075744]\n",
      "67 [D real: -0.562225, D fake: 0.565817], [Enc/Dec loss: 0.065768, Enc/Dis: 0.070702]\n",
      "68 [D real: -0.563161, D fake: 0.567191], [Enc/Dec loss: 0.062590, Enc/Dis: 0.067365]\n",
      "69 [D real: -0.562411, D fake: 0.568667], [Enc/Dec loss: 0.067371, Enc/Dis: 0.071821]\n",
      "70 [D real: -0.560415, D fake: 0.569826], [Enc/Dec loss: 0.058684, Enc/Dis: 0.063424]\n",
      "71 [D real: -0.557110, D fake: 0.543085], [Enc/Dec loss: 0.061001, Enc/Dis: 0.065492]\n",
      "72 [D real: -0.563443, D fake: 0.558031], [Enc/Dec loss: 0.071057, Enc/Dis: 0.075228]\n",
      "73 [D real: -0.566101, D fake: 0.559038], [Enc/Dec loss: 0.064163, Enc/Dis: 0.068455]\n",
      "74 [D real: -0.568400, D fake: 0.566280], [Enc/Dec loss: 0.062718, Enc/Dis: 0.067023]\n",
      "75 [D real: -0.565068, D fake: 0.566101], [Enc/Dec loss: 0.065455, Enc/Dis: 0.069426]\n",
      "76 [D real: -0.564945, D fake: 0.565771], [Enc/Dec loss: 0.061646, Enc/Dis: 0.066280]\n",
      "77 [D real: -0.564363, D fake: 0.565998], [Enc/Dec loss: 0.061130, Enc/Dis: 0.066502]\n",
      "78 [D real: -0.559876, D fake: 0.565818], [Enc/Dec loss: 0.059877, Enc/Dis: 0.063542]\n",
      "79 [D real: -0.559951, D fake: 0.567386], [Enc/Dec loss: 0.063091, Enc/Dis: 0.066932]\n",
      "80 [D real: -0.561149, D fake: 0.567010], [Enc/Dec loss: 0.064516, Enc/Dis: 0.070645]\n",
      "81 [D real: -0.562090, D fake: 0.576388], [Enc/Dec loss: 0.062714, Enc/Dis: 0.067050]\n",
      "82 [D real: -0.568285, D fake: 0.576892], [Enc/Dec loss: 0.066910, Enc/Dis: 0.071458]\n",
      "83 [D real: -0.566622, D fake: 0.571632], [Enc/Dec loss: 0.066210, Enc/Dis: 0.071018]\n",
      "84 [D real: -0.567773, D fake: 0.578660], [Enc/Dec loss: 0.065315, Enc/Dis: 0.070186]\n",
      "85 [D real: -0.569627, D fake: 0.575974], [Enc/Dec loss: 0.068991, Enc/Dis: 0.073742]\n",
      "86 [D real: -0.568729, D fake: 0.575912], [Enc/Dec loss: 0.059365, Enc/Dis: 0.063674]\n",
      "87 [D real: -0.569132, D fake: 0.574850], [Enc/Dec loss: 0.066039, Enc/Dis: 0.070844]\n",
      "88 [D real: -0.568476, D fake: 0.575604], [Enc/Dec loss: 0.061596, Enc/Dis: 0.066057]\n",
      "89 [D real: -0.569856, D fake: 0.574020], [Enc/Dec loss: 0.068015, Enc/Dis: 0.071350]\n",
      "90 [D real: -0.572132, D fake: 0.574394], [Enc/Dec loss: 0.065194, Enc/Dis: 0.068818]\n",
      "91 [D real: -0.545586, D fake: 0.565051], [Enc/Dec loss: 0.068787, Enc/Dis: 0.072837]\n",
      "92 [D real: -0.552675, D fake: 0.567724], [Enc/Dec loss: 0.062510, Enc/Dis: 0.066116]\n",
      "93 [D real: -0.555152, D fake: 0.572032], [Enc/Dec loss: 0.063483, Enc/Dis: 0.068031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 [D real: -0.563340, D fake: 0.570218], [Enc/Dec loss: 0.069887, Enc/Dis: 0.072708]\n",
      "95 [D real: -0.563550, D fake: 0.569124], [Enc/Dec loss: 0.059129, Enc/Dis: 0.064399]\n",
      "96 [D real: -0.563862, D fake: 0.573228], [Enc/Dec loss: 0.067824, Enc/Dis: 0.071812]\n",
      "97 [D real: -0.567280, D fake: 0.569690], [Enc/Dec loss: 0.057852, Enc/Dis: 0.061373]\n",
      "98 [D real: -0.567044, D fake: 0.568863], [Enc/Dec loss: 0.058390, Enc/Dis: 0.063916]\n",
      "99 [D real: -0.567144, D fake: 0.566920], [Enc/Dec loss: 0.066028, Enc/Dis: 0.068520]\n",
      "100 [D real: -0.568474, D fake: 0.566386], [Enc/Dec loss: 0.064189, Enc/Dis: 0.069144]\n",
      "101 [D real: -0.586672, D fake: 0.564896], [Enc/Dec loss: 0.064454, Enc/Dis: 0.069519]\n",
      "102 [D real: -0.589374, D fake: 0.565213], [Enc/Dec loss: 0.068810, Enc/Dis: 0.074209]\n",
      "103 [D real: -0.586281, D fake: 0.572413], [Enc/Dec loss: 0.060852, Enc/Dis: 0.066330]\n",
      "104 [D real: -0.585201, D fake: 0.565936], [Enc/Dec loss: 0.066148, Enc/Dis: 0.068613]\n",
      "105 [D real: -0.577040, D fake: 0.561660], [Enc/Dec loss: 0.060599, Enc/Dis: 0.064804]\n",
      "106 [D real: -0.577718, D fake: 0.561230], [Enc/Dec loss: 0.058489, Enc/Dis: 0.062361]\n",
      "107 [D real: -0.580098, D fake: 0.563833], [Enc/Dec loss: 0.061732, Enc/Dis: 0.067113]\n",
      "108 [D real: -0.577885, D fake: 0.563067], [Enc/Dec loss: 0.060685, Enc/Dis: 0.064904]\n",
      "109 [D real: -0.577699, D fake: 0.566374], [Enc/Dec loss: 0.058714, Enc/Dis: 0.064786]\n",
      "110 [D real: -0.576699, D fake: 0.569988], [Enc/Dec loss: 0.061661, Enc/Dis: 0.066251]\n",
      "111 [D real: -0.578963, D fake: 0.579928], [Enc/Dec loss: 0.061790, Enc/Dis: 0.066780]\n",
      "112 [D real: -0.575179, D fake: 0.577355], [Enc/Dec loss: 0.057598, Enc/Dis: 0.063085]\n",
      "113 [D real: -0.571746, D fake: 0.581455], [Enc/Dec loss: 0.060510, Enc/Dis: 0.064989]\n",
      "114 [D real: -0.568430, D fake: 0.578805], [Enc/Dec loss: 0.073264, Enc/Dis: 0.075257]\n",
      "115 [D real: -0.569562, D fake: 0.574238], [Enc/Dec loss: 0.063517, Enc/Dis: 0.065953]\n",
      "116 [D real: -0.573343, D fake: 0.573864], [Enc/Dec loss: 0.067035, Enc/Dis: 0.070523]\n",
      "117 [D real: -0.574445, D fake: 0.572730], [Enc/Dec loss: 0.061327, Enc/Dis: 0.065070]\n",
      "118 [D real: -0.572670, D fake: 0.570750], [Enc/Dec loss: 0.064345, Enc/Dis: 0.068985]\n",
      "119 [D real: -0.572683, D fake: 0.570671], [Enc/Dec loss: 0.062336, Enc/Dis: 0.066990]\n",
      "120 [D real: -0.574274, D fake: 0.572718], [Enc/Dec loss: 0.061433, Enc/Dis: 0.066271]\n",
      "121 [D real: -0.559863, D fake: 0.580734], [Enc/Dec loss: 0.065396, Enc/Dis: 0.069019]\n",
      "122 [D real: -0.570135, D fake: 0.570947], [Enc/Dec loss: 0.062405, Enc/Dis: 0.066008]\n",
      "123 [D real: -0.572422, D fake: 0.557701], [Enc/Dec loss: 0.058986, Enc/Dis: 0.064081]\n",
      "124 [D real: -0.572489, D fake: 0.558440], [Enc/Dec loss: 0.068482, Enc/Dis: 0.072949]\n",
      "125 [D real: -0.568799, D fake: 0.557503], [Enc/Dec loss: 0.060621, Enc/Dis: 0.065609]\n",
      "126 [D real: -0.567986, D fake: 0.555917], [Enc/Dec loss: 0.064107, Enc/Dis: 0.068697]\n",
      "127 [D real: -0.565303, D fake: 0.557945], [Enc/Dec loss: 0.066334, Enc/Dis: 0.070227]\n",
      "128 [D real: -0.566676, D fake: 0.560070], [Enc/Dec loss: 0.064567, Enc/Dis: 0.067708]\n",
      "129 [D real: -0.567792, D fake: 0.561428], [Enc/Dec loss: 0.063920, Enc/Dis: 0.067233]\n",
      "130 [D real: -0.568665, D fake: 0.562035], [Enc/Dec loss: 0.064132, Enc/Dis: 0.068148]\n",
      "131 [D real: -0.584081, D fake: 0.564488], [Enc/Dec loss: 0.056909, Enc/Dis: 0.060758]\n",
      "132 [D real: -0.557867, D fake: 0.563968], [Enc/Dec loss: 0.057602, Enc/Dis: 0.061303]\n",
      "133 [D real: -0.560988, D fake: 0.571178], [Enc/Dec loss: 0.065163, Enc/Dis: 0.068631]\n",
      "134 [D real: -0.563388, D fake: 0.566457], [Enc/Dec loss: 0.063668, Enc/Dis: 0.065878]\n",
      "135 [D real: -0.563800, D fake: 0.567217], [Enc/Dec loss: 0.054930, Enc/Dis: 0.058919]\n",
      "136 [D real: -0.559810, D fake: 0.567648], [Enc/Dec loss: 0.064626, Enc/Dis: 0.067407]\n",
      "137 [D real: -0.560857, D fake: 0.566673], [Enc/Dec loss: 0.067472, Enc/Dis: 0.069884]\n",
      "138 [D real: -0.562599, D fake: 0.565925], [Enc/Dec loss: 0.062712, Enc/Dis: 0.066310]\n",
      "139 [D real: -0.562455, D fake: 0.565592], [Enc/Dec loss: 0.066091, Enc/Dis: 0.069894]\n",
      "140 [D real: -0.564335, D fake: 0.567293], [Enc/Dec loss: 0.062968, Enc/Dis: 0.066545]\n",
      "141 [D real: -0.542507, D fake: 0.585287], [Enc/Dec loss: 0.061191, Enc/Dis: 0.067214]\n",
      "142 [D real: -0.553118, D fake: 0.565732], [Enc/Dec loss: 0.061162, Enc/Dis: 0.064825]\n",
      "143 [D real: -0.557796, D fake: 0.560993], [Enc/Dec loss: 0.065152, Enc/Dis: 0.073208]\n",
      "144 [D real: -0.564491, D fake: 0.558390], [Enc/Dec loss: 0.066266, Enc/Dis: 0.068912]\n",
      "145 [D real: -0.565583, D fake: 0.566207], [Enc/Dec loss: 0.055580, Enc/Dis: 0.062197]\n",
      "146 [D real: -0.562621, D fake: 0.570707], [Enc/Dec loss: 0.061984, Enc/Dis: 0.063961]\n",
      "147 [D real: -0.563775, D fake: 0.561986], [Enc/Dec loss: 0.060959, Enc/Dis: 0.064397]\n",
      "148 [D real: -0.565275, D fake: 0.561927], [Enc/Dec loss: 0.055346, Enc/Dis: 0.059557]\n",
      "149 [D real: -0.567472, D fake: 0.560323], [Enc/Dec loss: 0.056277, Enc/Dis: 0.061393]\n",
      "150 [D real: -0.564616, D fake: 0.558599], [Enc/Dec loss: 0.065319, Enc/Dis: 0.069204]\n",
      "151 [D real: -0.559858, D fake: 0.532901], [Enc/Dec loss: 0.059811, Enc/Dis: 0.064228]\n",
      "152 [D real: -0.556019, D fake: 0.557821], [Enc/Dec loss: 0.056312, Enc/Dis: 0.060476]\n",
      "153 [D real: -0.560862, D fake: 0.552795], [Enc/Dec loss: 0.059332, Enc/Dis: 0.063249]\n",
      "154 [D real: -0.560499, D fake: 0.553468], [Enc/Dec loss: 0.066763, Enc/Dis: 0.068873]\n",
      "155 [D real: -0.557444, D fake: 0.556399], [Enc/Dec loss: 0.061770, Enc/Dis: 0.064945]\n",
      "156 [D real: -0.559257, D fake: 0.551155], [Enc/Dec loss: 0.059475, Enc/Dis: 0.063916]\n",
      "157 [D real: -0.561503, D fake: 0.551824], [Enc/Dec loss: 0.059201, Enc/Dis: 0.065281]\n",
      "158 [D real: -0.561409, D fake: 0.554736], [Enc/Dec loss: 0.061009, Enc/Dis: 0.066077]\n",
      "159 [D real: -0.564791, D fake: 0.553485], [Enc/Dec loss: 0.062379, Enc/Dis: 0.066396]\n",
      "160 [D real: -0.563642, D fake: 0.553812], [Enc/Dec loss: 0.067585, Enc/Dis: 0.070659]\n",
      "161 [D real: -0.584196, D fake: 0.565981], [Enc/Dec loss: 0.057194, Enc/Dis: 0.061737]\n",
      "162 [D real: -0.585190, D fake: 0.559912], [Enc/Dec loss: 0.055471, Enc/Dis: 0.059541]\n",
      "163 [D real: -0.582175, D fake: 0.567126], [Enc/Dec loss: 0.060719, Enc/Dis: 0.065996]\n",
      "164 [D real: -0.577593, D fake: 0.569489], [Enc/Dec loss: 0.059355, Enc/Dis: 0.064578]\n",
      "165 [D real: -0.575111, D fake: 0.563796], [Enc/Dec loss: 0.064195, Enc/Dis: 0.068117]\n",
      "166 [D real: -0.574897, D fake: 0.563665], [Enc/Dec loss: 0.064124, Enc/Dis: 0.068323]\n",
      "167 [D real: -0.572880, D fake: 0.561133], [Enc/Dec loss: 0.056205, Enc/Dis: 0.061255]\n",
      "168 [D real: -0.573928, D fake: 0.563917], [Enc/Dec loss: 0.060842, Enc/Dis: 0.064533]\n",
      "169 [D real: -0.574981, D fake: 0.563677], [Enc/Dec loss: 0.058013, Enc/Dis: 0.060910]\n",
      "170 [D real: -0.575053, D fake: 0.560034], [Enc/Dec loss: 0.056446, Enc/Dis: 0.060343]\n",
      "171 [D real: -0.576111, D fake: 0.555486], [Enc/Dec loss: 0.059991, Enc/Dis: 0.060951]\n",
      "172 [D real: -0.581719, D fake: 0.576015], [Enc/Dec loss: 0.061401, Enc/Dis: 0.065596]\n",
      "173 [D real: -0.572158, D fake: 0.566338], [Enc/Dec loss: 0.053916, Enc/Dis: 0.058648]\n",
      "174 [D real: -0.567603, D fake: 0.565822], [Enc/Dec loss: 0.058359, Enc/Dis: 0.063350]\n",
      "175 [D real: -0.566153, D fake: 0.568124], [Enc/Dec loss: 0.060557, Enc/Dis: 0.065593]\n",
      "176 [D real: -0.569922, D fake: 0.569814], [Enc/Dec loss: 0.055432, Enc/Dis: 0.060320]\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(i, Z, batch_size, train_dataset, epochs, scaler, X_train_scaled, scaled, X_train, y_train )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#Discriminator Loss\n",
    "Dloss = Image.open('AAE/Losses/D_loss_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"D_loss\",figsize=[15,10])\n",
    "plt.imshow(Dloss)\n",
    "#Encoder Loss\n",
    "Gloss = Image.open('AAE/Losses/G_loss_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"G_loss\",figsize=[15,10])\n",
    "plt.imshow(Gloss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samping from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('AAE/Result/v'+str(i)+'_latent_space 3D_'+str(epochs)+'.png')\n",
    "plt.figure(\"3D\",figsize=[15,10])\n",
    "plt.imshow(img)\n",
    "\n",
    "img2 = Image.open('AAE/Result/v'+str(i)+'_Latent_Space 2D_'+str(epochs)+'.png')\n",
    "plt.figure(\"2D\",figsize=[15,10])\n",
    "plt.imshow(img2)\n",
    "\n",
    "img3 = Image.open('AAE/Result/v_'+str(i)+'_epochs_'+str(epochs)+'.png')\n",
    "plt.figure(\"Autoencoder\",figsize=[15,10])\n",
    "plt.imshow(img3)\n",
    "\n",
    "img4 = Image.open('AAE/Result/'+'countour_line_v'+str(i)+'_epochs'+str(epochs)+'.png')\n",
    "plt.figure(\"countour_line\",figsize=[15,10])\n",
    "plt.imshow(img4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.models.load_model('./AAE/Models/encoder_v'+str(i)+'_'+str(epochs))\n",
    "decoder = keras.models.load_model('./AAE/Models/decoder_v'+str(i)+'_'+str(epochs))\n",
    "discriminator = keras.models.load_model('./AAE/Models/discriminator_v'+str(i)+'_'+str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input = [-4,-3,-2,-1,0,1,2,3,4]\n",
    "n_points = 900\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//9, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//9, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//9, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//9, n_features), x_input[3])\n",
    "predict5 = np.full((n_points//9, n_features), x_input[4])\n",
    "predict6 = np.full((n_points//9, n_features), x_input[5])\n",
    "predict7 = np.full((n_points//9, n_features), x_input[6])\n",
    "predict8 = np.full((n_points//9, n_features), x_input[7])\n",
    "predict9 = np.full((n_points//9, n_features), x_input[8])\n",
    "\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4, predict5, predict6, predict7, predict8, predict9))\n",
    "predictthis_scaled = scaler.transform(predictthis)\n",
    "input_test = predictthis_scaled.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated = aae.predict(input_test, scaler)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,c='orange') \n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    #plt.scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    #plt.scatter(predicted_values2[:,0],predicted_values2[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Prediction/'+str(epochs)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
