{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from backend import import_excel, export_excel\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# style.use('bmh')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dataset,network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "scenario= \"moons\" #sinus, helix\n",
    "#n_instance = 1000\n",
    "n_instance = 5000\n",
    "n_features = 2\n",
    "Z = 6 #3的倍數\n",
    "nodes = 4 #8\n",
    "var = 4\n",
    "scales = ['-1-1','0-1']\n",
    "scaled = '-1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    print(\"X_train= x,y\",X_train.shape)\n",
    "    print(\"y_train= z\",y_train.shape)\n",
    "\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], y_train, c='orange')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "else:\n",
    "    X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(n_instance, scenario)\n",
    "    plt.scatter(X_train,y_train, c='orange', label='Sample Data')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1) (5000, 1)\n",
      "made dataset\n"
     ]
    }
   ],
   "source": [
    "#storage data\n",
    "os.system('mkdir Dataset')\n",
    "os.system('mkdir AAE')\n",
    "os.system('mkdir AAE/Models')\n",
    "os.system('mkdir AAE/Losses')\n",
    "os.system('mkdir AAE/Random_test')\n",
    "export_excel(X_train, 'Dataset/X_train')\n",
    "export_excel(y_train, 'Dataset/y_train')\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "X_train = import_excel('Dataset/X_train')\n",
    "y_train = import_excel('Dataset/y_train')\n",
    "print('made dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 8, 8)         0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 8, 16)        128         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 16)        64          conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 8, 16)        0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 8, 4)         64          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 4)         16          conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 8, 4)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            192         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            192         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6)            24          lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,096\n",
      "Trainable params: 900\n",
      "Non-trainable params: 196\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                360       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 2,440\n",
      "Trainable params: 2,240\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 8, 16)             128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 16)             64        \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 8, 8)              128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8)              32        \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 1,056\n",
      "Trainable params: 880\n",
      "Non-trainable params: 176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=network.build_encoder(Z, nodes, n_features)\n",
    "decoder=network.build_decoder(Z, var, n_features)\n",
    "discriminator=network.build_discriminator(Z, nodes)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AAE_Model\n",
    "\n",
    "GANorWGAN='WGAN' #GAN\n",
    "epochs = 2000 #500\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           128         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64)           256         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 64)           0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 8, 8)         0           re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8)         32          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 8, 16)        128         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 16)        64          conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 16)        0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTrans (None, 8, 4)         64          re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 4)         16          conv1d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 8, 4)         0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            192         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 6)            192         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6)            0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 6)            24          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,096\n",
      "Trainable params: 900\n",
      "Non-trainable params: 196\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                360       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 2,440\n",
      "Trainable params: 2,240\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aae = AAE_Model.AAE(Z, n_features, batch_size, GANorWGAN, nodes, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape_1 (100, 2)\n",
      "data shape_2 (100, 2)\n",
      "data shape_3 (100, 2)\n",
      "data shape_4 (100, 2)\n",
      "data shape_5 (100, 2)\n",
      "data shape_6 (100, 2)\n",
      "data shape_7 (100, 2)\n",
      "data shape_8 (100, 2)\n",
      "data shape_9 (100, 2)\n",
      "data shape_10 (100, 2)\n",
      "data shape_11 (100, 2)\n",
      "data shape_12 (100, 2)\n",
      "data shape_13 (100, 2)\n",
      "data shape_14 (100, 2)\n",
      "data shape_15 (100, 2)\n",
      "data shape_16 (100, 2)\n",
      "data shape_17 (100, 2)\n",
      "data shape_18 (100, 2)\n",
      "data shape_19 (100, 2)\n",
      "data shape_20 (100, 2)\n",
      "data shape_21 (100, 2)\n",
      "data shape_22 (100, 2)\n",
      "data shape_23 (100, 2)\n",
      "data shape_24 (100, 2)\n",
      "data shape_25 (100, 2)\n",
      "data shape_26 (100, 2)\n",
      "data shape_27 (100, 2)\n",
      "data shape_28 (100, 2)\n",
      "data shape_29 (100, 2)\n",
      "data shape_30 (100, 2)\n",
      "data shape_31 (100, 2)\n",
      "data shape_32 (100, 2)\n",
      "data shape_33 (100, 2)\n",
      "data shape_34 (100, 2)\n",
      "data shape_35 (100, 2)\n",
      "data shape_36 (100, 2)\n",
      "data shape_37 (100, 2)\n",
      "data shape_38 (100, 2)\n",
      "data shape_39 (100, 2)\n",
      "data shape_40 (100, 2)\n",
      "data shape_41 (100, 2)\n",
      "data shape_42 (100, 2)\n",
      "data shape_43 (100, 2)\n",
      "data shape_44 (100, 2)\n",
      "data shape_45 (100, 2)\n",
      "data shape_46 (100, 2)\n",
      "data shape_47 (100, 2)\n",
      "data shape_48 (100, 2)\n",
      "data shape_49 (100, 2)\n",
      "data shape_50 (100, 2)\n",
      "data shape_51 (100, 2)\n",
      "data shape_52 (100, 2)\n",
      "data shape_53 (100, 2)\n",
      "data shape_54 (100, 2)\n",
      "data shape_55 (100, 2)\n",
      "data shape_56 (100, 2)\n",
      "data shape_57 (100, 2)\n",
      "data shape_58 (100, 2)\n",
      "data shape_59 (100, 2)\n",
      "data shape_60 (100, 2)\n",
      "data shape_61 (100, 2)\n",
      "data shape_62 (100, 2)\n",
      "data shape_63 (100, 2)\n",
      "data shape_64 (100, 2)\n",
      "data shape_65 (100, 2)\n",
      "data shape_66 (100, 2)\n",
      "data shape_67 (100, 2)\n",
      "data shape_68 (100, 2)\n",
      "data shape_69 (100, 2)\n",
      "data shape_70 (100, 2)\n",
      "data shape_71 (100, 2)\n",
      "data shape_72 (100, 2)\n",
      "data shape_73 (100, 2)\n",
      "data shape_74 (100, 2)\n",
      "data shape_75 (100, 2)\n",
      "data shape_76 (100, 2)\n",
      "data shape_77 (100, 2)\n",
      "data shape_78 (100, 2)\n",
      "data shape_79 (100, 2)\n",
      "data shape_80 (100, 2)\n",
      "data shape_81 (100, 2)\n",
      "data shape_82 (100, 2)\n",
      "data shape_83 (100, 2)\n",
      "data shape_84 (100, 2)\n",
      "data shape_85 (100, 2)\n",
      "data shape_86 (100, 2)\n",
      "data shape_87 (100, 2)\n",
      "data shape_88 (100, 2)\n",
      "data shape_89 (100, 2)\n",
      "data shape_90 (100, 2)\n",
      "data shape_91 (100, 2)\n",
      "data shape_92 (100, 2)\n",
      "data shape_93 (100, 2)\n",
      "data shape_94 (100, 2)\n",
      "data shape_95 (100, 2)\n",
      "data shape_96 (100, 2)\n",
      "data shape_97 (100, 2)\n",
      "data shape_98 (100, 2)\n",
      "data shape_99 (100, 2)\n",
      "data shape_100 (100, 2)\n",
      "Cycles:  100\n",
      "X_train (10000, 1)\n",
      "y_train (10000, 1)\n",
      "X_train_scaled (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, scaler, X_train_scaled = aae.preproc(X_train, y_train, scaled)\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"X_train_scaled\",X_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_13/kernel:0'] when minimizing the loss.\n",
      "1 [D real: -0.620065, D fake: 0.611636], [Enc/Dec loss: 0.659813, Enc/Dis: 0.666666]\n",
      "2 [D real: -0.629273, D fake: 0.620341], [Enc/Dec loss: 0.631330, Enc/Dis: 0.638136]\n",
      "3 [D real: -0.636227, D fake: 0.635918], [Enc/Dec loss: 0.602354, Enc/Dis: 0.609195]\n",
      "4 [D real: -0.637297, D fake: 0.633462], [Enc/Dec loss: 0.594293, Enc/Dis: 0.601195]\n",
      "5 [D real: -0.640917, D fake: 0.637141], [Enc/Dec loss: 0.573888, Enc/Dis: 0.580842]\n",
      "6 [D real: -0.645424, D fake: 0.639539], [Enc/Dec loss: 0.567131, Enc/Dis: 0.574137]\n",
      "7 [D real: -0.648955, D fake: 0.648901], [Enc/Dec loss: 0.557110, Enc/Dis: 0.564162]\n",
      "8 [D real: -0.653921, D fake: 0.653856], [Enc/Dec loss: 0.550412, Enc/Dis: 0.557501]\n",
      "9 [D real: -0.659695, D fake: 0.658322], [Enc/Dec loss: 0.545301, Enc/Dis: 0.552440]\n",
      "10 [D real: -0.664605, D fake: 0.660922], [Enc/Dec loss: 0.534158, Enc/Dis: 0.541329]\n",
      "11 [D real: -0.670228, D fake: 0.666174], [Enc/Dec loss: 0.527707, Enc/Dis: 0.534924]\n",
      "12 [D real: -0.675271, D fake: 0.670240], [Enc/Dec loss: 0.523975, Enc/Dis: 0.531233]\n",
      "13 [D real: -0.679683, D fake: 0.675881], [Enc/Dec loss: 0.513357, Enc/Dis: 0.520661]\n",
      "14 [D real: -0.685052, D fake: 0.680480], [Enc/Dec loss: 0.503527, Enc/Dis: 0.510868]\n",
      "15 [D real: -0.689518, D fake: 0.685813], [Enc/Dec loss: 0.498650, Enc/Dis: 0.506041]\n",
      "16 [D real: -0.693952, D fake: 0.690108], [Enc/Dec loss: 0.488466, Enc/Dis: 0.495895]\n",
      "17 [D real: -0.698758, D fake: 0.694956], [Enc/Dec loss: 0.488134, Enc/Dis: 0.495606]\n",
      "18 [D real: -0.703557, D fake: 0.699971], [Enc/Dec loss: 0.484109, Enc/Dis: 0.491621]\n",
      "19 [D real: -0.708057, D fake: 0.704974], [Enc/Dec loss: 0.478351, Enc/Dis: 0.485904]\n",
      "20 [D real: -0.712794, D fake: 0.709416], [Enc/Dec loss: 0.472645, Enc/Dis: 0.480234]\n",
      "21 [D real: -0.717739, D fake: 0.713690], [Enc/Dec loss: 0.468341, Enc/Dis: 0.475969]\n",
      "22 [D real: -0.721511, D fake: 0.717932], [Enc/Dec loss: 0.463926, Enc/Dis: 0.471594]\n",
      "23 [D real: -0.725393, D fake: 0.722147], [Enc/Dec loss: 0.460845, Enc/Dis: 0.468550]\n",
      "24 [D real: -0.729188, D fake: 0.726333], [Enc/Dec loss: 0.456446, Enc/Dis: 0.464182]\n",
      "25 [D real: -0.733056, D fake: 0.729828], [Enc/Dec loss: 0.449815, Enc/Dis: 0.457586]\n",
      "26 [D real: -0.737088, D fake: 0.734127], [Enc/Dec loss: 0.443230, Enc/Dis: 0.451034]\n",
      "27 [D real: -0.740924, D fake: 0.737887], [Enc/Dec loss: 0.438626, Enc/Dis: 0.446462]\n",
      "28 [D real: -0.744616, D fake: 0.742309], [Enc/Dec loss: 0.433703, Enc/Dis: 0.441573]\n",
      "29 [D real: -0.748311, D fake: 0.746188], [Enc/Dec loss: 0.428745, Enc/Dis: 0.436647]\n",
      "30 [D real: -0.752488, D fake: 0.749861], [Enc/Dec loss: 0.424766, Enc/Dis: 0.432698]\n",
      "31 [D real: -0.755470, D fake: 0.753395], [Enc/Dec loss: 0.419775, Enc/Dis: 0.427738]\n",
      "32 [D real: -0.758676, D fake: 0.756582], [Enc/Dec loss: 0.415173, Enc/Dis: 0.423165]\n",
      "33 [D real: -0.761944, D fake: 0.759687], [Enc/Dec loss: 0.410415, Enc/Dis: 0.418436]\n",
      "34 [D real: -0.764992, D fake: 0.763102], [Enc/Dec loss: 0.407506, Enc/Dis: 0.415556]\n",
      "35 [D real: -0.768280, D fake: 0.766241], [Enc/Dec loss: 0.404831, Enc/Dis: 0.412908]\n",
      "36 [D real: -0.771362, D fake: 0.769352], [Enc/Dec loss: 0.400738, Enc/Dis: 0.408840]\n",
      "37 [D real: -0.774525, D fake: 0.772531], [Enc/Dec loss: 0.396962, Enc/Dis: 0.405091]\n",
      "38 [D real: -0.777804, D fake: 0.775774], [Enc/Dec loss: 0.393290, Enc/Dis: 0.401445]\n",
      "39 [D real: -0.780722, D fake: 0.778681], [Enc/Dec loss: 0.389522, Enc/Dis: 0.397702]\n",
      "40 [D real: -0.783662, D fake: 0.781905], [Enc/Dec loss: 0.385770, Enc/Dis: 0.393977]\n",
      "41 [D real: -0.786391, D fake: 0.784774], [Enc/Dec loss: 0.382305, Enc/Dis: 0.390537]\n",
      "42 [D real: -0.788977, D fake: 0.787514], [Enc/Dec loss: 0.379650, Enc/Dis: 0.387908]\n",
      "43 [D real: -0.791689, D fake: 0.790038], [Enc/Dec loss: 0.376770, Enc/Dis: 0.385054]\n",
      "44 [D real: -0.794373, D fake: 0.792743], [Enc/Dec loss: 0.374005, Enc/Dis: 0.382313]\n",
      "45 [D real: -0.796940, D fake: 0.795360], [Enc/Dec loss: 0.371791, Enc/Dis: 0.380123]\n",
      "46 [D real: -0.799547, D fake: 0.797755], [Enc/Dec loss: 0.368352, Enc/Dis: 0.376705]\n",
      "47 [D real: -0.801895, D fake: 0.800205], [Enc/Dec loss: 0.365665, Enc/Dis: 0.374040]\n",
      "48 [D real: -0.804323, D fake: 0.802752], [Enc/Dec loss: 0.363038, Enc/Dis: 0.371435]\n",
      "49 [D real: -0.806633, D fake: 0.805122], [Enc/Dec loss: 0.360675, Enc/Dis: 0.369092]\n",
      "50 [D real: -0.808961, D fake: 0.807475], [Enc/Dec loss: 0.357199, Enc/Dis: 0.365637]\n",
      "51 [D real: -0.811230, D fake: 0.809864], [Enc/Dec loss: 0.355123, Enc/Dis: 0.363582]\n",
      "52 [D real: -0.813200, D fake: 0.812171], [Enc/Dec loss: 0.352997, Enc/Dis: 0.361477]\n",
      "53 [D real: -0.815515, D fake: 0.814420], [Enc/Dec loss: 0.350755, Enc/Dis: 0.359255]\n",
      "54 [D real: -0.817627, D fake: 0.816541], [Enc/Dec loss: 0.347922, Enc/Dis: 0.356442]\n",
      "55 [D real: -0.819711, D fake: 0.818694], [Enc/Dec loss: 0.345535, Enc/Dis: 0.354073]\n",
      "56 [D real: -0.821805, D fake: 0.820748], [Enc/Dec loss: 0.343411, Enc/Dis: 0.351967]\n",
      "57 [D real: -0.823854, D fake: 0.822739], [Enc/Dec loss: 0.340632, Enc/Dis: 0.349205]\n",
      "58 [D real: -0.825746, D fake: 0.824790], [Enc/Dec loss: 0.338150, Enc/Dis: 0.346742]\n",
      "59 [D real: -0.827631, D fake: 0.826688], [Enc/Dec loss: 0.335685, Enc/Dis: 0.344292]\n",
      "60 [D real: -0.829384, D fake: 0.828670], [Enc/Dec loss: 0.334227, Enc/Dis: 0.342852]\n",
      "61 [D real: -0.831230, D fake: 0.830488], [Enc/Dec loss: 0.331122, Enc/Dis: 0.339763]\n",
      "62 [D real: -0.833078, D fake: 0.832149], [Enc/Dec loss: 0.328812, Enc/Dis: 0.337470]\n",
      "63 [D real: -0.834716, D fake: 0.834018], [Enc/Dec loss: 0.327456, Enc/Dis: 0.336131]\n",
      "64 [D real: -0.836580, D fake: 0.835747], [Enc/Dec loss: 0.325702, Enc/Dis: 0.334392]\n",
      "65 [D real: -0.838261, D fake: 0.837438], [Enc/Dec loss: 0.324077, Enc/Dis: 0.332783]\n",
      "66 [D real: -0.839942, D fake: 0.839178], [Enc/Dec loss: 0.322236, Enc/Dis: 0.330956]\n",
      "67 [D real: -0.841611, D fake: 0.840849], [Enc/Dec loss: 0.320544, Enc/Dis: 0.329279]\n",
      "68 [D real: -0.843181, D fake: 0.842439], [Enc/Dec loss: 0.318525, Enc/Dis: 0.327275]\n",
      "69 [D real: -0.844711, D fake: 0.844123], [Enc/Dec loss: 0.316846, Enc/Dis: 0.325610]\n",
      "70 [D real: -0.846294, D fake: 0.845640], [Enc/Dec loss: 0.314729, Enc/Dis: 0.323506]\n",
      "71 [D real: -0.847781, D fake: 0.847206], [Enc/Dec loss: 0.312500, Enc/Dis: 0.321291]\n",
      "72 [D real: -0.849266, D fake: 0.848728], [Enc/Dec loss: 0.310999, Enc/Dis: 0.319804]\n",
      "73 [D real: -0.850752, D fake: 0.850242], [Enc/Dec loss: 0.309253, Enc/Dis: 0.318070]\n",
      "74 [D real: -0.852205, D fake: 0.851687], [Enc/Dec loss: 0.307430, Enc/Dis: 0.316259]\n",
      "75 [D real: -0.853586, D fake: 0.853028], [Enc/Dec loss: 0.305542, Enc/Dis: 0.314384]\n",
      "76 [D real: -0.854986, D fake: 0.854469], [Enc/Dec loss: 0.303877, Enc/Dis: 0.312731]\n",
      "77 [D real: -0.856390, D fake: 0.855824], [Enc/Dec loss: 0.302170, Enc/Dis: 0.311036]\n",
      "78 [D real: -0.857750, D fake: 0.857187], [Enc/Dec loss: 0.300803, Enc/Dis: 0.309682]\n",
      "79 [D real: -0.859050, D fake: 0.858507], [Enc/Dec loss: 0.299675, Enc/Dis: 0.308566]\n",
      "80 [D real: -0.860364, D fake: 0.859799], [Enc/Dec loss: 0.298470, Enc/Dis: 0.307373]\n",
      "81 [D real: -0.861659, D fake: 0.861068], [Enc/Dec loss: 0.296518, Enc/Dis: 0.305432]\n",
      "82 [D real: -0.862936, D fake: 0.862300], [Enc/Dec loss: 0.294858, Enc/Dis: 0.303784]\n"
     ]
    }
   ],
   "source": [
    "hist = aae.train(Z, batch_size, train_dataset, epochs, scaler, X_train_scaled, scaled, X_train, y_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('D_Loss: ')\n",
    "fig, ax = plt.subplots(1,1, figsize=[10,5])\n",
    "ax.plot(aae.c1_hist, c='red')\n",
    "ax.plot(aae.c2_hist, c='blue')\n",
    "\n",
    "ax.legend(['C real', 'C fake'])\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"AAE D_Loss per Epoch\")\n",
    "plt.savefig('AAE/Losses/D_loss'+str(epochs)+'.png')\n",
    "\n",
    "print('G_Loss: ')\n",
    "fig, ax = plt.subplots(1,1, figsize=[10,5])\n",
    "ax.plot(aae.g1_hist, c='orange')\n",
    "ax.plot(aae.g2_hist, c='green')\n",
    "\n",
    "ax.legend(['Generator', 'MSE'])\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"AAE G_Loss per Epoch\")\n",
    "plt.savefig('AAE/Losses/G_loss'+str(epochs)+'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict from the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the labels of the data values on the basis of the trained model.\n",
    "#sampling from the latent space without prediction\n",
    "#X, _ = make_swiss_roll(n_samples=int(self.batch_size*self.Z/3), noise=0.3)\n",
    "#latent_values5 = X.reshape([1000,Z])\n",
    "latent_values = tf.random.normal([1000, Z])\n",
    "predicted_values = aae.decoder(latent_values)\n",
    "\n",
    "predicted_values2 = aae.decoder(aae.encoder(X_train_scaled))\n",
    "predicted_values3 = aae.encoder(X_train_scaled)\n",
    "#predicted_values4 = scaler.inverse_transform(X_train_scaled)\n",
    "\n",
    "if scaled == '-1-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "elif scaled =='0-1':\n",
    "    predicted_values = scaler.inverse_transform(predicted_values)\n",
    "    predicted_values2 = scaler.inverse_transform(predicted_values2)\n",
    "    \n",
    "\n",
    "\n",
    "if n_features==3:\n",
    "    print(\"Predicted Values:\",predicted_values.shape)\n",
    "    print(\"latent_space:\",Z)\n",
    "    print(\"BATCH_SIZE:\",BATCH_SIZE)\n",
    "    print(\"epochs:\",epochs)\n",
    "    \n",
    "\n",
    "    ab = plt.subplot(projection='3d')\n",
    "    ab.scatter(predicted_values5[:,0],predicted_values5[:,1],predicted_values5[:,2])\n",
    "    ab.set_ylabel('Y')\n",
    "    ab.set_zlabel('Z')\n",
    "    ab.set_xlabel('X')\n",
    "    \n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(predicted_values[:,0],predicted_values[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(predicted_values[:,1],predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,0]>=-0.8-0.05,predicted_values[:,0]<=-0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,0]>=0.0-0.05,predicted_values[:,0]<=0.0+0.05),predicted_values[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,0]>=0.8-0.05,predicted_values[:,0]<=0.8+0.05),predicted_values[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(predicted_values[:,1]>=0.2-0.05,predicted_values[:,1]<=0.2+0.05),predicted_values[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,predicted_values[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(predicted_values[:,1]>=0.5-0.05,predicted_values[:,1]<=0.5+0.05),predicted_values[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,predicted_values[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(predicted_values[:,1]>=0.8-0.05,predicted_values[:,1]<=0.8+0.05),predicted_values[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,predicted_values[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Random_test'+'.png')\n",
    "    \n",
    "    \n",
    "else:\n",
    "    #ab = plt.subplot(projection='3d')\n",
    "    #ab.scatter(latent_values5[:,0],latent_values5[:,1],latent_values5[:,2])\n",
    "    #ab.set_ylabel('Y')\n",
    "    #ab.set_zlabel('Z')\n",
    "    #ab.set_xlabel('X')\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "\n",
    "    axes[0].scatter(predicted_values3[:,0],predicted_values3[:,1],c='pink')#encoder(X_train_scaled)\n",
    "    axes[0].scatter(latent_values[:,0],latent_values[:,1],c='grey')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[0].set_xlabel('X')\n",
    "\n",
    "    \n",
    "    \n",
    "    axes[1].scatter(predicted_values2[:,0],predicted_values2[:,1],)#encoder/decoder\n",
    "    #axes[1].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[1].set_ylabel('Y')\n",
    "    axes[1].set_xlabel('X')\n",
    "\n",
    "    \n",
    "    axes[2].scatter(predicted_values[:,0],predicted_values[:,1],c='red') #decoder(latent space)\n",
    "    #axes[2].scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    axes[2].set_ylabel('Y')\n",
    "    axes[2].set_xlabel('X')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Result/'+str(epochs)+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these for desired prediction\n",
    "x_input =[-1.0,-0.5,0,0.5,1.0,1.5,2.0]\n",
    "n_points = 700\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "\n",
    "# produces an input of fixed x coordinates with random y values\n",
    "predict1 = np.full((n_points//7, n_features), x_input[0])\n",
    "predict2 = np.full((n_points//7, n_features), x_input[1])\n",
    "predict3 = np.full((n_points//7, n_features), x_input[2])\n",
    "predict4 = np.full((n_points//7, n_features), x_input[3])\n",
    "predict5 = np.full((n_points//7, n_features), x_input[4])\n",
    "predict6 = np.full((n_points//7, n_features), x_input[5])\n",
    "predict7 = np.full((n_points//7, n_features), x_input[6])\n",
    "\n",
    "predictthis = np.concatenate((predict1, predict2, predict3, predict4, predict5, predict6, predict7))\n",
    "#predictthis_scaled = scaler.transform(predictthis)\n",
    "input_test = predictthis.reshape(n_points, n_features).astype('float32')\n",
    "\n",
    "\n",
    "print(\"input_test :\",input_test.shape)\n",
    "plt.scatter(input_test[:,0],input_test[:,1] ,c='grey')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated = aae.predict(input_test, scaler)\n",
    "print(\"X_generated :\",X_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario in (\"3d\", \"helix\"):\n",
    "    print(\"latent_space=\",latent_space)\n",
    "    print(\"Epochs=\",epochs)\n",
    "    print(\"BATCH_SIZE=\",BATCH_SIZE)\n",
    "    print(\"use_bias=\",use_bias)\n",
    "    \n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter(X_generated[:,0], X_generated[:,1], X_generated[:,2], label='Generated Data')\n",
    "\n",
    "\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlabel('X')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"X-Y 2D slices:\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    axes[0].scatter(X_train[:,0],X_train[:,1])\n",
    "    axes[0].scatter(X_generated[:,0],X_generated[:,1])\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlim(-2,22)\n",
    "    axes[1].scatter(X_train[:,1],y_train)\n",
    "    axes[1].scatter(X_generated[:,1],X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-2,22)\n",
    "    axes[2].scatter(X_train[:,0],y_train)\n",
    "    axes[2].scatter(X_generated[:,0],X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Prediction/'+str(epochs)+'.png')\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    \n",
    "    ac=np.where(np.logical_and(X_train[:,0]>=-0.8-0.05,X_train[:,0]<=-0.8+0.05),X_train[:,1],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,0]>=-0.8-0.05,X_generated[:,0]<=-0.8+0.05),X_generated[:,1],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"Y(X=-0.8)\")\n",
    "    axes[0].set_ylabel(\"Y\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,0]>=0.0-0.05,X_train[:,0]<=0.0+0.05),X_train[:,1],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,0]>=0.0-0.05,X_generated[:,0]<=0.0+0.05),X_generated[:,1],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"Y(X=0.0)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,0]>=0.8-0.05,X_train[:,0]<=0.8+0.05),X_train[:,1],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,0]>=0.8-0.05,X_generated[:,0]<=0.8+0.05),X_generated[:,1],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"Y(X=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Prediction/'+str(epochs)+'.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharey=False, sharex=False)\n",
    "    ac=np.where(np.logical_and(X_train[:,1]>=0.2-0.05,X_train[:,1]<=0.2+0.05),X_train[:,0],None)\n",
    "    ad=np.where(np.logical_and(X_generated[:,1]>=0.2-0.05,X_generated[:,1]<=0.2+0.05),X_generated[:,0],None)\n",
    "    axes[0].scatter(ac,y_train)\n",
    "    axes[0].scatter(ad,X_generated[:,2])\n",
    "    axes[0].set_xlabel(\"X(Y=0.2)\")\n",
    "    axes[0].set_ylabel(\"Z\")\n",
    "    \n",
    "    ae=np.where(np.logical_and(X_train[:,1]>=0.5-0.05,X_train[:,1]<=0.5+0.05),X_train[:,0],None)\n",
    "    af=np.where(np.logical_and(X_generated[:,1]>=0.5-0.05,X_generated[:,1]<=0.5+0.05),X_generated[:,0],None)\n",
    "    axes[1].scatter(ae,y_train)\n",
    "    axes[1].scatter(af,X_generated[:,2])\n",
    "    axes[1].set_xlabel(\"X(Y=0.5)\")\n",
    "    axes[1].set_ylabel(\"Z\")\n",
    "    \n",
    "    ag=np.where(np.logical_and(X_train[:,1]>=0.8-0.05,X_train[:,1]<=0.8+0.05),X_train[:,0],None)\n",
    "    ah=np.where(np.logical_and(X_generated[:,1]>=0.8-0.05,X_generated[:,1]<=0.8+0.05),X_generated[:,0],None)\n",
    "    axes[2].scatter(ag,y_train)\n",
    "    axes[2].scatter(ah,X_generated[:,2])\n",
    "    axes[2].set_xlabel(\"X(Y=0.8)\")\n",
    "    axes[2].set_ylabel(\"Z\")\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Generated Data:\",X_generated.shape)\n",
    "    plt.scatter(X_train, y_train,c='orange') \n",
    "    plt.scatter(X_generated[:,0],X_generated[:,1])\n",
    "    #plt.scatter(predicted_values4[:,0],predicted_values4[:,1],c='grey')#X_trained_scaled\n",
    "    #plt.scatter(predicted_values2[:,0],predicted_values2[:,1])\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlabel('X')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('AAE/Prediction/'+str(epochs)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
